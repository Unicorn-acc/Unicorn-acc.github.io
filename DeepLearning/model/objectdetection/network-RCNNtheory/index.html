<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>目标检测_01_R-CNN/Fast R-CNN/Faster R-CNN理论详解 | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;ar">
<meta property="og:type" content="article">
<meta property="og:title" content="目标检测_01_R-CNN&#x2F;Fast R-CNN&#x2F;Faster R-CNN理论详解">
<meta property="og:url" content="http://unicorn-acc.github.io/DeepLearning/model/objectdetection/network-RCNNtheory/index.html">
<meta property="og:site_name" content="Miraclo’s Blog">
<meta property="og:description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;ar">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg">
<meta property="article:published_time" content="2022-11-13T12:00:38.000Z">
<meta property="article:modified_time" content="2022-11-13T13:39:35.548Z">
<meta property="article:author" content="Miraclo">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/DeepLearning/model/objectdetection/network-RCNNtheory/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":2000},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":500,"languages":{"author":"作者: Miraclo","link":"链接: ","source":"来源: Miraclo’s Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '目标检测_01_R-CNN/Fast R-CNN/Faster R-CNN理论详解',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-13 21:39:35'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">160</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg')"><!--nav#nav--><!--  span#blog_name--><!--    a#site-name(href=url_for('/')) #[=config.title]--><!----><!--  #menus--><!--    if (theme.algolia_search.enable || theme.local_search.enable)--><!--      #search-button--><!--        a.site-page.social-icon.search--><!--          i.fas.fa-search.fa-fw--><!--          span=' '+_p('search.title')--><!--    !=partial('includes/header/menu_item', {}, {cache: true})--><!----><!--    #toggle-menu--><!--      a.site-page--><!--        i.fas.fa-bars.fa-fw--><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="nav-right"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i></a></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div><div id="randomPost"><a class="site-page social-icon search" href="javascript:;" onclick="randomPost()" title="随机访问一篇文章"><i class="fas fa-car fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">目标检测_01_R-CNN/Fast R-CNN/Faster R-CNN理论详解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-13T12:00:38.000Z" title="发表于 2022-11-13 20:00:38">2022-11-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-13T13:39:35.548Z" title="更新于 2022-11-13 21:39:35">2022-11-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/2%E3%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AF%87/">2、目标检测篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="目标检测_01_R-CNN/Fast R-CNN/Faster R-CNN理论详解"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>参考内容来自霹雳吧啦Wz</p>
<p>up主的b站链接：https://space.bilibili.com/18161609/channel/index</p>
<p>up主的github：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</p>
<p>up主的CSDN博客：https://blog.csdn.net/qq_37541097/article/details/103482003</p>
</blockquote>
<h2 id="一目标检测的基本介绍">一、目标检测的基本介绍</h2>
<p>​ 所谓目标检测就是在一张图像中找到我们关注的目标，并确定它的类别和位置，这是计算机视觉领域最核心的问题之一。由于各类目标不同的外观，颜色，大小以及在成像时光照，遮挡等具有挑战性的问题，目标检测一直处于不断的优化和研究中。</p>
<p><strong>目标检测算法的分类</strong></p>
<p>传统的目标检测算法有：SIFT（尺度不变特征变换）、HOG（方向梯度直方图）、DPM（一种基于组件的图像检测算法）等。</p>
<p>基于深度学习的目标检测算法可以分为两类：二阶算法（Two Stage）和一阶算法（One Stage）。</p>
<ul>
<li>二阶算法：先生成区域候选框，再通过卷积神经网络进行分类和回归修正。常见算法有 RCNN、SPPNet、Fast RCNN，Faster RCNN 和 RFCN 等。二阶算法检测结果更精确。</li>
<li>一阶算法：不生成候选框，直接在网络中提取特征来预测物体的分类和位置。常见算法有 SSD、YOLO系列 和 RetinaNet 等。一阶算法检测速度与更快。</li>
</ul>
<h2 id="二r-cnnregion-with-cnn-feature">二、R-CNN(Region with CNN feature)</h2>
<h3 id="rcnn简介">2.1 RCNN简介</h3>
<p>RCNN（Region with CNN feature）算法出现于2014年，是将深度学习应用到目标检测领域的开山之作，凭借卷积神经网络出色的特征提取能力，大幅度提升了目标检测的效果。</p>
<p>RCNN在PASCAL VOC2012数据集上将检测率从35.1%提升至53.7%，使得CNN在目标检测领域成为常态，也使得大家开始探索CNN在其他计算机视觉领域的巨大潜力。</p>
<p>论文：《 Rich feature hierarchies for accurate object detection and semantic segmentation 》 作者：Ross Girshick 源码（作者提供）：https://github.com/rbgirshick/rcnn</p>
<h3 id="rcnn算法流程">2.2 RCNN算法流程</h3>
<p>RCNN继承了传统目标检测的思想，将目标检测当做分类问题进行处理，先提取一系列目标的候选区域，然后对候选区域进行类。</p>
<p><strong>RCNN算法流程可分为4个步骤</strong></p>
<ul>
<li><p>1、一张图像生成1K~2K个<strong>候选区域</strong></p></li>
<li><p>2、对每个候选区域，使用深度网络<strong>提取特征</strong></p></li>
<li><p>3、特征送入每一类的<strong>SVM 分类器</strong>，判别是否属于该类</p></li>
<li><p>4、使用回归器<strong>精细修正</strong>候选框位置</p></li>
</ul>
<p><strong>（1）生成候选区域：</strong></p>
<p>采用一定区域候选算法（如 Selective Search）将图像分割成小区域，然后合并包含同一物体可能性高的区域作为候选区域输出，这里也需要采用一些合并策略。不同候选区域会有重合部分，如下图所示（黑色框是候选区域）：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211131947294.png" style="zoom:67%;" /></p>
<p>​</p>
<p>要生成1000-2000个候选区域（以2000个为例），之后将每个区域进行归一化，即缩放到固定的大小（227*227）.</p>
<p><strong>（2）对每个候选区域用CNN进行特征提取：</strong></p>
<p>这里要事先选择一个预训练神经网络（如AlexNet、VGG），并重新训练全连接层，即 fintune 技术的应用。</p>
<p>将候选区域输入训练好的AlexNet CNN网络（去除最后<code>(4096,1000)</code>的全连接层），得到固定维度的特征输出（4096维），得到2000×4096的特征矩阵。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211131951698.png" /></p>
<p><strong>（3）用每一类的SVM分类器对CNN的输出特征进行分类：</strong></p>
<p>此处以PASCAL VOC数据集为例，该数据集中有20个类别，因此设置20个SVM分类器。</p>
<p>将2000×4096的特征与20个SVM组成的权值矩阵4096×20相乘，获得2000×20维矩阵，<strong>表示2000个候选区域分别属于20个分类的概率</strong>，因此矩阵的每一行之和为1。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211131951222.png" /></p>
<p>权值矩阵相乘示例：</p>
<ul>
<li>假设第一列预测为猫，则最后得到<code>2000x20</code>中第一列第一元素表示输入矩阵中第一个候选框(第一行)预测为猫的概率。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211131953470.png" /></p>
<p>分别对上述2000×20维矩阵中<font color="#FF0000"><strong>每一列（即每一类）</strong></font>进行<strong>非极大值抑制剔除重叠建议框</strong>，得到该列即该类中概率最大的一些候选框。</p>
<p>非极大值抑制剔除重叠建议框的具体实现方法是：</p>
<p>第一步：定义 IoU 指数(Intersection over Union)，即 (A∩B) / (AUB) ，即AB的重合区域面积与AB总面积的比。直观上来讲 IoU 就是表示AB重合的比率， IoU越大说明AB的重合部分占比越大，即A和B越相似。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211131956072.png" /></p>
<p>第二步：<strong>找到每一类中2000个候选区域中概率最高的区域，计算其他区域与该区域的IoU值，删除所有IoU值大于阈值的候选区域。依次循环</strong>，这样可以只保留少数重合率较低的候选区域，去掉重复区域。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211131958698.png" style="zoom:50%;" /></p>
<p>​ 比如下面的例子，A是向日葵类对应的所有候选框中概率最大的区域，B是另一个区域，计算AB的IoU，其结果大于阈值，那么就认为AB属于同一类（即都是向日葵），所以应该保留A，删除B，这就是非极大值抑制。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211131958456.png" style="zoom:67%;" /> ​</p>
<p><strong>（4）使用回归器精修候选区域的位置：</strong></p>
<p>通过 Selective Search算法得到的候选区域位置不一定准确，因此用20个回归器对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的目标区域。具体实现如下：</p>
<p>如图，黄色框表示候选区域 Region Proposal,绿色窗口表示实际区域Ground Truth（人工标注的），红色窗口表示 Region Proposal 进行回归后的预测区域，可以用最小二乘法解决线性回归问题。</p>
<p>通过回归器可以得到候选区域的四个参数，分别为：候选区域的x和y的偏移量，高度和宽度的缩放因子。可以通过这四个参数对候选区域的位置进行精修调整，就得到了红色的预测区域。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132004039.png" style="zoom:50%;" /></p>
<h3 id="rcnn流程图">2.3 RCNN流程图</h3>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132005846.png" /></p>
<p>​</p>
<h3 id="rcnn框架">2.4 RCNN框架</h3>
<p>RCNN由四个部分组成：SS算法、CNN、SVM、bbox regression。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132006465.png" style="zoom:50%;" /></p>
<p>​</p>
<h3 id="rcnn的缺点">2.5 RCNN的缺点</h3>
<p><strong>（1）训练和测试速度慢，需要多步训练，非常繁琐。</strong></p>
<p>​ 测试一张图片约53s(CPU)。用Selective Search算法，提取候选框用时约2秒，一张图像内<strong>候选框之间存在大量重叠</strong>，提取特征操作冗余。</p>
<p><strong>（2）由于涉及分类中的全连接网络，因此输入CNN的候选区域尺寸是固定的，造成了精度的降低。</strong></p>
<p>（3）候选区域需要提前提取并保存，<strong>占用的空间很大。</strong>对于非常深的网络，如VGG16，从VOCO7训练集上的5000张图片上提取的特征需要数百GB的存储空间，这个问题是致命的。</p>
<p>RCNN 成为了当时目标检测领域的SOAT算法，尽管现在已经不怎么用了，但其思想仍然值得我们借鉴和学习。</p>
<hr />
<h2 id="三fast-rcnn">三、Fast RCNN</h2>
<h3 id="fast-rcnn简介">3.1 Fast RCNN简介</h3>
<p>在RCNN之后，SPPNet解决了重复卷积计算和固定输出尺寸两个问题，SPPNet的主要贡献是在整张图像上计算全局特征图，然后对于特定的建议候选框，只需要在全局特征图上取出对应坐标的特征图就可以了。但SPPNe仍然存在一些弊端，如仍然需要将特征保存在磁盘中，速度还是很慢。</p>
<p>Fast RCNN算法是2015年Ross Girshick（还是这位大佬）提出的，在RCNN和SPPNet的基础上进行了改进。根据名字就知道，Fast RCNN更快更强。其训练步骤实现了端到端，基于VGG16网络，其训练速度比RCNN快了9倍，测试速度快了213倍，在PASCAL VOC2012数据集达到了68.4%的准确率。</p>
<p>论文：《Fast R-CNN》 源码（作者提供）：https://github.com/rbgirshick/fast-rcnn</p>
<h3 id="fast-rcnn算法流程">3.2 Fast RCNN算法流程</h3>
<p>（1）一张图像生成1K~2K个<strong>候选区域</strong>(使用Selective Search算法，简称SS算法)，我们将某个候选区域称为ROI区域。</p>
<p>（2）将图像输入网络得到相应的<strong>特征图</strong>，将SS算法生成的候选框投影到特征图上获得相应的<strong>特征矩阵</strong>。</p>
<blockquote>
<p>R-CNN vs Fast-RCNN区别：</p>
<p>R-CNN依次将2000个候选框区域输入卷积神经网络得到特征，存在大量冗余，提取时间很长。</p>
<p>Fast-RCNN将<strong>整张图像送入网络，一次性计算整张图像特征</strong>，这样就可以根据特征图的坐标获得想要的候选区域的<strong>特征图</strong>，<strong>不需要重复计算。</strong></p>
</blockquote>
<p>（3）将每个特征矩阵通过 ROI pooling 层缩放到<strong>7x7大小的特征图</strong>，接着将特征图展平通过一系列全连接层得到预测结果</p>
<blockquote>
<p>前面讲到RCNN需要将候选区域归一化到固定大小（227x227），而Fast RCNN并不需要这样的操作，<strong>Fast RCNN通过pooling层将每个候选区域的特征图都变为7x7。</strong></p>
</blockquote>
<p>（4）将特征图展平（reshape）为向量，通过一系列全连接层和 softmax得到预测结果。</p>
<h3 id="fast-rcnn算法流程图">3.3 Fast RCNN算法流程图</h3>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132030849.png" style="zoom:80%;" /></p>
<p>​ 如图，将一张图像输入到 Deep ConvNet 中得到图像的特征图，根据ROI区域与整体图像的坐标映射关系 （RoI Projection）进行特征映射（Conv feature map），能够得到每一个候选区域（ROI区域）的特征矩阵。</p>
<p>​ 将每一个特征矩阵通过RoI pooling layer，池化到固定尺寸（7*7），然后展平为向量（vector）。再经过两个全连接层（fully connected layers,FC），得到ROI特征向量（ROI feature vector）。</p>
<p>​ 之后 ROI feature vector 并联两个FC，其中一个用于目标概率预测（softmax），另一个用于边界框参数的回归（bbox regressor，bbox 表示 bounding box）。</p>
<p><strong>1、一次性计算整张图像特征</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132015408.png" style="zoom: 50%;" /></p>
<p><strong>2、训练数据的采样（正样本和负样本）</strong></p>
<p>在一个batch随机选择一半正样本，一半负样本，防止模型将背景当作目标进行训练。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132021525.png" style="zoom: 67%;" /></p>
<p><strong>3、Rol Pooling Layer</strong></p>
<p>​ 前面讲到RCNN需要将候选区域归一化到固定大小（227x227），而Fast RCNN并不需要这样的操作，Fast RCNN通过pooling层将每个候选区域的特征图都变为7x7，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132024056.png" style="zoom: 50%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132012940.png" style="zoom:50%;" /></p>
<h4 id="softmax-分类器">3.3.1 softmax 分类器</h4>
<p>softmax 分类器输出N+1个类别的概率，如下图所示。PASCAL VOC2012数据集中有20个分类，因此会输出21个类别的概率，其中第一个为背景概率，其余20个为每个分类的概率。所以softmax的FC中有N+1个节点。</p>
<p><strong>4、分类器</strong></p>
<p>输出N+1个类别的概率（N为检测目标的种类, 1为背景）共N+1个节点</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132027966.png" style="zoom: 50%;" /></p>
<h4 id="边界框回归器bbox-regressor">3.3.2 边界框回归器（bbox regressor ）</h4>
<p>一幅图片中会画出N+1个分类的候选框，每个候选框都有x、y、w、d四个参数，所以 bbox regressor 的FC中有 4(N+1) 个节点。</p>
<p><strong>5、边界框回归器</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132028230.png" alt="、" style="zoom:67%;" /></p>
<p>那么如何使用边界框回归参数预测边界框？<strong>边界框参数回归的计算方法：</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132033252.png" style="zoom: 67%;" /></p>
<h3 id="fast-rcnn-中-loss-的计算">3.4 Fast RCNN 中 loss 的计算</h3>
<p>因为在Fast RCNN 中需要预测N+1个类别的概率以及边界框的回归参数，所以定义了两个损失函数：分类损失和边界框回归损失。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132035630.png" style="zoom: 67%;" /></p>
<p>分类损失： <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132036778.png" style="zoom:50%;" /></p>
<p>边界框回归损失： <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132037767.png" style="zoom: 67%;" /></p>
<h3 id="fast-rcnn框架">3.5 Fast RCNN框架</h3>
<p>首先回顾一下RCNN的框架：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132040828.png" style="zoom: 67%;" /></p>
<p>​</p>
<p>RCNN由四部分组成，因此需要多步训练，非常繁琐。</p>
<p><strong>Fast RCNN将CNN特征提取，SVM边界框分类，bbox regression边界框回归三部分结合到了一起，都融合到同一个CNN中。</strong>那么Fast RCNN就只有两部分了：先通过SS算法获取候选框，再通过CNN完成特征提取、分类和边界框回归。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132040940.png" style="zoom: 80%;" /></p>
<p>​</p>
<p>那么自然而然的，在接下来的 Faster RCNN 算法中，就要考虑如何将 Region proposal 也融入到CNN中，将整个算法合并为一个网络，这样就可以实现端到端的目标检测。</p>
<h3 id="fast-rcnn的缺点">3.5 Fast RCNN的缺点</h3>
<p>1、尽管用到了GPU，但Region proposal还是在CPU上实现的。在CPU中，用SS算法提取一张图片的候选框区域大约需要2s，而完成整个CNN则只需要0.32s，因此Fast RCNN 计算速度的瓶颈是Region proposal。</p>
<p>2、无法满足实时应用，没有真正实现端到端训练测试；</p>
<h2 id="四faster-rcnn">四、Faster RCNN</h2>
<h3 id="faster-rcnn简介">4.1 Faster RCNN简介</h3>
<p>Faster RCNN 是作者 Ross Girshick 继 RCNN 和 Fast RCNN后的又一力作。同样使用 VGG16作为网络的backbone，推理速度在GPU上达到5fps(包括候选区域的生成)，准确率也有进一步的提升。在2015年的ILSVRC以及cOco竞赛中获得多个项目的第一名。</p>
<p>论文：《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》</p>
<p>论文地址：https://arxiv.org/abs/1506.01497</p>
<h3 id="faster-rcnn算法流程">4.2 Faster RCNN算法流程</h3>
<p><strong>算法流程：</strong></p>
<p>（1）将图像输入网络得到相应的<strong>特征图</strong>。</p>
<p>（2）使用RPN网络生成候选框，将RPN生成的候选框投影到特征图上获得ROI区域的<strong>特征矩阵</strong>。</p>
<p>（3）将每个ROI区域的特征矩阵通过 ROI pooling 层缩放到7x7大小的特征图，接着将特征图展平为vector，之后通过一系列全连接层得到预测结果。</p>
<blockquote>
<blockquote>
<p><font color = "#FF0000"><strong>Faster RCNN = RPN + Fast RCNN</strong></font></p>
</blockquote>
<p>RPN 是指 Region Proposal Network，建议区域生成网络。 Faster RCNN 中用 RPN 来代替了 Fast RCNN 中的SS算法。其余部分与Fast RCNN相同。</p>
</blockquote>
<p><strong>网络结构：</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132103453.png" style="zoom:80%;" /></p>
<h3 id="rpn网络">4.2 RPN网络</h3>
<h4 id="rpn网络结构">4.2.1 RPN网络结构</h4>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132104079.png" style="zoom:80%;" /></p>
<blockquote>
<p>对于特征图上的每个3x3的滑动窗口，计算出滑动窗口中心点对应原始图像上的中心点，并计算出k个anchor boxes(注意和proposal的差异)。</p>
</blockquote>
<p>​ 图中的 conv feature map 是图像输入网络得到相应的<strong>特征图</strong>，<strong>通过sliding window处理之后产生一个256d的一维向量</strong>（256个是因为使用了ZF网络作为FasterRCNN的backbone，如果使用VGG16作为backbone，应该输出512）。该向量通过两个全连接层，<strong>分别输出分类概率scores和边界框回归参数coordinates</strong>，其中k是指 k个 anchor boxes，2k个scores是每个 anchor box 分别为前景和背景的概率（注意这里只区分前景和背景，所有的类别都归为前景），4k个coordinates是因为每个anchor box 有四个参数。</p>
<h4 id="anchor的定义">4.2.2 anchor的定义</h4>
<p>那么什么是 anchor呢？</p>
<p>首先要明确，anchor不是候选框（Proposal），后面会提到二者的区别。</p>
<p><strong>我们在特征图中找一个点，就可以在原图中找到对应的一个像素点，以该像素点为中心，画出9个不同大小和长宽比的框，称为anchor 。</strong>如下图所示，这些anchor里面可能包含目标，也可能没有目标。因为我们在一张图中想找的的目标的大小和长宽比并不是固定的，所以这里用9个不同大小和长宽比的anchor来进行预测。</p>
<p>举例：滑动窗口找到原始图像车的坐标，然后生成4(k)个anchor boxes,同时生成8个(2k)个scores，分别表示是背景和前景的概率（此时未进行分类，只表示前景还是背景）</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132109954.png" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132117312.png" style="zoom: 67%;" /></p>
<p>那么为什么是9个anchor呢？</p>
<p>论文中给出了每个anchor的面积和长宽比：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132119231.png" /></p>
<p>所以特征图中的每个位置在原图中都会生成 3x3=9 个anchor，如下图所示，蓝色的三个anchor是面积为128x128的，红色是面积为256x256的，绿色是512x512的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132120976.png" style="zoom:50%;" /></p>
<h4 id="rpn生成proposal的过程">4.2.3 RPN生成proposal的过程</h4>
<p>对于一张 1000x600x3 的图像（三通道），用3x3的卷积核进行特征提取得到60x40的特征图，则共有 60x40x9 （约2w个）个anchor。<strong>忽略超过图片边界的 anchor 后</strong>，剩下约 6000 个anchor。</p>
<p>对于这6000 个 anchor，<strong>通过RPN生成的边界框回归参数将每个 anchor 调整为proposal</strong>（前面提到了每个anchor经过RPN都输出2个概率和4个边界框回归参数），这里就能看到anchor和proposal的区别。这个过程就是 RPN 生成候选框的过程。</p>
<p>RPN 生成的候选框之间存在大量重叠，<strong>基于候选框的cls得分，采用非极大值抑制，IoU设为0.7</strong>，这样每张图片只剩下 2000 个候选框。</p>
<h4 id="rpn中-loss-的计算">4.2.4 RPN中 loss 的计算</h4>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132128248.png" style="zoom:50%;" /></p>
<p>关于分类损失的计算：</p>
<p>1）使用Softmax交叉熵损失</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132130360.png" style="zoom: 50%;" /></p>
<p>2）使用二分类交叉熵损失</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132133715.png" /></p>
<p>关于边界框回归损失的计算：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132135902.png" style="zoom:50%;" /></p>
<h3 id="faster-rcnn训练">4.3 Faster RCNN训练</h3>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132137239.png"  /></p>
<h3 id="faster-rcnn框架">4.4 Faster RCNN框架</h3>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132123057.png" style="zoom:50%;" /></p>
<p>Faster RCNN 在Fast RCNN的基础上更进一步，将候选框生成也融入到CNN网络中，使得 <strong>候选框生成、特征提取、候选框分类、候选框边界回归</strong> 这四大部分都结合在一个CNN网络中，避免了分步训练，实现了真正<strong>端到端的目标检测</strong>。</p>
<h2 id="五三者的比较rcnnfast-rcnn-faster-rcn">五、三者的比较：RCNN、Fast RCNN、 Faster RCN</h2>
<p>三者都是二阶算法，网络框架比较：</p>
<p>​</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132124451.png" /></p>
<p>可以看到，从RCNN、Fast RCNN 到 Faster RCNN，网络框架越来越简洁，目标检测效果也越来越好。</p>
<p>三者的优缺点比较：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211132126081.png" /></p>
<blockquote>
<p>参考：https://blog.csdn.net/qq_43799400/article/details/123127851</p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/DeepLearning/model/objectdetection/network-RCNNtheory/">http://unicorn-acc.github.io/DeepLearning/model/objectdetection/network-RCNNtheory/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Algorithm/LC-501-1000/LC-791/"><img class="prev-cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">LC-791.自定义字符串排序</div></div></a></div><div class="next-post pull-right"><a href="/Java_notes/java/Java-13Collection/"><img class="next-cover" src="https://w.wallhaven.cc/full/1p/wallhaven-1pjml1.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">JavaSE_13_集合</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/DeepLearning/CAM/" title="CV可解释性分析_CAM热力图"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-03</div><div class="title">CV可解释性分析_CAM热力图</div></div></a></div><div><a href="/DeepLearning/Grad-CAM/" title="CV可解释性分析_Grad-CAM"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-03</div><div class="title">CV可解释性分析_Grad-CAM</div></div></a></div><div><a href="/DeepLearning/dataset/CIFAR10/" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/DeepLearning/dataset/Fashion-MNIST/" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/DeepLearning/dataset/PASCALVOC2010/" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/DeepLearning/dataset/MSCOCO/" title="目标检测&#x2F;分割&#x2F;图像描述_MS COCO数据集及pycocotools的使用"><img class="cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割&#x2F;图像描述_MS COCO数据集及pycocotools的使用</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D"><span class="toc-text">一、目标检测的基本介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8Cr-cnnregion-with-cnn-feature"><span class="toc-text">二、R-CNN(Region with CNN feature)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rcnn%E7%AE%80%E4%BB%8B"><span class="toc-text">2.1 RCNN简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rcnn%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-text">2.2 RCNN算法流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rcnn%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="toc-text">2.3 RCNN流程图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rcnn%E6%A1%86%E6%9E%B6"><span class="toc-text">2.4 RCNN框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rcnn%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="toc-text">2.5 RCNN的缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89fast-rcnn"><span class="toc-text">三、Fast RCNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fast-rcnn%E7%AE%80%E4%BB%8B"><span class="toc-text">3.1 Fast RCNN简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fast-rcnn%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-text">3.2 Fast RCNN算法流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fast-rcnn%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="toc-text">3.3 Fast RCNN算法流程图</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#softmax-%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-text">3.3.1 softmax 分类器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8bbox-regressor"><span class="toc-text">3.3.2 边界框回归器（bbox regressor ）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fast-rcnn-%E4%B8%AD-loss-%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-text">3.4 Fast RCNN 中 loss 的计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fast-rcnn%E6%A1%86%E6%9E%B6"><span class="toc-text">3.5 Fast RCNN框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fast-rcnn%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="toc-text">3.5 Fast RCNN的缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9Bfaster-rcnn"><span class="toc-text">四、Faster RCNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#faster-rcnn%E7%AE%80%E4%BB%8B"><span class="toc-text">4.1 Faster RCNN简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#faster-rcnn%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-text">4.2 Faster RCNN算法流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rpn%E7%BD%91%E7%BB%9C"><span class="toc-text">4.2 RPN网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#rpn%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">4.2.1 RPN网络结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#anchor%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-text">4.2.2 anchor的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rpn%E7%94%9F%E6%88%90proposal%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-text">4.2.3 RPN生成proposal的过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rpn%E4%B8%AD-loss-%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-text">4.2.4 RPN中 loss 的计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#faster-rcnn%E8%AE%AD%E7%BB%83"><span class="toc-text">4.3 Faster RCNN训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#faster-rcnn%E6%A1%86%E6%9E%B6"><span class="toc-text">4.4 Faster RCNN框架</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E4%B8%89%E8%80%85%E7%9A%84%E6%AF%94%E8%BE%83rcnnfast-rcnn-faster-rcn"><span class="toc-text">五、三者的比较：RCNN、Fast RCNN、 Faster RCN</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (50)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (9)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/算法刷题记录/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍💻 算法刷题记录 (55)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><!-- hexo injector body_end end --></body></html>