<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>目标检测-03-RetinaNet | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:type" content="article"><meta property="og:title" content="目标检测-03-RetinaNet"><meta property="og:url" content="http://unicorn-acc.github.io/posts/60257.html"><meta property="og:site_name" content="Miraclo’s Blog"><meta property="og:description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg"><meta property="article:published_time" content="2022-11-17T17:03:30.000Z"><meta property="article:modified_time" content="2022-11-18T07:19:39.444Z"><meta property="article:author" content="Miraclo"><meta property="article:tag" content="DeepLearning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/posts/60257"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"prismjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:2e3},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:500,languages:{author:"作者: Miraclo",link:"链接: ",source:"来源: Miraclo’s Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"目标检测-03-RetinaNet",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-11-18 07:19:39"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouth.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">目标检测-03-RetinaNet</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2022-11-17T17:03:30.000Z" title="发表于 2022-11-17 17:03:30">2022-11-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/2%E3%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AF%87/">2、目标检测篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="目标检测-03-RetinaNet"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>参考内容来自霹雳吧啦Wz</p><p>up主的b站链接：https://space.bilibili.com/18161609/channel/index</p><p>up主的github：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</p><p>up主的CSDN博客：https://blog.csdn.net/qq_37541097/article/details/103482003</p></blockquote><h2 id="retinanet">1. RetinaNet</h2><p>RetinaNet 原始论文为发表于 2017 ICCV 的 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.02002">Focal Loss for Dense Object Detection</a>。one-stage 网络首次超越 two-stage 网络，拿下了 best student paper，仅管其在网络结构部分并没有颠覆性贡献。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171705478.png" style="zoom:50%"> <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171706502.png" style="zoom:33%"></p><h3 id="backbone-部分">1.1 backbone 部分</h3><p>RetinaNet 网络详细结构如下所示，与 FPN 不同，<strong>FPN 会使用 C2，而 RetinaNet 则没有，</strong>因为 C2 生成的 P2 会占用更多的计算资源，所以作者直接从 C3 开始生产 P3。关于 backbone 部分和 FPN 部分基本类似，所以具体细节部分就不细讲了。<strong>第二个不同点在于 P6 这个地方</strong>，原论文是在 C5 的基础上生成的（最大池化下采样得到的），这里是根据 pytorch 官方的实现绘制的，是通过 $ 3 $ 的卷积层来实现下采样的。第三个不同是 FPN 是从 P2 到 P6，而 <strong>RetinaNet 是从 P3 到 P7。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171706923.png" style="zoom:67%"></p><p>上图也给出了 P3 到 P7 上使用的 scale 和 ratios。在 FPN 中每个特征层上使用了一个 scale 和三个 ratios。<strong>在 RetinaNet 中是三个 scale 和三个 ratios 共计 9 个 anchor</strong>。 注意，这里 scale 等于 32 对应的 anchor 的面积是 32 的平方的。所以在 RetinaNet 中最小的 scale 是 32，最大的则是接近 813。</p><h3 id="预测器部分">1.2 预测器部分</h3><p>由于 RetinaNet 是一个 one-stage 的网络，所以不用 ROI pooling，直接使用如下图所示的<strong>权重共享的基于卷积操作的预测器</strong>。预测器分为两个分支，分别预测每个 anchor 所属的类别，以及目标边界框回归参数。最后的 kA 中 k 是检测目标的类别个数，注意这里的 <strong>k 不包含背景类别</strong>，对于 PASCAL VOC 数据集的话就是 20。这里的 A 是预测特征层在每一个位置生成的 anchor 的个数，在这里就是 9。（现在基本都是这样的<strong>类别不可知</strong> anchor 回归参数预测，也可以理解为每一类共享了同一个 anchor 回归参数预测器） <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171707144.png"></p><h3 id="正负样本匹配">1.3 正负样本匹配</h3><p>针对每一个 anchor 与事先标注好的 GT box 进行比对，如果 iou 大于 0.5 则是正样本，如果某个 anchor 与所有的 GT box 的 iou 值都小于 0.4，则是负样本。其余的进行舍弃。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171710727.png" style="zoom:67%"></p><h3 id="损失计算">1.4 损失计算</h3><p>本文一个核心的贡献点就是 focal loss。总损失依然分为两部分，一部分是分类损失，一部分是回归损失。Focal loss 比较独特的一个点就是<strong>正负样本都会来计算分类损失，然后仅对正样本进行回归损失的计算</strong>。回归损失在 SSD 以及 Faster R-CNN 中都有讲解，这里就不细说了。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171710927.png"></p><h2 id="focal-loss">2. Focal Loss</h2><p>为了实现正负样本的比例均衡，不至于整个训练过程被负样本“淹没”，一般采取抽样的方法，将正负样本比例控制在1:3，从而在正负样本间保持合理的比例。因为 one-stage 只有一个阶段，产生的候选框相比 two-stage 要多太多。通常需要大约100K个位置（例如 SSD 的 8700+ 个位置），且这里面正样本几个十几个，少之又少。即使你抽样了，最后在训练过程中，还是会惊奇的发现，整个过程还是被大量容易区分的负样本，也就是背景所主导。Focal loss 则是一个动态缩放的交叉熵损失，一言以蔽之，通过一个动态缩放因子，可以动态降低训练过程中易区分样本的权重，从而将 loss 的重心快速聚焦在<strong>那些难区分的样本</strong>上 (注意：难以区分的样本不一定是正样本)。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171711629.png" style="zoom:67%"></p><h3 id="cross-entropy-loss">2.1 Cross Entropy Loss</h3><p>Focal loss的起源是二分类交叉熵 CE，它的形式是这样的：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171715077.png"></p><p>在上式中， y 的取值有 1 和 -1 两种，代表前景和背景。p 的取值范围是 [0,1]，是模型预测的属于前景的概率，为了表示方便，定义一个 $ P_t$，如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171714182.png"></p><p>综合(1)(2)两个式子就可以得到：</p><p><span class="math inline">\(CE(p,y) = CE(p_t) = −\log(p_t)\)</span></p><p>CE 曲线就是下图中的蓝色曲线，可以看到，相比较其他曲线，蓝色线条是变化最平缓的，即使在$ p&gt;0.5$ (已经属于很好区分的样本)的情况下，它的损失相对于其他曲线仍然是高的，尽管它相对于自己前面的已经下降很多了，但是当数量巨大的易区分样本损失相加，就会主导我们的训练过程，所以要进一步增加前后损失的大小比。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171715581.png" style="zoom:50%"></p><h3 id="balanced-cross-entropy">2.2 Balanced Cross Entropy</h3><p><strong>Balanced Cross Entropy</strong> 是常见的<strong>解决类不平衡的方法</strong>，其思想是引入一个权重因子<span class="math inline">\(\alpha \in [0,1]\)</span>，当类标签是 1 时，权重因子是 α ，当类标签是 -1 时，权重因子是 1 − α 。同样为了表示方便，用 <span class="math inline">\(\alpha_t\)</span> 表示权重因子，那么此时的损失函数被改写为：</p><p><span class="math inline">\(CE(p,y) = −\alpha_t\log(p_t)\)</span></p><h3 id="focal-loss-1">2.3 Focal Loss</h3><p>​ Balanced Cross Entropy 解决了正负样本的比例失衡问题（positive/negative examples），但是<strong>这种方法仅仅解决了正负样本之间的平衡问题，并没有区分简单还是难分样本（easy/hard examples）</strong>。当容易区分的负样本的泛滥时，整个训练过程都是围绕容易区分的样本进行（小损失积少成多超过大损失），而被忽略的难区分的样本才是训练的重点。作者新引入了一个调制因子，公式如下：</p><p><span class="math inline">\(FL(p_t) = −(1-p_t)^{\gamma}\log(p_t)\)</span></p><p>其中 <span class="math inline">\(\gamma\)</span> 也是一个参数，范围在 [0,5]。观察上式可以发现，当 <span class="math inline">\(P_t\)</span>趋向于 1 时，说明该样本比较容易区分，整个调制因子<span class="math inline">\((1-p_t)^{\gamma}\)</span>是趋向于 0 的，也就是 loss 的贡献值会很小；如果某样本被错分，<span class="math inline">\(p_t\)</span> 很小，那么此时调制因子 <span class="math inline">\((1-p_t)^{\gamma}\)</span> 是趋向 1 的，对 loss 没有大的影响（相对于基础的交叉熵），<strong>参数<span class="math inline">\(\gamma\)</span> 能够调整权重衰减的速率</strong>。从下面这张图可以看出，当<span class="math inline">\(\gamma = 0\)</span>的时候，FL 就是原来的交叉熵损失 CE，随着 <span class="math inline">\(\gamma\)</span> 的增大，调整速率也在变化，实验表明，在<span class="math inline">\(\gamma =2\)</span>时，效果最佳。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171721901.png" style="zoom:67%"></p><p>结合正负样本平衡以及难易样本平衡，最终的 Focal loss 形式如下：</p><p><span class="math inline">\(FL(p_t) = −\alpha_t(1-p_t)^{\gamma}\log(p_t)\)</span></p><p>它的功能可以解释为：<strong>通过 <span class="math inline">\(α_t\)</span>​ 可以抑制正负样本的数量失衡，通过 <span class="math inline">\(\gamma\)</span> 可以控制简单/难区分样本数量失衡。</strong></p><p>对于 Focal loss，总结如下：</p><ul><li>无论是前景类还是背景类，<span class="math inline">\(p_t\)</span> 越大，权重<span class="math inline">\((1-p_t)^{\gamma}\)</span> 就越小，即<strong>简单样本的损失可以通过权重进行抑制</strong>；</li><li><strong><span class="math inline">\(\alpha_t\)</span> 用于调节正负样本损失之间的比例</strong>，前景类别使用 <span class="math inline">\(\alpha_t\)</span> 时，对应的背景类别使用 <span class="math inline">\(1-\alpha_t\)</span> ;</li><li><span class="math inline">\(\gamma\)</span>和 <span class="math inline">\(\alpha_t\)</span> 的最优值是相互影响的，所以在评估准确度时需要把两者组合起来调节。作者在论文中给出<span class="math inline">\(\gamma = 2,\alpha_t = 0.25\)</span> 时，ResNet-101+FPN 作为 backbone 的 RetinaNet 有最优的性能。这里 <span class="math inline">\(\alpha_t = 0.25\)</span> 正样本的权重小，负样本的权重大有利于压低负样本的分类损失，尽可能将负样本的损失压低。</li></ul><h2 id="创新点与总结">创新点与总结</h2><p>RetinaNet是何凯明大神提出的一种网络，该网络结构采用FPN网络的结构，其主要创新点在于提出了一个新的损失函数Focal Loss，主要用于解决one-stage目标检测中正负样本极不平衡的问题。</p><p>主要内容与区别：</p><ul><li><strong>特征金字塔构建</strong></li></ul><p>​ 在ResNet结构上构建FPN，在P3~P7层上构建特征金字塔</p><ul><li><strong>anchor设计</strong></li></ul><p>​ 从P3到P7层的anchors的面积从32x32依次增加到512x512，每一层的anchors有三种长宽比{1:2,1:1, 2:1}；为了更加密集的覆盖在每层增加三种（<span class="math inline">\(2^0,2^{1/3},2^{2/3}\)</span>）size，一共9种anchor</p><ul><li><strong>网络的检测层</strong></li></ul><p>​ 网络的检测层分为分类子网络和回归子网络，详细介绍可以参考SSD网络结构</p><ul><li><strong>Focal Loss的超参数</strong></li></ul><p>​ 实验发现γ = 2效果最好，鲁棒区间是γ ∈ [0.5, 5]；权重参数α也有一个稳定的区间，但是与γ值互相影响，通常α随着γ的增大而轻微减少（γ = 2, α = 0.25效果最好）</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/posts/60257.html">http://unicorn-acc.github.io/posts/60257.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/693.html"><img class="prev-cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">小林计算机网络基础知识</div></div></a></div><div class="next-post pull-right"><a href="/posts/5932.html"><img class="next-cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/5074.html" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/posts/47625.html" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/posts/56670.html" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/posts/2490.html" title="图像分类_花分类数据集"><img class="cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-06</div><div class="title">图像分类_花分类数据集</div></div></a></div><div><a href="/posts/64179.html" title="图像分类_00_LeNet_Pytorch官方示例"><img class="cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_00_LeNet_Pytorch官方示例</div></div></a></div><div><a href="/posts/32696.html" title="目标检测的常见指标与COCO评价标准"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-12</div><div class="title">目标检测的常见指标与COCO评价标准</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#retinanet"><span class="toc-text">1. RetinaNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#backbone-%E9%83%A8%E5%88%86"><span class="toc-text">1.1 backbone 部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%99%A8%E9%83%A8%E5%88%86"><span class="toc-text">1.2 预测器部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E5%8C%B9%E9%85%8D"><span class="toc-text">1.3 正负样本匹配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97"><span class="toc-text">1.4 损失计算</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#focal-loss"><span class="toc-text">2. Focal Loss</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cross-entropy-loss"><span class="toc-text">2.1 Cross Entropy Loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#balanced-cross-entropy"><span class="toc-text">2.2 Balanced Cross Entropy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#focal-loss-1"><span class="toc-text">2.3 Focal Loss</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9%E4%B8%8E%E6%80%BB%E7%BB%93"><span class="toc-text">创新点与总结</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const n of document.querySelectorAll('script[type^="math/tex"]')){var e=!!n.type.match(/; *mode=display/),e=new t.options.MathItem(n.textContent,t.inputJax[0],e),a=document.createTextNode("");n.parentNode.replaceChild(a,n),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],insertScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t.hasAttribute("display")?btf.wrap(t,"div",{class:"mathjax-overflow"}):btf.wrap(t,"span",{class:"mathjax-overflow"})})},"",!1]}}};const a=document.createElement("script");a.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script src="/js/mouth.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (54)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (19)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(33.333333333333336% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>