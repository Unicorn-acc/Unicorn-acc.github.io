<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>图像分类_04_ResNet网络结构、BN层、迁移学习详解 | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:type" content="article"><meta property="og:title" content="图像分类_04_ResNet网络结构、BN层、迁移学习详解"><meta property="og:url" content="http://unicorn-acc.github.io/posts/41407.html"><meta property="og:site_name" content="Miraclo’s Blog"><meta property="og:description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://w.wallhaven.cc/full/gp/wallhaven-gpjj9q.jpg"><meta property="article:published_time" content="2022-11-10T14:48:11.000Z"><meta property="article:modified_time" content="2022-11-17T09:30:16.891Z"><meta property="article:author" content="Miraclo"><meta property="article:tag" content="DeepLearning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://w.wallhaven.cc/full/gp/wallhaven-gpjj9q.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/posts/41407"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"prismjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:2e3},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:500,languages:{author:"作者: Miraclo",link:"链接: ",source:"来源: Miraclo’s Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"图像分类_04_ResNet网络结构、BN层、迁移学习详解",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-11-17 09:30:16"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouth.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">171</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">32</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://w.wallhaven.cc/full/gp/wallhaven-gpjj9q.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">图像分类_04_ResNet网络结构、BN层、迁移学习详解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-10T14:48:11.000Z" title="发表于 2022-11-10 14:48:11">2022-11-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-17T09:30:16.891Z" title="更新于 2022-11-17 09:30:16">2022-11-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/1%E3%80%81%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%AF%87/">1、图像分类篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>26分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="图像分类_04_ResNet网络结构、BN层、迁移学习详解"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>参考内容来自霹雳吧啦Wz</p><p>up主的b站链接：https://space.bilibili.com/18161609/channel/index</p><p>up主的github：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</p><p>up主的CSDN博客：https://blog.csdn.net/qq_37541097/article/details/103482003</p></blockquote><h1 id="一resnet介绍">一、ResNet介绍</h1><p>原论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>（作者是CV大佬何凯明团队）</p><p>ResNet 网络是在 <strong>2015年</strong> 由微软实验室提出，斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO数据集中目标检测第一名，图像分割第一名。</p><p>在ResNet网络的创新点：</p><ul><li><p>搭建超深的网络结构（可突破1000层）</p></li><li><p>提出 <strong>Residual</strong> 结构（残差结构）</p></li><li><p>使用 <strong>Batch Normalization</strong> 加速训练（丢弃dropout）</p></li></ul><p>下图是ResNet34层模型的结构简图：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101451462.png"></p><h2 id="why-residual">1.1 Why residual?</h2><p>在ResNet网络提出之前，传统的卷积神经网络都是通过将一系列卷积层与池化层进行堆叠得到的。</p><p>一般我们会觉得网络越深，特征信息越丰富，模型效果应该越好。但是实验证明，当网络堆叠到一定深度时，会出现两个问题：</p><ol type="1"><li><p><strong>梯度消失或梯度爆炸</strong></p><blockquote><p>关于梯度消失和梯度爆炸，其实看名字理解最好： 若每一层的误差梯度小于1，反向传播时，网络越深，梯度越趋近于0 反之，若每一层的误差梯度大于1，反向传播时，网路越深，梯度越来越大</p></blockquote></li><li><p><strong>退化问题</strong>(degradation problem)：在解决了梯度消失、爆炸问题后，仍然存在深层网络的效果可能比浅层网络差的现象</p></li></ol><p>总结就是，<strong>当网络堆叠到一定深度时，反而会出现深层网络比浅层网络效果差的情况</strong>。</p><p>如下图所示，20层网络 反而比 56层网络 的误差更小：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101455581.png" style="zoom:50%"></p><ul><li>对于梯度消失或梯度爆炸问题，ResNet论文提出通过数据的预处理以及在网络中使用 <strong>BN</strong>（<strong>Batch Normalization</strong>）层来解决。</li><li>对于退化问题，ResNet论文提出了 <strong>residual结构</strong>（<strong>残差结构</strong>）来减轻退化问题，下图是使用residual结构的卷积网络，可以看到随着网络的不断加深，效果并没有变差，而是变的更好了。（虚线是train error，实线是test error）</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101456802.png" style="zoom:67%"></p><h2 id="what-is-residual">1.2 What is residual？</h2><p>为了解决深层网络中的退化问题，可以人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为 <strong>残差网络</strong> (<strong>ResNets</strong>)。</p><p>残差网络由许多隔层相连的神经元子模块组成，我们称之为 <strong>残差块</strong> <strong>Residual block</strong>。单个残差块的结构如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101500790.png" style="zoom:80%"> 上图中红色部分称为 <strong>short cut</strong> 或者 <strong>skip connection</strong>（也称 捷径分支)，<strong>直接建立</strong> $ a^{[l]}$与 <span class="math inline">\(a^{[l+2]}\)</span>之间的<strong>隔层联系</strong>。其前向传播的计算步骤为：</p><ul><li>$ z<sup>{[l+1]}=W</sup>{[l+1]}a^{[l]}+b$</li><li><span class="math inline">\(a^ {[l+1]}=g(z^{ [l+1]} )\)</span></li><li><span class="math inline">\(z ^{[l+2]} =W ^{[l+2]} a^{[l+1]}+b^{ [l+2]}\)</span></li><li>$ a^{ [l+2] }=g(z ^{[l+2]} +a^{ [l]} )$</li></ul><p><span class="math inline">\(a ^{[l]}\)</span>直接隔层与下一层的线性输出相连，与<span class="math inline">\(z^{[l+2]}\)</span> 共同通过激活函数（ReLU）输出 $ a^{[l+2]}$。</p><p>由多个 残差块 组成的神经网络就是 残差网络 。其结构如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101501945.png"></p><p>实验表明，这种模型结构对于训练非常深的神经网络,效果很好。另外，为了便于区分，我们把 <strong>非残差网络</strong> 称为 <strong>Plain Network。</strong></p><h2 id="resnet中的残差结构">1.3 ResNet中的残差结构</h2><p>实际应用中，残差结构的 short cut 不一定是隔一层连接，也可以中间隔多层，ResNet所提出的残差网络中就是隔多层。</p><p>跟VggNet类似，ResNet也有多个不同层的版本，而残差结构也有两种对应浅层和深层网络：</p><table><thead><tr class="header"><th></th><th>ResNet</th><th>残差结构</th></tr></thead><tbody><tr class="odd"><td>浅层网络</td><td>ResNet18/34</td><td>BasicBlock</td></tr><tr class="even"><td>深层网络</td><td>ResNet50/101/152</td><td>Bottleneck</td></tr></tbody></table><p>下图中左侧残差结构称为 <strong>BasicBlock</strong>，右侧残差结构称为 <strong>Bottleneck</strong></p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101458170.png" style="zoom:80%"></p><p>对于深层的 Bottleneck，<strong>1×1的卷积核起到降维和升维（特征矩阵深度）的作用</strong>，同时可以大大减少网络参数。</p><blockquote><p>可以计算一下，假设两个残差结构的输入特征和输出特征矩阵的深度都是256维，那么两个残差结构所需的参数为：</p><ul><li>左侧：<span class="math inline">\(3 \times 3 \times 256 \times 256+3 \times 3 \times 256 \times 256=1,179,648\)</span></li><li>右侧：$ 1 +3 +1 =69,632$</li><li>注：CNN参数个数 = 卷积核尺寸×卷积核深度 × 卷积核组数 = 卷积核尺寸 × 输入特征矩阵深度 × 输出特征矩阵深度</li><li>明显搭建深层网络时，使用右侧的残差结构更合适。</li></ul></blockquote><h2 id="降维时的-shortcut">1.4 降维时的 shortcut</h2><p>观察下图的 ResNet18层网络，可以发现有些残差块的 short cut 是实线的，而有些则是虚线的。</p><p>这些虚线的 short cut 上通过1×1的卷积核进行了维度处理（特征矩阵在长宽方向降采样，深度方向调整成下一层残差结构所需要的channel）。 <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101509558.png" style="zoom:33%"></p><h2 id="不同深度的resnet网络结构配置">1.5 不同深度的ResNet网络结构配置</h2><p>下图是原论文给出的不同深度的ResNet网络结构配置，注意表中的残差结构给出了主分支上卷积核的大小与卷积核个数，表中 残差块×N 表示将该残差结构重复N次。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101511122.png"></p><p>​ 原文的表注中已说明，conv3_x, conv4_x, conv5_x所对应的一系列残差结构的<strong>第一层残差结构</strong>都是虚线残差结构。因为这一系列残差结构的第一层都有<strong>调整输入特征矩阵shape</strong>的使命（将特征矩阵的高和宽缩减为原来的一半，将深度channel调整成下一层残差结构所需要的channel）</p><p>​ 需要注意的是，对于ResNet50/101/152，其实conv2_x所对应的一系列残差结构的第一层也是<strong>虚线残差结构</strong>，因为它需要调整输入特征矩阵的channel。根据表格可知通过3x3的max pool之后输出的特征矩阵shape应该是[56, 56, 64]，但conv2_x所对应的一系列残差结构中的实线残差结构它们期望的输入特征矩阵shape是[56, 56, 256]（因为这样才能保证输入输出特征矩阵shape相同，才能将捷径分支的输出与主分支的输出进行相加）。所以第一层残差结构需要将shape从[56, 56, 64] --&gt; [56, 56, 256]。注意，这里只调整channel维度，高和宽不变（而conv3_x, conv4_x, conv5_x所对应的一系列残差结构的第一层虚线残差结构不仅要调整channel还要将高和宽缩减为原来的一半）。</p><p>下面是 ResNet 18/34 和 ResNet 50/101/152 具体的实线/虚线残差结构图：</p><p>ResNet 18/34</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101513974.png" style="zoom:67%"></p><p>ResNet 50/101/152s</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101518156.png" style="zoom:50%"></p><p>这里第一个卷积核没有降维，只是提取特征，第二个卷积核（3x3,128,stride=2）进行了降维56--&gt;28</p><h1 id="二bn层batch-normalization">二、BN层（Batch Normalization）</h1><blockquote><p>https://blog.csdn.net/qq_37541097/article/details/104434557</p></blockquote><p><strong>Batch Normalization</strong>是google团队在2015年论文《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》提出的。通过该方法能够<strong>加速网络的收敛并提升准确率。</strong></p><p>​ 我们在图像预处理过程中通常会对图像进行标准化处理，这样能够加速网络的收敛，如下图所示，对于Conv1来说输入的就是满足某一分布的特征矩阵，但对于Conv2而言输入的feature map就不一定满足某一分布规律了（<strong>注意这里所说满足某一分布规律并不是指某一个feature map的数据要满足分布规律，理论上是指整个训练样本集所对应feature map的数据要满足分布规律</strong>）。<font color="#DC4040" size="4" face="黑体">而我们Batch Normalization的目的就是使我们的feature map满足均值为0，方差为1的分布规律。</font></p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101525789.png" style="zoom:50%"></p><ul><li><strong>计算同一个通道下一批数据的均值和方差，然后将输入参数减去均值除与方法得到标准化之后的参数，通过<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\beta\)</span>进行进一步调整。</strong></li></ul><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101528462.png" style="zoom:67%"></p><p>示例</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101532098.png" style="zoom:80%"></p><p>在我们训练网络的过程中，我们是通过一个batch一个batch的数据进行训练的，但是我们在预测过程中通常都是输入一张图片进行预测，此时batch size为1，如果在通过上述方法计算均值和方差就没有意义了。所以我们<strong>在训练过程中要去不断的计算每个batch的均值和方差，并使用移动平均(moving average)的方法记录统计的均值和方差</strong>，在训练完后我们可以近似认为所统计的均值和方差就等于整个训练集的均值和方差<strong>。然后在我们验证以及预测过程中，就使用统计得到的均值和方差进行标准化处理</strong>。</p><p><span class="math inline">\(\gamma\)</span>是用来调整数值分布的方差大小和<span class="math inline">\(\beta\)</span>是用来调节数值均值的位置。</p><p><span class="math inline">\(\gamma\)</span>的默认值是1和<span class="math inline">\(\beta\)</span>的默认值是0</p><h2 id="使用bn时需要注意的问题">使用BN时需要注意的问题</h2><p>（1）<strong>训练时要将traning参数设置为True，在验证时将trainning参数设置为False。</strong>在pytorch中可通过创建模型的model.train()和model.eval()方法控制。</p><p>（2）<strong>batch size尽可能设置大点，</strong>设置小后表现可能很糟糕，设置的越大求的均值和方差越接近整个训练集的均值和方差。</p><p>（3）<strong>建议将bn层放在卷积层（Conv）和激活层（例如Relu）之间，且卷积层不要使用偏置bias，因为没有用，</strong>参考下图推理，即使使用了偏置bias求出的结果也是一样的！</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101535490.png" style="zoom:50%"></p><p>最后给出李宏毅老师关于batch normalization的视频讲解：</p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av9770302?p=10">李宏毅深度学习(2017)_哔哩哔哩_bilibili</a></p><h1 id="三迁移学习">三、迁移学习</h1><p>迁移学习是一个比较大的领域，<strong>我们这里说的迁移学习是指神经网络训练中使用到的迁移学习</strong>。</p><p>在迁移学习中，我们希望利用源任务（Source Task）学到的知识帮助学习目标任务 (Target Task)。例如，一个训练好的图像分类网络能够被用于另一个图像相关的任务。再比如，一个网络在仿真环境学习的知识可以被迁移到真实环境的网络。迁移学习一个典型的例子就是载入训练好VGG网络，这个大规模分类网络能将图像分到1000个类别，然后把这个网络用于另一个任务，如医学图像分类。</p><p>为什么可以这么做呢？如下图所示，神经网络逐层提取图像的深层信息，这样，预训练网络就相当于一个特征提取器。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101538462.png" style="zoom:67%"></p><ul><li><strong>使用迁移学习的优势</strong>：</li></ul><ol type="1"><li>能够快速的训练出一个理想的结果</li><li>当数据集较小时也能训练出理想的效果</li></ol><p>   注意：<font color="#DC4040" size="4" face="黑体">使用别人预训练好的模型参数时，要注意别人的预处理方式。</font></p><ul><li><strong>常见的迁移学习方式</strong>：</li></ul><ol type="1"><li>载入权重后训练所有参数</li><li>载入权重后只训练最后几层参数</li><li>载入权重后在原网络基础上再添加一层全连接层，仅训练最后一个全连接层</li></ol><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211101543510.png" style="zoom:67%"></p><h1 id="四resnet网络pytorch实现">四、ResNet网络Pytorch实现</h1><h2 id="model模型">1、Model模型</h2><p>①残差块residual：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ResNet18/34的残差结构，用的是2个3x3的卷积</span>
<span class="token keyword">class</span> <span class="token class-name">BasicBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    expansion <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># 残差结构中，主分支的卷积核个数是否发生变化，不变则为1</span>

    <span class="token comment"># 输入通道，输出通道，downsample下采样，对应虚线残差结构</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> downsample<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BasicBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channel<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>out_channel<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>out_channel<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>out_channel<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>downsample <span class="token operator">=</span> downsample

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>downsample <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># 虚线残差结构，需要下采样</span>
            identity <span class="token operator">=</span> self<span class="token punctuation">.</span>downsample<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 捷径分支 short cut</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">+=</span> identity
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out

<span class="token comment"># ResNet50/101/152的残差结构，用的是1x1+3x3+1x1的卷积</span>
<span class="token keyword">class</span> <span class="token class-name">Bottleneck</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。
    但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2，
    这么做的好处是能够在top1上提升大概0.5%的准确率。
    可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch
    """</span>
    expansion <span class="token operator">=</span> <span class="token number">4</span> <span class="token comment"># 残差结构中第三层卷积核个数是第一/二层卷积核个数的4倍</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> downsample<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> width_per_group<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>out_channel <span class="token operator">*</span> <span class="token punctuation">(</span>width_per_group <span class="token operator">/</span> <span class="token number">64.</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> groups

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channel<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>width<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># squeeze channels</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>width<span class="token punctuation">)</span>
        <span class="token comment"># -----------------------------------------</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>width<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>width<span class="token punctuation">,</span> groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>width<span class="token punctuation">)</span>
        <span class="token comment"># -----------------------------------------</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>width<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>out_channel<span class="token operator">*</span>self<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># unsqueeze channels</span>
        self<span class="token punctuation">.</span>bn3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channel<span class="token operator">*</span>self<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>downsample <span class="token operator">=</span> downsample

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>downsample <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            identity <span class="token operator">=</span> self<span class="token punctuation">.</span>downsample<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">+=</span> identity
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>②ResNet定义</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># block = BasicBlock or Bottleneck</span>
    <span class="token comment"># block_num为残差结构中conv2_x~conv5_x中残差块个数，是一个列表</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 block<span class="token punctuation">,</span>
                 blocks_num<span class="token punctuation">,</span>
                 num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
                 include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                 groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 width_per_group<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ResNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>include_top <span class="token operator">=</span> include_top
        self<span class="token punctuation">.</span>in_channel <span class="token operator">=</span> <span class="token number">64</span>

        self<span class="token punctuation">.</span>groups <span class="token operator">=</span> groups
        self<span class="token punctuation">.</span>width_per_group <span class="token operator">=</span> width_per_group

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                               padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>include_top<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># output size = (1, 1)</span>
            self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span> nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>

    <span class="token comment"># channel为残差结构中第一层卷积核个数</span>
    <span class="token keyword">def</span> <span class="token function">_make_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> block_num<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        downsample <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token comment"># 对于18和34层的的ResNet会直接跳过</span>
        <span class="token comment"># ResNet50/101/152的残差结构，block.expansion=4</span>
        <span class="token keyword">if</span> stride <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>in_channel <span class="token operator">!=</span> channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">:</span>
            downsample <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span> channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span><span class="token punctuation">)</span>

        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span>
                            channel<span class="token punctuation">,</span>
                            downsample<span class="token operator">=</span>downsample<span class="token punctuation">,</span>
                            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>
                            groups<span class="token operator">=</span>self<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>
                            width_per_group<span class="token operator">=</span>self<span class="token punctuation">.</span>width_per_group<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>in_channel <span class="token operator">=</span> channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion

        <span class="token comment"># 上面构建完第一个残差块后，后面按需复制几个</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> block_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span>
                                channel<span class="token punctuation">,</span>
                                groups<span class="token operator">=</span>self<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>
                                width_per_group<span class="token operator">=</span>self<span class="token punctuation">.</span>width_per_group<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>  <span class="token comment"># 将列表转换为非关键字参数传递给nn.Sequential</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>include_top<span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x


<span class="token keyword">def</span> <span class="token function">resnet34</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnet34-333f7ec4.pth</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>BasicBlock<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> include_top<span class="token operator">=</span>include_top<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet50</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnet50-19c8e357.pth</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> include_top<span class="token operator">=</span>include_top<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet101</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> include_top<span class="token operator">=</span>include_top<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnext50_32x4d</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth</span>
    groups <span class="token operator">=</span> <span class="token number">32</span>
    width_per_group <span class="token operator">=</span> <span class="token number">4</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span>
                  include_top<span class="token operator">=</span>include_top<span class="token punctuation">,</span>
                  groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
                  width_per_group<span class="token operator">=</span>width_per_group<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnext101_32x8d</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth</span>
    groups <span class="token operator">=</span> <span class="token number">32</span>
    width_per_group <span class="token operator">=</span> <span class="token number">8</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span>
                  include_top<span class="token operator">=</span>include_top<span class="token punctuation">,</span>
                  groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
                  width_per_group<span class="token operator">=</span>width_per_group<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完整代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch

<span class="token comment"># ResNet18/34的残差结构，用的是2个3x3的卷积</span>
<span class="token keyword">class</span> <span class="token class-name">BasicBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    expansion <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># 残差结构中，主分支的卷积核个数是否发生变化，不变则为1</span>

    <span class="token comment"># 输入通道，输出通道，downsample下采样，对应虚线残差结构</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> downsample<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BasicBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channel<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>out_channel<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>out_channel<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>out_channel<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>downsample <span class="token operator">=</span> downsample

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>downsample <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># 虚线残差结构，需要下采样</span>
            identity <span class="token operator">=</span> self<span class="token punctuation">.</span>downsample<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 捷径分支 short cut</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">+=</span> identity
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out


<span class="token keyword">class</span> <span class="token class-name">Bottleneck</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。
    但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2，
    这么做的好处是能够在top1上提升大概0.5%的准确率。
    可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch
    """</span>
    expansion <span class="token operator">=</span> <span class="token number">4</span> <span class="token comment"># 残差结构中第三层卷积核个数是第一/二层卷积核个数的4倍</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> downsample<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> width_per_group<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>out_channel <span class="token operator">*</span> <span class="token punctuation">(</span>width_per_group <span class="token operator">/</span> <span class="token number">64.</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> groups

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channel<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>width<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># squeeze channels</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>width<span class="token punctuation">)</span>
        <span class="token comment"># -----------------------------------------</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>width<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>width<span class="token punctuation">,</span> groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>width<span class="token punctuation">)</span>
        <span class="token comment"># -----------------------------------------</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>width<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>out_channel<span class="token operator">*</span>self<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span>
                               kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># unsqueeze channels</span>
        self<span class="token punctuation">.</span>bn3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channel<span class="token operator">*</span>self<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>downsample <span class="token operator">=</span> downsample

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>downsample <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            identity <span class="token operator">=</span> self<span class="token punctuation">.</span>downsample<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">+=</span> identity
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out


<span class="token keyword">class</span> <span class="token class-name">ResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># block = BasicBlock or Bottleneck</span>
    <span class="token comment"># block_num为残差结构中conv2_x~conv5_x中残差块个数，是一个列表</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 block<span class="token punctuation">,</span>
                 blocks_num<span class="token punctuation">,</span>
                 num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
                 include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                 groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 width_per_group<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ResNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>include_top <span class="token operator">=</span> include_top
        self<span class="token punctuation">.</span>in_channel <span class="token operator">=</span> <span class="token number">64</span>

        self<span class="token punctuation">.</span>groups <span class="token operator">=</span> groups
        self<span class="token punctuation">.</span>width_per_group <span class="token operator">=</span> width_per_group

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                               padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>include_top<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># output size = (1, 1)</span>
            self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span> nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>

    <span class="token comment"># channel为残差结构中第一层卷积核个数</span>
    <span class="token keyword">def</span> <span class="token function">_make_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> block_num<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        downsample <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token comment"># 对于18和34层的的ResNet会直接跳过</span>
        <span class="token comment"># ResNet50/101/152的残差结构，block.expansion=4</span>
        <span class="token keyword">if</span> stride <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>in_channel <span class="token operator">!=</span> channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">:</span>
            downsample <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span> channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span><span class="token punctuation">)</span>

        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span>
                            channel<span class="token punctuation">,</span>
                            downsample<span class="token operator">=</span>downsample<span class="token punctuation">,</span>
                            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>
                            groups<span class="token operator">=</span>self<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>
                            width_per_group<span class="token operator">=</span>self<span class="token punctuation">.</span>width_per_group<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>in_channel <span class="token operator">=</span> channel <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion

        <span class="token comment"># 上面构建完第一个残差块后，后面按需复制几个</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> block_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span>
                                channel<span class="token punctuation">,</span>
                                groups<span class="token operator">=</span>self<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>
                                width_per_group<span class="token operator">=</span>self<span class="token punctuation">.</span>width_per_group<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>  <span class="token comment"># 将列表转换为非关键字参数传递给nn.Sequential</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>include_top<span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x


<span class="token keyword">def</span> <span class="token function">resnet34</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnet34-333f7ec4.pth</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>BasicBlock<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> include_top<span class="token operator">=</span>include_top<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet50</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnet50-19c8e357.pth</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> include_top<span class="token operator">=</span>include_top<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet101</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> include_top<span class="token operator">=</span>include_top<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnext50_32x4d</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth</span>
    groups <span class="token operator">=</span> <span class="token number">32</span>
    width_per_group <span class="token operator">=</span> <span class="token number">4</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span>
                  include_top<span class="token operator">=</span>include_top<span class="token punctuation">,</span>
                  groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
                  width_per_group<span class="token operator">=</span>width_per_group<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnext101_32x8d</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth</span>
    groups <span class="token operator">=</span> <span class="token number">32</span>
    width_per_group <span class="token operator">=</span> <span class="token number">8</span>
    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span>
                  include_top<span class="token operator">=</span>include_top<span class="token punctuation">,</span>
                  groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
                  width_per_group<span class="token operator">=</span>width_per_group<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="train训练">2、train训练</h2><p>由于ResNet网络较深，直接训练的话会非常耗时，因此用迁移学习的方法导入预训练好的模型参数： 在pycharm中输入<code>import torchvision.models.resnet</code>，ctrl+左键<code>resnet</code>跳转到pytorch官方实现resnet的源码中，下载预训练的模型参数：</p><p>下载预训练模型参数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model_urls <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">'resnet18'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/resnet18-5c106cde.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'resnet34'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/resnet34-333f7ec4.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'resnet50'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/resnet50-19c8e357.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'resnet101'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'resnet152'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/resnet152-b121ed2d.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'resnext50_32x4d'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'resnext101_32x8d'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'wide_resnet50_2'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'wide_resnet101_2'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth'</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与之前大体相同</p><p>不同之处：</p><p>①数据增广方法标准化参数与pytorch相同，验证集先resize到256，再中心裁剪到224</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data_transform <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"train"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"val"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>②<strong>载入预训练参数方法</strong>，更改最后输出的类别个数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> resnet34<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># load pretrain weights</span>
    <span class="token comment"># download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth</span>
    model_weight_path <span class="token operator">=</span> <span class="token string">"./resnet34-pre.pth"</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>model_weight_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file &#123;&#125; does not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>model_weight_path<span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_weight_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># for param in net.parameters():</span>
    <span class="token comment">#     param.requires_grad = False</span>

    <span class="token comment"># change fc layer structure</span>
    in_channel <span class="token operator">=</span> net<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_features
    net<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完整代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> json

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token punctuation">,</span> datasets
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm

<span class="token keyword">from</span> model <span class="token keyword">import</span> resnet34


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"using &#123;&#125; device."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

    data_transform <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"train"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"val"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>

    data_root <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"../.."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># get data root path</span>
    image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">"data_set"</span><span class="token punctuation">,</span> <span class="token string">"flower_data"</span><span class="token punctuation">)</span>  <span class="token comment"># flower data set path</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"&#123;&#125; path does not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>
    train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                         transform<span class="token operator">=</span>data_transform<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>

    <span class="token comment"># &#123;'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4&#125;</span>
    flower_list <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>class_to_idx
    cla_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>val<span class="token punctuation">,</span> key<span class="token punctuation">)</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> flower_list<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># write dict into json file</span>
    json_str <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>cla_dict<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'class_indices.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> json_file<span class="token punctuation">:</span>
        json_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>json_str<span class="token punctuation">)</span>

    batch_size <span class="token operator">=</span> <span class="token number">16</span>
    nw <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">[</span>os<span class="token punctuation">.</span>cpu_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size <span class="token keyword">if</span> batch_size <span class="token operator">></span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># number of workers</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; dataloader workers every process'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>nw<span class="token punctuation">)</span><span class="token punctuation">)</span>

    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                                               batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                               num_workers<span class="token operator">=</span>nw<span class="token punctuation">)</span>

    validate_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> <span class="token string">"val"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                            transform<span class="token operator">=</span>data_transform<span class="token punctuation">[</span><span class="token string">"val"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    val_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>validate_dataset<span class="token punctuation">)</span>
    validate_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>validate_dataset<span class="token punctuation">,</span>
                                                  batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                                  num_workers<span class="token operator">=</span>nw<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"using &#123;&#125; images for training, &#123;&#125; images for validation."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_num<span class="token punctuation">,</span>
                                                                           val_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    net <span class="token operator">=</span> resnet34<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># load pretrain weights</span>
    <span class="token comment"># download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth</span>
    model_weight_path <span class="token operator">=</span> <span class="token string">"./resnet34-pre.pth"</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>model_weight_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file &#123;&#125; does not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>model_weight_path<span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_weight_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># for param in net.parameters():</span>
    <span class="token comment">#     param.requires_grad = False</span>

    <span class="token comment"># change fc layer structure</span>
    in_channel <span class="token operator">=</span> net<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_features
    net<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># define loss function</span>
    loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># construct an optimizer</span>
    params <span class="token operator">=</span> <span class="token punctuation">[</span>p <span class="token keyword">for</span> p <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> p<span class="token punctuation">.</span>requires_grad<span class="token punctuation">]</span>
    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>params<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">3</span>
    best_acc <span class="token operator">=</span> <span class="token number">0.0</span>
    save_path <span class="token operator">=</span> <span class="token string">'./resNet34.pth'</span>
    train_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># train</span>
        net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        train_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
        <span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_bar<span class="token punctuation">)</span><span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            logits <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># print statistics</span>
            running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            train_bar<span class="token punctuation">.</span>desc <span class="token operator">=</span> <span class="token string">"train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                                                     epochs<span class="token punctuation">,</span>
                                                                     loss<span class="token punctuation">)</span>

        <span class="token comment"># validate</span>
        net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        acc <span class="token operator">=</span> <span class="token number">0.0</span>  <span class="token comment"># accumulate accurate number / epoch</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            val_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>validate_loader<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
            <span class="token keyword">for</span> val_data <span class="token keyword">in</span> val_bar<span class="token punctuation">:</span>
                val_images<span class="token punctuation">,</span> val_labels <span class="token operator">=</span> val_data
                outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>val_images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment"># loss = loss_function(outputs, test_labels)</span>
                predict_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                acc <span class="token operator">+=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>predict_y<span class="token punctuation">,</span> val_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

                val_bar<span class="token punctuation">.</span>desc <span class="token operator">=</span> <span class="token string">"valid epoch[&#123;&#125;/&#123;&#125;]"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                                           epochs<span class="token punctuation">)</span>

        val_accurate <span class="token operator">=</span> acc <span class="token operator">/</span> val_num
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[epoch %d] train_loss: %.3f  val_accuracy: %.3f'</span> <span class="token operator">%</span>
              <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> train_steps<span class="token punctuation">,</span> val_accurate<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> val_accurate <span class="token operator">></span> best_acc<span class="token punctuation">:</span>
            best_acc <span class="token operator">=</span> val_accurate
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="predict预测">3、predict预测</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> json

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> model <span class="token keyword">import</span> resnet34


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

    data_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># load image</span>
    img_path <span class="token operator">=</span> <span class="token string">"../tulip.jpg"</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file: '&#123;&#125;' dose not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    <span class="token comment"># [N, C, H, W]</span>
    img <span class="token operator">=</span> data_transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    <span class="token comment"># expand batch dimension</span>
    img <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># read class_indict</span>
    json_path <span class="token operator">=</span> <span class="token string">'./class_indices.json'</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>json_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file: '&#123;&#125;' dose not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>json_path<span class="token punctuation">)</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>json_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        class_indict <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>

    <span class="token comment"># create model</span>
    model <span class="token operator">=</span> resnet34<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># load model weights</span>
    weights_path <span class="token operator">=</span> <span class="token string">"./resNet34.pth"</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>weights_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file: '&#123;&#125;' dose not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>weights_path<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>weights_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># prediction</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># predict class</span>
        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>model<span class="token punctuation">(</span>img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        predict_cla <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predict<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    print_res <span class="token operator">=</span> <span class="token string">"class: &#123;&#125;   prob: &#123;:.3&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>class_indict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>predict_cla<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                 predict<span class="token punctuation">[</span>predict_cla<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>print_res<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>predict<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"class: &#123;:10&#125;   prob: &#123;:.3&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>class_indict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                  predict<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/posts/41407.html">http://unicorn-acc.github.io/posts/41407.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/gp/wallhaven-gpjj9q.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/13596.html"><img class="prev-cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Spring5_04_JdbcTemplate</div></div></a></div><div class="next-post pull-right"><a href="/posts/58469.html"><img class="next-cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Redis相关资料_安装Canal(数据同步-异步通知)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/32234.html" title="CV可解释性分析_CAM热力图"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-03</div><div class="title">CV可解释性分析_CAM热力图</div></div></a></div><div><a href="/posts/11760.html" title="CV可解释性分析_Grad-CAM"><img class="cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-03</div><div class="title">CV可解释性分析_Grad-CAM</div></div></a></div><div><a href="/posts/5074.html" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/1p/wallhaven-1pjml1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/posts/47625.html" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/posts/56670.html" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/posts/2490.html" title="图像分类_花分类数据集"><img class="cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-06</div><div class="title">图像分类_花分类数据集</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80resnet%E4%BB%8B%E7%BB%8D"><span class="toc-text">一、ResNet介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#why-residual"><span class="toc-text">1.1 Why residual?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-is-residual"><span class="toc-text">1.2 What is residual？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#resnet%E4%B8%AD%E7%9A%84%E6%AE%8B%E5%B7%AE%E7%BB%93%E6%9E%84"><span class="toc-text">1.3 ResNet中的残差结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%8D%E7%BB%B4%E6%97%B6%E7%9A%84-shortcut"><span class="toc-text">1.4 降维时的 shortcut</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E6%B7%B1%E5%BA%A6%E7%9A%84resnet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E9%85%8D%E7%BD%AE"><span class="toc-text">1.5 不同深度的ResNet网络结构配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8Cbn%E5%B1%82batch-normalization"><span class="toc-text">二、BN层（Batch Normalization）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8bn%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">使用BN时需要注意的问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="toc-text">三、迁移学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9Bresnet%E7%BD%91%E7%BB%9Cpytorch%E5%AE%9E%E7%8E%B0"><span class="toc-text">四、ResNet网络Pytorch实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#model%E6%A8%A1%E5%9E%8B"><span class="toc-text">1、Model模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#train%E8%AE%AD%E7%BB%83"><span class="toc-text">2、train训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#predict%E9%A2%84%E6%B5%8B"><span class="toc-text">3、predict预测</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const n of document.querySelectorAll('script[type^="math/tex"]')){var e=!!n.type.match(/; *mode=display/),e=new t.options.MathItem(n.textContent,t.inputJax[0],e),a=document.createTextNode("");n.parentNode.replaceChild(a,n),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],insertScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t.hasAttribute("display")?btf.wrap(t,"div",{class:"mathjax-overflow"}):btf.wrap(t,"span",{class:"mathjax-overflow"})})},"",!1]}}};const a=document.createElement("script");a.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script src="/js/mouth.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (53)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (20)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (12)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/算法刷题记录/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍💻 算法刷题记录 (59)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(33.333333333333336% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>