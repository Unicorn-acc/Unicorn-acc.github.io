<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>图像分类_03_GoogLeNet网络详解(多loss计算方式) | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:type" content="article"><meta property="og:title" content="图像分类_03_GoogLeNet网络详解(多loss计算方式)"><meta property="og:url" content="http://unicorn-acc.github.io/posts/53738.html"><meta property="og:site_name" content="Miraclo’s Blog"><meta property="og:description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://w.wallhaven.cc/full/e7/wallhaven-e7jj6r.jpg"><meta property="article:published_time" content="2022-11-09T14:25:07.000Z"><meta property="article:modified_time" content="2022-11-18T14:20:40.062Z"><meta property="article:author" content="Miraclo"><meta property="article:tag" content="DeepLearning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://w.wallhaven.cc/full/e7/wallhaven-e7jj6r.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/posts/53738"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"prismjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:2e3},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:500,languages:{author:"作者: Miraclo",link:"链接: ",source:"来源: Miraclo’s Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"图像分类_03_GoogLeNet网络详解(多loss计算方式)",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-11-18 14:20:40"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouth.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">123</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://w.wallhaven.cc/full/e7/wallhaven-e7jj6r.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">图像分类_03_GoogLeNet网络详解(多loss计算方式)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2022-11-09T14:25:07.000Z" title="发表于 2022-11-09 14:25:07">2022-11-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/1%E3%80%81%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%AF%87/">1、图像分类篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>24分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="图像分类_03_GoogLeNet网络详解(多loss计算方式)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>参考内容来自霹雳吧啦Wz</p><p>up主的b站链接：https://space.bilibili.com/18161609/channel/index</p><p>up主的github：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</p><p>up主的CSDN博客：https://blog.csdn.net/qq_37541097/article/details/103482003</p></blockquote><h1 id="一googlenet介绍">一、GoogLeNet介绍</h1><p>GoogLeNet在2014年由Google团队提出（与VGG网络同年，注意GoogLeNet中的L大写是为了致敬LeNet），斩获当年ImageNet竞赛中Classification Task (分类任务) 第一名。</p><p>论文地址：https://arxiv.org/pdf/1409.4842.pdf 源代码：<a target="_blank" rel="noopener" href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/Test4_googlenet/model.py">googlenet</a></p><p><strong>GoogLeNet 的创新点</strong>：</p><ul><li>引入了 <strong>Inception</strong> 结构（融合不同尺度的特征信息）</li><li>使用<strong>1x1的卷积核</strong>进行降维以及映射处理 （虽然VGG网络中也有，但该论文介绍的更详细）</li><li>添加两个<strong>辅助分类器</strong>帮助训练</li><li>丢弃全连接层，使用平均池化层（大大减少模型参数，除去两个辅助分类器，网络大小只有vgg的1/20）</li></ul><h1 id="二动机和高层面的思考">二、动机和高层面的思考</h1><p>​ 提高深度神经网络性能方法：增加网络大小，包括深度和宽度，这是最直接的办法，也是最简单最安全的办法，尤其是当给定大量带标签的训练数据时。但是缺点明显：增加网络中训练的参数（导致过拟合），增加计算量。</p><p>​ 解决上述问题的方法：从FC层完全转变到稀疏连接的结构，卷积层内部也是如此。Arora等人的开创性工作给了这种方法更坚实的理论基础，因为他们的主要结果表明如果数据集的概率分布可以用一个大的、非常稀疏的深度神经网络来表示，那么可以通过分析最后一层激活函数的相关统计量（均值方差等）和聚合有着高度相关输出的神经元来逐层生成最优的网络拓扑，这与<strong>赫布原理</strong>相仿——神经元一起发射且连接在一起。</p><blockquote><p><strong>Inception Net设计的思考是什么？(好的深度网络有哪些设计原则)</strong></p><ul><li><strong>逐层构造网络</strong>：如果数据集的概率分布能够被一个神经网络所表达，那么构造这个网络的最佳方法是逐层构筑网络，即将上一层高度相关的节点连接在一起。几乎所有效果好的深度网络都具有这一点，不管AlexNet VGG堆叠多个卷积，googLeNet堆叠多个inception模块，还是ResNet堆叠多个resblock。</li><li>稀疏的结构：人脑的神经元连接就是稀疏的，因此大型神经网络的合理连接方式也应该是稀疏的。稀疏的结构对于大型神经网络至关重要，可以减轻计算量并减少过拟合。 卷积操作（局部连接，权值共享）本身就是一种稀疏的结构，相比于全连接网络结构是很稀疏的。</li><li>符合Hebbian原理: Cells that fire together, wire together. 一起发射的神经元会连在一起。 相关性高的节点应该被连接而在一起。</li></ul></blockquote><h1 id="三googlenet网络结构">三、GoogleNet网络结构</h1><p>网络模型：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091431820.png" style="zoom:50%"></p><h2 id="inception模块">Inception模块</h2><p>传统的CNN结构如AlexNet、VggNet（下图）都是==串联==的结构，即将一系列的卷积层和池化层进行串联得到的结构。 <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091435202.png" style="zoom:67%"></p><p>GoogLeNet 提出了一种==并联结构==，下图是论文中提出的inception原始结构，将特征矩阵<strong>同时输入到多个分支</strong>进行处理，并将输出的特征矩阵<strong>按深度进行拼接</strong>，得到最终输出。</p><ul><li>inception的作用：增加网络深度和宽度的同时减少参数。 <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091435261.png" style="zoom:67%"> 注意：<strong>每个分支所得特征矩阵的高和宽必须相同（通过调整stride和padding)，以保证输出特征能在深度上进行拼接。</strong></li></ul><h3 id="inception-降维">inception + 降维</h3><p>在 inception 的基础上，还可以加上降维功能的结构，如下图所示，在原始 inception 结构的基础上，在分支2，3，4上加入了<strong>卷积核大小为1x1的卷积层</strong>，目的是为了降维（减小深度），减少模型训练参数，减少计算量。 <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091436400.png" style="zoom:67%"></p><ul><li><strong>1×1卷积核的降维功能</strong> 同样是对一个深度为512的特征矩阵使用64个大小为5x5的卷积核进行卷积，不使用1x1卷积核进行降维的 话一共需要819200个参数，如果使用1x1卷积核进行降维一共需要50688个参数，明显少了很多。 <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091437017.png" style="zoom:50%"> <strong>注：CNN参数个数 = 卷积核尺寸×卷积核深度 × 卷积核组数 = 卷积核尺寸 × 输入特征矩阵深度 × 输出特征矩阵深度</strong></li></ul><hr><p>    单从上面的网络结构并不能很好的看懂GoogleNet的高明之处，但是如果将其拆分则很容易明白其设计思想。其实，GoogleNet的核心思想就是Inception模块。整个网络实际上就是Inception模块的叠加与应用。Inception模块具体如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091433575.jpeg"></p><p>    GoogleNet主要有两个贡献：<strong>1）使用1x1的卷积结构；2）在多个尺度上并行卷积然后再组合在一起。</strong></p><h3 id="网络结构">1×1网络结构</h3><p><strong>1.1、1x1卷积结构解析</strong></p><p>    1x1的卷积结构主要有两个作用，第一是<strong>提取更丰富的特征</strong>；第二是可以进行<strong>降维运算</strong>，降低计算的复杂度。这也是1x1的卷积结构提出后受到追捧的主要原因，当然，最先提出1x1卷积结构的应该是NiN网络，感兴趣的同学可以去查一下。</p><p>    <strong>1.1.1、提取更丰富的特征</strong></p><p>    众所周知，一般进行卷积操作后都会连接激活函数以便于得到非线性的特征。传统方法如果采用3x3卷积+ReLU的结构，将会逐步拟合非线性函数F1，但是如果将3x3卷积+ReLU的结构中串联一个1x1卷积就可以得到更多的非线性特征。</p><p>    <strong>1.1.2、降低计算复杂度</strong></p><p>    使用1x1卷积进行降维，降低了计算复杂度。举个例子来说明这个问题将更为直观，例如输入为64通道的24x24的特征图，用3x3卷积操作输出为24x24大小的256通道特征，那么其计算复杂度为：64x3x3x24x24x256=84934656；那么如果在输入后使用1x1卷积将64通道降为32，在进行3x3卷积恢复出256组特征，那么他的复杂度为：64x1x1x24x24x32+32x3x3x24x24x256 = 43646976。与以上相比，使用1x1卷积计算复杂度大概可以节省一半的计算量，而且中间降维的操作不会影响到最终的训练结果。</p><p><strong>1.2、多个尺度上并行卷积然后再组合</strong></p><p>    如图2所示，Inception有4各分支，每个分支的卷积或是池化的尺度均不相同，最后将4个分支组合到一起。在多个尺度上同时进行卷积可以提取到不同尺度的特征，组合之后可以想象一下，其包含的特征更为丰富，当然理论上分类效果也更好。当然5x5的卷积计算量较大，因此也有了后面对其的改进，即使用两个3x3来代替。</p><h2 id="辅助分类器auxiliary-classifier">辅助分类器（Auxiliary Classifier）</h2><p>AlexNet 和 VGG 都只有1个输出层，GoogLeNet 有3个输出层，其中的两个是辅助分类层。</p><p>如下图所示，网络主干右边的 两个分支 就是 辅助分类器，其结构一模一样。</p><p>在训练模型时，将两个辅助分类器的损失乘以权重（论文中是0.3）加到网络的整体损失上，再进行反向传播。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091523310.png" style="zoom:67%"></p><blockquote><p>辅助分类器的两个分支有什么用呢？</p><ul><li>作用一：可以把他看做inception网络中的一个小细节，它确保了即便是隐藏单元和中间层也参与了特征计算，他们也能预测图片的类别，他在inception网络中起到一种调整的效果，并且能防止网络发生过拟合。</li><li>作用二：给定深度相对较大的网络，有效传播梯度反向通过所有层的能力是一个问题。通过将辅助分类器添加到这些中间层，可以期望较低阶段分类器的判别力。在训练期间，它们的损失以折扣权重（辅助分类器损失的权重是0.3）加到网络的整个损失上。</li></ul></blockquote><h2 id="googlenet网络参数">GoogLeNet网络参数</h2><p>论文中展示了网络结构参数：（后面各配置是output_channel）</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091445579.png"></p><blockquote><ul><li><code>#1x1</code>对应着分支1上1x1的卷积核个数</li><li><code>#3x3reduce</code>对应着分支2上1x1的卷积核个数</li><li><code>#3x3</code>对应着分支2上3x3的卷积核个数</li><li><code>#5x5reduce</code>对应着分支3上1x1的卷积核个数</li><li><code>#5x5</code>对应着分支3上5x5的卷积核个数</li><li><code>poolproj</code>对应着分支4上1x1的卷积核个数。</li></ul></blockquote><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211091500715.png" style="zoom:67%"></p><h1 id="四googlenet网络结构pytorch实现">四、GoogLeNet网络结构Pytorch实现</h1><h2 id="model模型">1、model模型</h2><blockquote><p>在Module中，上面init先定义模型，在forward前向传播中写激活函数和展平flatten</p></blockquote><h3 id="基本卷积块定义每个卷积后跟relu函数">①基本卷积块定义(每个卷积后跟Relu函数)</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BasicConv2d</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BasicConv2d<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="inception模块定义">②Inception模块定义</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Inception</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> ch1x1<span class="token punctuation">,</span> ch3x3red<span class="token punctuation">,</span> ch3x3<span class="token punctuation">,</span> ch5x5red<span class="token punctuation">,</span> ch5x5<span class="token punctuation">,</span> pool_proj<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Inception<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch1 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> ch1x1<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> ch3x3red<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            BasicConv2d<span class="token punctuation">(</span>ch3x3red<span class="token punctuation">,</span> ch3x3<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># 保证输出大小等于输入大小</span>
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> ch5x5red<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># 在官方的实现中，其实是3x3的kernel并不是5x5，这里我也懒得改了，具体可以参考下面的issue</span>
            <span class="token comment"># Please see https://github.com/pytorch/vision/issues/906 for details.</span>
            BasicConv2d<span class="token punctuation">(</span>ch5x5red<span class="token punctuation">,</span> ch5x5<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>   <span class="token comment"># 保证输出大小等于输入大小</span>
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> pool_proj<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        branch1 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch2 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch4 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> <span class="token punctuation">[</span>branch1<span class="token punctuation">,</span> branch2<span class="token punctuation">,</span> branch3<span class="token punctuation">,</span> branch4<span class="token punctuation">]</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># [N,C,H,W] 在channel维度上拼接起来</span>
    <span class="token comment"># 想要去对那哪一个维度进行concat就必须要保证其他维度的大小是一样的</span>
    <span class="token comment"># 维度0为width，卷积过后都是一致的；维度2为depth，卷积过后不一致。因此concat只能在维度1上进行</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="辅助分类器定义">③辅助分类器定义</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">InceptionAux</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>InceptionAux<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>averagePool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># output[batch, 128, 4, 4]</span>

        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>averagePool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 128 x 4 x 4</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#　在channel维进行展平</span>
        <span class="token comment"># training=self.training使用moedl.train() 和model.eval()进行控制是否使用dropout</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span> <span class="token comment"># 论文中 70%，这里使用50%</span>
        <span class="token comment"># N x 2048</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        <span class="token comment"># N x 1024</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x num_classes</span>
        <span class="token keyword">return</span> x
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="googlenet网络">④GoogLeNet网络</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GoogLeNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># aux_logits是否使用辅助分类器</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> aux_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> init_weights<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GoogLeNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>aux_logits <span class="token operator">=</span> aux_logits
		<span class="token comment"># 这里padding=3：(224-7+2*p)/2+1=112 ==> p = 3</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
        <span class="token comment"># ceil_mode=True，最大池化层值为小数时，向上取整，为false则为向下取整</span>
        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>inception3a <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception3b <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>inception4a <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">480</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">208</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4b <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4c <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4d <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">144</span><span class="token punctuation">,</span> <span class="token number">288</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4e <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">528</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>inception5a <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception5b <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>aux1 <span class="token operator">=</span> InceptionAux<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span> <span class="token comment"># 来自inception4a</span>
            self<span class="token punctuation">.</span>aux2 <span class="token operator">=</span> InceptionAux<span class="token punctuation">(</span><span class="token number">528</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span> <span class="token comment"># 来自inception4d，4d输出528，所以输入528channel</span>

        <span class="token comment"># AdaptiveAvgPool2d自适应最大池化层，无论输入多大，最后输出都是高为1宽为1</span>
        self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
        <span class="token keyword">if</span> init_weights<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>_initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># N x 3 x 224 x 224</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 64 x 112 x 112</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 64 x 56 x 56</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 64 x 56 x 56</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 192 x 56 x 56</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment"># N x 192 x 28 x 28</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception3a<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 256 x 28 x 28</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception3b<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 480 x 28 x 28</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 480 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4a<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 512 x 14 x 14</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>    <span class="token comment"># eval model lose this layer</span>
            aux1 <span class="token operator">=</span> self<span class="token punctuation">.</span>aux1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4b<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 512 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4c<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 512 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4d<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 528 x 14 x 14</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>    <span class="token comment"># eval model lose this layer</span>
            aux2 <span class="token operator">=</span> self<span class="token punctuation">.</span>aux2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4e<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 832 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 832 x 7 x 7</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception5a<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 832 x 7 x 7</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception5b<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 1024 x 7 x 7</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 1024 x 1 x 1</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># N x 1024</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 1000 (num_classes)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>   <span class="token comment"># eval model lose this layer</span>
            <span class="token keyword">return</span> x<span class="token punctuation">,</span> aux2<span class="token punctuation">,</span> aux1
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">_initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span> nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完整代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F


<span class="token keyword">class</span> <span class="token class-name">GoogLeNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> aux_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> init_weights<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GoogLeNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>aux_logits <span class="token operator">=</span> aux_logits

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>inception3a <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception3b <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>inception4a <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">480</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">208</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4b <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4c <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4d <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">144</span><span class="token punctuation">,</span> <span class="token number">288</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception4e <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">528</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>inception5a <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inception5b <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>aux1 <span class="token operator">=</span> InceptionAux<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>aux2 <span class="token operator">=</span> InceptionAux<span class="token punctuation">(</span><span class="token number">528</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
        <span class="token keyword">if</span> init_weights<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>_initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># N x 3 x 224 x 224</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 64 x 112 x 112</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 64 x 56 x 56</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 64 x 56 x 56</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 192 x 56 x 56</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment"># N x 192 x 28 x 28</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception3a<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 256 x 28 x 28</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception3b<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 480 x 28 x 28</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 480 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4a<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 512 x 14 x 14</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>    <span class="token comment"># eval model lose this layer</span>
            aux1 <span class="token operator">=</span> self<span class="token punctuation">.</span>aux1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4b<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 512 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4c<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 512 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4d<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 528 x 14 x 14</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>    <span class="token comment"># eval model lose this layer</span>
            aux2 <span class="token operator">=</span> self<span class="token punctuation">.</span>aux2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception4e<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 832 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 832 x 7 x 7</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception5a<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 832 x 7 x 7</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>inception5b<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 1024 x 7 x 7</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 1024 x 1 x 1</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># N x 1024</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 1000 (num_classes)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>aux_logits<span class="token punctuation">:</span>   <span class="token comment"># eval model lose this layer</span>
            <span class="token keyword">return</span> x<span class="token punctuation">,</span> aux2<span class="token punctuation">,</span> aux1
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">_initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span> nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Inception</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> ch1x1<span class="token punctuation">,</span> ch3x3red<span class="token punctuation">,</span> ch3x3<span class="token punctuation">,</span> ch5x5red<span class="token punctuation">,</span> ch5x5<span class="token punctuation">,</span> pool_proj<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Inception<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch1 <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> ch1x1<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> ch3x3red<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            BasicConv2d<span class="token punctuation">(</span>ch3x3red<span class="token punctuation">,</span> ch3x3<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># 保证输出大小等于输入大小</span>
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> ch5x5red<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># 在官方的实现中，其实是3x3的kernel并不是5x5，这里我也懒得改了，具体可以参考下面的issue</span>
            <span class="token comment"># Please see https://github.com/pytorch/vision/issues/906 for details.</span>
            BasicConv2d<span class="token punctuation">(</span>ch5x5red<span class="token punctuation">,</span> ch5x5<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>   <span class="token comment"># 保证输出大小等于输入大小</span>
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>branch4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> pool_proj<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        branch1 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch2 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch4 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> <span class="token punctuation">[</span>branch1<span class="token punctuation">,</span> branch2<span class="token punctuation">,</span> branch3<span class="token punctuation">,</span> branch4<span class="token punctuation">]</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">InceptionAux</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>InceptionAux<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>averagePool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> BasicConv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># output[batch, 128, 4, 4]</span>

        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>averagePool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x 128 x 4 x 4</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        <span class="token comment"># N x 2048</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        <span class="token comment"># N x 1024</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># N x num_classes</span>
        <span class="token keyword">return</span> x


<span class="token keyword">class</span> <span class="token class-name">BasicConv2d</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BasicConv2d<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="train训练">2、train训练</h2><p>与VGGNet大体相同</p><p>不同之处：</p><p>①创建模型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> GoogLeNet<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> aux_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> init_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>②计算损失</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_bar<span class="token punctuation">)</span><span class="token punctuation">:</span>
    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    logits<span class="token punctuation">,</span> aux_logits2<span class="token punctuation">,</span> aux_logits1 <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss0 <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss1 <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>aux_logits1<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss2 <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>aux_logits2<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> loss0 <span class="token operator">+</span> loss1 <span class="token operator">*</span> <span class="token number">0.3</span> <span class="token operator">+</span> loss2 <span class="token operator">*</span> <span class="token number">0.3</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完整代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> json

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token punctuation">,</span> datasets
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm

<span class="token keyword">from</span> model <span class="token keyword">import</span> GoogLeNet


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"using &#123;&#125; device."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

    data_transform <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"train"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"val"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>

    data_root <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"../"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># get data root path</span>
    image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">"data_set"</span><span class="token punctuation">,</span> <span class="token string">"flower_data"</span><span class="token punctuation">)</span>  <span class="token comment"># flower data set path</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"&#123;&#125; path does not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>
    train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                         transform<span class="token operator">=</span>data_transform<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>

    <span class="token comment"># &#123;'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4&#125;</span>
    flower_list <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>class_to_idx
    cla_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>val<span class="token punctuation">,</span> key<span class="token punctuation">)</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> flower_list<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># write dict into json file</span>
    json_str <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>cla_dict<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'class_indices.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> json_file<span class="token punctuation">:</span>
        json_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>json_str<span class="token punctuation">)</span>

    batch_size <span class="token operator">=</span> <span class="token number">32</span>
    nw <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">[</span>os<span class="token punctuation">.</span>cpu_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size <span class="token keyword">if</span> batch_size <span class="token operator">></span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># number of workers</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; dataloader workers every process'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>nw<span class="token punctuation">)</span><span class="token punctuation">)</span>

    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                                               batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                               num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    validate_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> <span class="token string">"val"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                            transform<span class="token operator">=</span>data_transform<span class="token punctuation">[</span><span class="token string">"val"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    val_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>validate_dataset<span class="token punctuation">)</span>
    validate_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>validate_dataset<span class="token punctuation">,</span>
                                                  batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                                  num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"using &#123;&#125; images for training, &#123;&#125; images for validation."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_num<span class="token punctuation">,</span>
                                                                           val_num<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># test_data_iter = iter(validate_loader)</span>
    <span class="token comment"># test_image, test_label = test_data_iter.next()</span>

    net <span class="token operator">=</span> GoogLeNet<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> aux_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> init_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># 如果要使用官方的预训练权重，注意是将权重载入官方的模型，不是我们自己实现的模型</span>
    <span class="token comment"># 官方的模型中使用了bn层以及改了一些参数，不能混用</span>
    <span class="token comment"># import torchvision</span>
    <span class="token comment"># net = torchvision.models.googlenet(num_classes=5)</span>
    <span class="token comment"># model_dict = net.state_dict()</span>
    <span class="token comment"># # 预训练权重下载地址: https://download.pytorch.org/models/googlenet-1378be20.pth</span>
    <span class="token comment"># pretrain_model = torch.load("googlenet.pth")</span>
    <span class="token comment"># del_list = ["aux1.fc2.weight", "aux1.fc2.bias",</span>
    <span class="token comment">#             "aux2.fc2.weight", "aux2.fc2.bias",</span>
    <span class="token comment">#             "fc.weight", "fc.bias"]</span>
    <span class="token comment"># pretrain_dict = &#123;k: v for k, v in pretrain_model.items() if k not in del_list&#125;</span>
    <span class="token comment"># model_dict.update(pretrain_dict)</span>
    <span class="token comment"># net.load_state_dict(model_dict)</span>
    net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0003</span><span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">30</span>
    best_acc <span class="token operator">=</span> <span class="token number">0.0</span>
    save_path <span class="token operator">=</span> <span class="token string">'./googleNet.pth'</span>
    train_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># train</span>
        net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        train_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
        <span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_bar<span class="token punctuation">)</span><span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            logits<span class="token punctuation">,</span> aux_logits2<span class="token punctuation">,</span> aux_logits1 <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss0 <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss1 <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>aux_logits1<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss2 <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>aux_logits2<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss0 <span class="token operator">+</span> loss1 <span class="token operator">*</span> <span class="token number">0.3</span> <span class="token operator">+</span> loss2 <span class="token operator">*</span> <span class="token number">0.3</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># print statistics</span>
            running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            train_bar<span class="token punctuation">.</span>desc <span class="token operator">=</span> <span class="token string">"train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                                                     epochs<span class="token punctuation">,</span>
                                                                     loss<span class="token punctuation">)</span>

        <span class="token comment"># validate</span>
        net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        acc <span class="token operator">=</span> <span class="token number">0.0</span>  <span class="token comment"># accumulate accurate number / epoch</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            val_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>validate_loader<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
            <span class="token keyword">for</span> val_data <span class="token keyword">in</span> val_bar<span class="token punctuation">:</span>
                val_images<span class="token punctuation">,</span> val_labels <span class="token operator">=</span> val_data
                outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>val_images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># eval model only have last output layer</span>
                predict_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                acc <span class="token operator">+=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>predict_y<span class="token punctuation">,</span> val_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        val_accurate <span class="token operator">=</span> acc <span class="token operator">/</span> val_num
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[epoch %d] train_loss: %.3f  val_accuracy: %.3f'</span> <span class="token operator">%</span>
              <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> train_steps<span class="token punctuation">,</span> val_accurate<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> val_accurate <span class="token operator">></span> best_acc<span class="token punctuation">:</span>
            best_acc <span class="token operator">=</span> val_accurate
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="predict预测">3、predict预测</h2><p>初始化不用辅助分类器，加载预训练权重strict=False</p><ul><li>strict=False：参数和模型不需要严格相同（不加载两个辅助分类层的参数）</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># create model</span>
    model <span class="token operator">=</span> GoogLeNet<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> aux_logits<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># load model weights</span>
    weights_path <span class="token operator">=</span> <span class="token string">"./googleNet.pth"</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>weights_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file: '&#123;&#125;' dose not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>weights_path<span class="token punctuation">)</span>
    missing_keys<span class="token punctuation">,</span> unexpected_keys <span class="token operator">=</span> model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>weights_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                          strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完整代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> json

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> model <span class="token keyword">import</span> GoogLeNet


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

    data_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># load image</span>
    img_path <span class="token operator">=</span> <span class="token string">"../tulip.jpg"</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file: '&#123;&#125;' dose not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    <span class="token comment"># [N, C, H, W]</span>
    img <span class="token operator">=</span> data_transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    <span class="token comment"># expand batch dimension</span>
    img <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># read class_indict</span>
    json_path <span class="token operator">=</span> <span class="token string">'./class_indices.json'</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>json_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file: '&#123;&#125;' dose not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>json_path<span class="token punctuation">)</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>json_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        class_indict <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>

    <span class="token comment"># create model</span>
    model <span class="token operator">=</span> GoogLeNet<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> aux_logits<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># load model weights</span>
    weights_path <span class="token operator">=</span> <span class="token string">"./googleNet.pth"</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>weights_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"file: '&#123;&#125;' dose not exist."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>weights_path<span class="token punctuation">)</span>
    missing_keys<span class="token punctuation">,</span> unexpected_keys <span class="token operator">=</span> model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>weights_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                          strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># predict class</span>
        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>model<span class="token punctuation">(</span>img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        predict_cla <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predict<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    print_res <span class="token operator">=</span> <span class="token string">"class: &#123;&#125;   prob: &#123;:.3&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>class_indict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>predict_cla<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                 predict<span class="token punctuation">[</span>predict_cla<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>print_res<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>predict<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"class: &#123;:10&#125;   prob: &#123;:.3&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>class_indict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                  predict<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/posts/53738.html">http://unicorn-acc.github.io/posts/53738.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/e7/wallhaven-e7jj6r.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/14161.html"><img class="prev-cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">SpringMVC_01_入门案例</div></div></a></div><div class="next-post pull-right"><a href="/posts/60116.html"><img class="next-cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Redis相关资料_搭建集群(单机、主从集群、哨兵集群、分片集群)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/5074.html" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/p9/wallhaven-p9273e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/posts/47625.html" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/posts/56670.html" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/posts/2490.html" title="图像分类_花分类数据集"><img class="cover" src="https://w.wallhaven.cc/full/p9/wallhaven-p9273e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-06</div><div class="title">图像分类_花分类数据集</div></div></a></div><div><a href="/posts/64179.html" title="图像分类_00_LeNet_Pytorch官方示例"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_00_LeNet_Pytorch官方示例</div></div></a></div><div><a href="/posts/5932.html" title="目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)"><img class="cover" src="https://w.wallhaven.cc/full/p9/wallhaven-p9273e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-17</div><div class="title">目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80googlenet%E4%BB%8B%E7%BB%8D"><span class="toc-text">一、GoogLeNet介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E5%8A%A8%E6%9C%BA%E5%92%8C%E9%AB%98%E5%B1%82%E9%9D%A2%E7%9A%84%E6%80%9D%E8%80%83"><span class="toc-text">二、动机和高层面的思考</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89googlenet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">三、GoogleNet网络结构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#inception%E6%A8%A1%E5%9D%97"><span class="toc-text">Inception模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#inception-%E9%99%8D%E7%BB%B4"><span class="toc-text">inception + 降维</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">1×1网络结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%85%E5%8A%A9%E5%88%86%E7%B1%BB%E5%99%A8auxiliary-classifier"><span class="toc-text">辅助分类器（Auxiliary Classifier）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#googlenet%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0"><span class="toc-text">GoogLeNet网络参数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9Bgooglenet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84pytorch%E5%AE%9E%E7%8E%B0"><span class="toc-text">四、GoogLeNet网络结构Pytorch实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#model%E6%A8%A1%E5%9E%8B"><span class="toc-text">1、model模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8D%B7%E7%A7%AF%E5%9D%97%E5%AE%9A%E4%B9%89%E6%AF%8F%E4%B8%AA%E5%8D%B7%E7%A7%AF%E5%90%8E%E8%B7%9Frelu%E5%87%BD%E6%95%B0"><span class="toc-text">①基本卷积块定义(每个卷积后跟Relu函数)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#inception%E6%A8%A1%E5%9D%97%E5%AE%9A%E4%B9%89"><span class="toc-text">②Inception模块定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%85%E5%8A%A9%E5%88%86%E7%B1%BB%E5%99%A8%E5%AE%9A%E4%B9%89"><span class="toc-text">③辅助分类器定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#googlenet%E7%BD%91%E7%BB%9C"><span class="toc-text">④GoogLeNet网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#train%E8%AE%AD%E7%BB%83"><span class="toc-text">2、train训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#predict%E9%A2%84%E6%B5%8B"><span class="toc-text">3、predict预测</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const n of document.querySelectorAll('script[type^="math/tex"]')){var e=!!n.type.match(/; *mode=display/),e=new t.options.MathItem(n.textContent,t.inputJax[0],e),a=document.createTextNode("");n.parentNode.replaceChild(a,n),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],insertScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t.hasAttribute("display")?btf.wrap(t,"div",{class:"mathjax-overflow"}):btf.wrap(t,"span",{class:"mathjax-overflow"})})},"",!1]}}};const a=document.createElement("script");a.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script src="/js/mouth.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (54)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (19)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(33.333333333333336% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>