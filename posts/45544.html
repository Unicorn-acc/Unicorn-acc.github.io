<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>语义分割-00-语义分割基础 | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1. 常见的分割任务  语义分割 (Semantic Segmentation) -&gt; FCN 实例分割 (Instance Segmentation) -&gt; Mask R-CNN 全景分割 (Panoramic Segmentation) -&gt; Panoptic FPN    2. 暂定的学习规划    Model mIoU Global Pixel Acc Inference"><meta property="og:type" content="article"><meta property="og:title" content="语义分割-00-语义分割基础"><meta property="og:url" content="http://unicorn-acc.github.io/posts/45544.html"><meta property="og:site_name" content="Miraclo’s Blog"><meta property="og:description" content="1. 常见的分割任务  语义分割 (Semantic Segmentation) -&gt; FCN 实例分割 (Instance Segmentation) -&gt; Mask R-CNN 全景分割 (Panoramic Segmentation) -&gt; Panoptic FPN    2. 暂定的学习规划    Model mIoU Global Pixel Acc Inference"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg"><meta property="article:published_time" content="2022-11-19T15:18:55.000Z"><meta property="article:modified_time" content="2022-11-19T13:00:26.146Z"><meta property="article:author" content="Miraclo"><meta property="article:tag" content="DeepLearning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/posts/45544"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"prismjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:2e3},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:500,languages:{author:"作者: Miraclo",link:"链接: ",source:"来源: Miraclo’s Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"语义分割-00-语义分割基础",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-11-19 13:00:26"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouth.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">128</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-film"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/DL-record/"><i class="fa-fw fas fa-trophy"></i><span> 深度学习记录</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-film"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/DL-record/"><i class="fa-fw fas fa-trophy"></i><span> 深度学习记录</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">语义分割-00-语义分割基础</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2022-11-19T15:18:55.000Z" title="发表于 2022-11-19 15:18:55">2022-11-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/3%E3%80%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%AF%87/">3、语义分割篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="语义分割-00-语义分割基础"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="常见的分割任务">1. 常见的分割任务</h1><ol type="1"><li>语义分割 (Semantic Segmentation) -&gt; FCN</li><li>实例分割 (Instance Segmentation) -&gt; Mask R-CNN</li><li>全景分割 (Panoramic Segmentation) -&gt; Panoptic FPN</li></ol><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191522079.png"></p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191522267.png"></p><h1 id="暂定的学习规划">2. 暂定的学习规划</h1><table><thead><tr class="header"><th>Model</th><th>mIoU</th><th>Global Pixel Acc</th><th>Inference on CPU (sec)</th><th>Params (M)</th></tr></thead><tbody><tr class="odd"><td><strong>LR-ASPP</strong> MobileNetV3-Large</td><td>57.9</td><td>91.2</td><td>0.3278</td><td>3.22</td></tr><tr class="even"><td><strong>DeepLabV3</strong> MobileNetV3-Large</td><td>60.3</td><td>91.2</td><td>0.5869</td><td>11.03</td></tr><tr class="odd"><td><strong>FCN</strong> MobileNetV3-Large (not released)</td><td>57.8</td><td>90.9</td><td>0.3702</td><td>5.05</td></tr><tr class="even"><td><strong>DeepLabV3</strong> ResNet50</td><td>66.4</td><td>92.4</td><td>6.3531</td><td>39.64</td></tr><tr class="odd"><td><strong>FCN</strong> ResNet50</td><td>60.5</td><td>91.4</td><td>5.0146</td><td>32.96</td></tr></tbody></table><h1 id="语义分割任务常见数据格式">3. 语义分割任务常见数据格式</h1><h2 id="pascal-voc">3.1 PASCAL VOC</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191522378.png"></p><p>PASCAL VOC中提供了分割数据集, 数据集中的图片对应标签存储格式为PNG (如右图所示), 标签图片中记录了每一个像素所属的类别信息. 需要注意的是, 右图所展示的图片是使用调色板实现的彩色, 它本质上是一个单通道的黑白图片.</p><p>那么这样是怎么实现的呢? 我们知道, 黑白图片每个像素的范围为 0 ~ 255, 那么不同值的像素就对应不同的颜色. 比如:</p><ul><li>像素0对应的是 (0, 0, 0) -&gt; 黑色</li><li>像素1对应的是 (127, 0, 0) -&gt; 深红色</li><li>像素255对应的是 (224, 224, 129) -&gt; 灰色(特殊颜色)</li></ul><p>这样, 不同值的像素就可以对应不同的颜色, 那么一张单通道黑白图就可以显示出彩色.</p><blockquote><p>在使用Python的PIL读取灰度图时, 默认使用调色板, 即P模式.</p></blockquote><p>除了上述需要明白的, 还有一些需要注意的点:</p><ol type="1"><li>目标的边缘会用特殊的颜色进行区分</li><li>图片中的特殊区域也会用该颜色进行填充</li></ol><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191524007.png"></p><p>特殊颜色标注位置对应像素的值是255, 在网络训练时, Loss的计算会忽略像素值为255的地方, 这么做的原因是:</p><ol type="1"><li>对于目标边缘到底属于那个部分, 并不好区分.</li><li>对于一些不好分割的目标, 使用该颜色进行填充, 以降低难度</li></ol><h2 id="ms-coco">3.2 MS COCO</h2><p>MS COCO数据集针对图像中的每一个目标都记录了多边形坐标 (polygons)</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191527465.png"></p><p>可以看到, COCO中所有目标的轮廓都用多边形坐标展示出来了, 在使用MS COCO数据集时, 我们需要将多边形信息解码为PNG图片 (所期望的P模式PNG图片).</p><blockquote><p>因为COCO划分的过于详细, 所以数据集不光可以做语义分割, 还可以做实例分割.</p></blockquote><h1 id="语义分割得到结果的具体形式">4. 语义分割得到结果的具体形式</h1><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191530639.png"></p><blockquote><p>用调色板是方便看, 不然真的用灰度图的话, 0 ~ 255, 人眼很难区分的.</p></blockquote><h1 id="常见语义分割评价指标">5. 常见语义分割评价指标</h1><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191532225.png"></p><p>举个例子：</p><p>写出混淆矩阵</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191652792.png"></p><p>根据混淆矩阵进行计算：</p><p><code>global_accuracy</code> = 预测正确的像素个数 ÷ 所有像素总个数</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191651093.png"></p><p><code>clsi_acc</code>每个类别的正确率 = 该类别预测正确的像素个数 ÷ 真实像素个数</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191653101.png"></p><p><code>mean IoU</code> = 该类别预测正确的像素个数 ÷ (真实像素个数+预测像素个数-预测正确的像素个数(分子)）</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191655021.png"></p><h1 id="语义分割标注工具">6. 语义分割标注工具</h1><h2 id="labelme---纯手工">6.1 Labelme -&gt; 纯手工</h2><p>代码地址: https://github.com/wkentaro/labelme</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191656707.png"></p><h2 id="eiseg---半自动">6.2 EISeg -&gt; 半自动</h2><p>代码地址: https://github.com/PaddlePaddle/PaddleSeg</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191656248.png"></p><p>该标注软件是一个半自动的标注工具, 里面内置了一些预训练模型, 可以使用AI帮助我们标注.</p><blockquote><p>百度的标注工具对于日常中常见的目标来说, 是极为高效的, 如果自定义数据集中的目标相对罕见, 那么EISeg和Labelme其实是差不多的.</p></blockquote><h1 id="转置卷积">7. 转置卷积</h1><p><strong>转置卷积（Transposed Convolution）</strong> 在语义分割或者对抗神经网络（GAN）中比较常见，其主要作用就是做上采样（<strong>UpSampling</strong>）。在有些地方转置卷积又被称作<strong>fractionally-strided convolution</strong>或者<strong>deconvolution</strong>，但<strong>deconvolution</strong>具有误导性，不建议使用。对于转置卷积需要注意的是：</p><ul><li>转置卷积不是卷积的逆运算、不是逆运算、不是逆运算（重要的事情说三遍）</li><li>转置卷积也是卷积</li></ul><h2 id="卷积操作">卷积操作</h2><p>首先回顾下普通卷积，下图以stride=1，padding=0，kernel_size=3为例，假设输入特征图大小是4x4的（假设输入输出都是单通道），通过卷积后得到的特征图大小为2x2。一般使用卷积的情况中，要么特征图变小（stride &gt; 1），要么保持不变（stride = 1），当然也可以通过四周padding让特征图变大但没有意义。关于卷积的详细介绍可以参考我之前的<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/102926037">博文</a>。 <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191741950.gif"></p><h2 id="转置卷积操作">转置卷积操作</h2><p>转置卷积刚刚说了，主要作用就是起到上采样的作用。但转置卷积不是卷积的逆运算（一般卷积操作是不可逆的），它只能恢复到原来的大小（shape）数值与原来不同。转置卷积的运算步骤可以归为以下几步：</p><ul><li><strong>在输入特征图元素间填充<code>s-1</code>行、列0（其中s表示转置卷积的步距）</strong></li><li><strong>在输入特征图四周填充<code>k-p-1</code>行、列0（其中k表示转置卷积的kernel_size大小，p为转置卷积的padding，注意这里的padding和卷积操作中有些不同）</strong></li><li><strong>将卷积核参数上下、左右翻转</strong></li><li><strong>做正常卷积运算（填充0，步距1）</strong></li></ul><p>下面假设输入的特征图大小为<code>2x2</code>（假设输入输出都为单通道），通过转置卷积后得到<code>4x4</code>大小的特征图。这里使用的转置卷积核大小为k=3，stride=1，padding=0的情况（忽略偏执bias）。</p><ul><li>首先在元素间填充s-1=0行、列0（等于0不用填充）</li><li>然后在特征图四周填充k-p-1=2行、列0</li><li>接着对卷积核参数进行上下、左右翻转</li><li>最后做正常卷积（填充0，步距1）</li></ul><figure><img src="https://img-blog.csdnimg.cn/017613b26bcd47aa98f9a5b41884b926.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5aSq6Ziz6Iqx55qE5bCP57u_6LGG,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><p>下图展示了转置卷积中不同s和p的情况：</p><table><thead><tr class="header"><th><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191743766.gif"></th><th><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191743402.gif"></th><th><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191743841.gif"></th></tr></thead><tbody><tr class="odd"><td>s=1, p=0, k=3</td><td>s=2, p=0, k=3</td><td>s=2, p=1, k=3</td></tr></tbody></table><p>转置卷积操作后特征图的大小可以通过如下公式计算：</p><ul><li>$H_{out} =(H_{in}-1) - 2 + {} $</li><li><span class="math inline">\(W_{out} =(W_{in}-1) \times {\rm stride[1]} - 2 \times {\rm padding[1]}+ {\rm kernel \_ size[1]}\)</span></li><li>其中stride[0]表示高度方向的stride，padding[0]表示高度方向的padding，kernel_size[0]表示高度方向的kernel_size，索引[1]都表示宽度方向上的。通过上面公式可以看出padding越大，输出的特征矩阵高、宽越小，<strong>你可以理解为正向卷积过程中进行了padding然后得到了特征图，现在使用转置卷积还原到原来高、宽后要把之前的padding减掉。</strong></li></ul><h2 id="pytorch中的转置卷积参数">Pytorch中的转置卷积参数</h2><p>pytorch官方关于转置卷积<code>ConvTranspose2d</code>的文档：https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html</p><p>官方原话： <code>Applies a 2D transposed convolution operator over an input image composed of several input planes.This module can be seen as the gradient of Conv2d with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation).</code></p><p>官方对转置卷积使用到的参数介绍：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191748737.png">上面讲的例子中已经介绍了<code>in_channels, out_channels, kernel_size, stride, padding</code>这几个参数了，在官方提供的方法中还有：</p><ul><li><code>output_padding</code>：在计算得到的输出特征图的高、宽方向各填充几行或列0（注意，这里只是在上下以及左右的一侧<code>one side</code>填充，并不是两侧都填充，有兴趣自己做个实验看下），默认为0不使用。</li><li><code>groups</code>：当使用到组卷积时才会用到的参数，默认为1即普通卷积。</li><li><code>bias</code>：是否使用偏执bias，默认为True使用。</li><li><code>dilation</code>：当使用到空洞卷积（膨胀卷积）时才会使用到的参数，默认为1即普通卷积。</li></ul><p>输出特征图宽、高计算：</p><ul><li><p><span class="math inline">\(H_{out} =(H_{in}-1) \times {\rm stride[0]} - 2 \times {\rm padding[0]}+ {\rm dilation[0]} \times ({\rm kernel \_ size[0]}-1) + {\rm output\_padding[0]}+1\)</span></p></li><li><p><span class="math inline">\(W_{out} =(W_{in}-1) \times {\rm stride[1]} - 2 \times {\rm padding[1]}+ {\rm dilation[1]} \times ({\rm kernel \_ size[1]}-1) + {\rm output\_padding[1]}+1\)</span></p></li></ul><hr><h2 id="pytorch转置卷积">Pytorch转置卷积</h2><h1 id="pytorch转置卷积实验">Pytorch转置卷积实验</h1><p>下面使用Pytorch框架来模拟s=1, p=0, k=3的转置卷积操作： <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs01/202211191750590.gif"></p><p>在代码中<code>transposed_conv_official</code>函数是使用官方的转置卷积进行计算，<code>transposed_conv_self</code>函数是按照上面讲的步骤自己对输入特征图进行填充并通过卷积得到的结果。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn


<span class="token keyword">def</span> <span class="token function">transposed_conv_official</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    feature_map <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>feature_map<span class="token punctuation">)</span>
    trans_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                                    kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    trans_conv<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"weight"</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                           <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>trans_conv<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
    output <span class="token operator">=</span> trans_conv<span class="token punctuation">(</span>feature_map<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">transposed_conv_self</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    feature_map <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>feature_map<span class="token punctuation">)</span>
    conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                     kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    conv<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"weight"</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                     <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                     <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>conv<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
    output <span class="token operator">=</span> conv<span class="token punctuation">(</span>feature_map<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    transposed_conv_official<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"---------------"</span><span class="token punctuation">)</span>
    transposed_conv_self<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>终端输出：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">2</span>., <span class="token number">1</span>.<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Parameter containing:
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">1</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">1</span>., <span class="token number">1</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">1</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">2</span>., <span class="token number">2</span>., <span class="token number">3</span>., <span class="token number">1</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">2</span>., <span class="token number">3</span>., <span class="token number">1</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">2</span>., <span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">grad_fn</span><span class="token operator">=</span><span class="token operator">&lt;</span>SlowConvTranspose2DBackward<span class="token operator">></span><span class="token punctuation">)</span>
---------------
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">2</span>., <span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Parameter containing:
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span>., <span class="token number">0</span>., <span class="token number">1</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">1</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">1</span>.<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">1</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">2</span>., <span class="token number">2</span>., <span class="token number">3</span>., <span class="token number">1</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">2</span>., <span class="token number">3</span>., <span class="token number">1</span>.<span class="token punctuation">]</span>,
          <span class="token punctuation">[</span><span class="token number">2</span>., <span class="token number">1</span>., <span class="token number">0</span>., <span class="token number">0</span>.<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">grad_fn</span><span class="token operator">=</span><span class="token operator">&lt;</span>ThnnConv2DBackward<span class="token operator">></span><span class="token punctuation">)</span>

Process finished with <span class="token builtin class-name">exit</span> code <span class="token number">0</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/posts/45544.html">http://unicorn-acc.github.io/posts/45544.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/51740.html"><img class="prev-cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">JVM系列-07-1、内存与垃圾回收篇---本地方法栈</div></div></a></div><div class="next-post pull-right"><a href="/posts/56362.html"><img class="next-cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python-10-文件</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/5074.html" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/posts/47625.html" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/posts/56670.html" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/posts/2490.html" title="图像分类_花分类数据集"><img class="cover" src="https://w.wallhaven.cc/full/p9/wallhaven-p9273e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-06</div><div class="title">图像分类_花分类数据集</div></div></a></div><div><a href="/posts/64179.html" title="图像分类_00_LeNet_Pytorch官方示例"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_00_LeNet_Pytorch官方示例</div></div></a></div><div><a href="/posts/5932.html" title="目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)"><img class="cover" src="https://w.wallhaven.cc/full/1p/wallhaven-1pjml1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-17</div><div class="title">目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1"><span class="toc-text">1. 常见的分割任务</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9A%82%E5%AE%9A%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%92"><span class="toc-text">2. 暂定的学习规划</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="toc-text">3. 语义分割任务常见数据格式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#pascal-voc"><span class="toc-text">3.1 PASCAL VOC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ms-coco"><span class="toc-text">3.2 MS COCO</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%BE%97%E5%88%B0%E7%BB%93%E6%9E%9C%E7%9A%84%E5%85%B7%E4%BD%93%E5%BD%A2%E5%BC%8F"><span class="toc-text">4. 语义分割得到结果的具体形式</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-text">5. 常见语义分割评价指标</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7"><span class="toc-text">6. 语义分割标注工具</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#labelme---%E7%BA%AF%E6%89%8B%E5%B7%A5"><span class="toc-text">6.1 Labelme -&gt; 纯手工</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#eiseg---%E5%8D%8A%E8%87%AA%E5%8A%A8"><span class="toc-text">6.2 EISeg -&gt; 半自动</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF"><span class="toc-text">7. 转置卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C"><span class="toc-text">卷积操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C"><span class="toc-text">转置卷积操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pytorch%E4%B8%AD%E7%9A%84%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E5%8F%82%E6%95%B0"><span class="toc-text">Pytorch中的转置卷积参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pytorch%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF"><span class="toc-text">Pytorch转置卷积</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E5%AE%9E%E9%AA%8C"><span class="toc-text">Pytorch转置卷积实验</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const n of document.querySelectorAll('script[type^="math/tex"]')){var e=!!n.type.match(/; *mode=display/),e=new t.options.MathItem(n.textContent,t.inputJax[0],e),a=document.createTextNode("");n.parentNode.replaceChild(a,n),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],insertScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t.hasAttribute("display")?btf.wrap(t,"div",{class:"mathjax-overflow"}):btf.wrap(t,"span",{class:"mathjax-overflow"})})},"",!1]}}};const a=document.createElement("script");a.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script src="/js/mouth.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (57)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (20)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (15)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(33.333333333333336% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>