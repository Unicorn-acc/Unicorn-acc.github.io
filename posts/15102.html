<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>目标检测_02_SSD源码解析（如何对ResNet50网络的改动以及拓展） | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:type" content="article"><meta property="og:title" content="目标检测_02_SSD源码解析（如何对ResNet50网络的改动以及拓展）"><meta property="og:url" content="http://unicorn-acc.github.io/posts/15102.html"><meta property="og:site_name" content="Miraclo’s Blog"><meta property="og:description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg"><meta property="article:published_time" content="2022-11-16T10:12:19.000Z"><meta property="article:modified_time" content="2022-11-18T07:19:39.444Z"><meta property="article:author" content="Miraclo"><meta property="article:tag" content="DeepLearning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/posts/15102"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"prismjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:2e3},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:500,languages:{author:"作者: Miraclo",link:"链接: ",source:"来源: Miraclo’s Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"目标检测_02_SSD源码解析（如何对ResNet50网络的改动以及拓展）",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-11-18 07:19:39"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouth.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">目标检测_02_SSD源码解析（如何对ResNet50网络的改动以及拓展）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2022-11-16T10:12:19.000Z" title="发表于 2022-11-16 10:12:19">2022-11-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/2%E3%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AF%87/">2、目标检测篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>40分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="目标检测_02_SSD源码解析（如何对ResNet50网络的改动以及拓展）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>参考内容来自霹雳吧啦Wz</p><p>up主的b站链接：https://space.bilibili.com/18161609/channel/index</p><p>up主的github：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</p><p>up主的CSDN博客：https://blog.csdn.net/qq_37541097/article/details/103482003</p><p>文章参考：https://blog.csdn.net/weixin_44878336/category_11399973.html</p></blockquote><h1 id="引言">0. 引言</h1><h2 id="代码来源">0.1 代码来源</h2><p>代码来源：https://github.com/NVIDIA/DeepLearningExamples/tree/master/<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=PyTorch&amp;spm=1001.2101.3001.7020">PyTorch</a>/Detection/SSD</p><h2 id="代码改动">0.2 代码改动</h2><p>NVIDIA复现的代码中有很多前沿的新技术（tricks），比如<code>NVIDIA DALI</code>模块，该模块可以加速数据的读取和预处理。注意，虽然NVIDIA复现了该代码，但相关人员对代码进行了修改。</p><p>The SSD300 v1.1 model is based on the SSD: Single Shot MultiBox Detector paper, which describes SSD as “a method for detecting objects in images using a single deep neural network". The input size is fixed to 300x300.</p><blockquote><p>输入依然是300×300</p></blockquote><p>The main difference between this model and the one described in the paper is in the backbone. Specifically, the VGG model is obsolete and is replaced by the ResNet-50 model.</p><blockquote><p>没有继续使用论文中VGG-16作为backbone，而是使用ResNet-50。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161027133.png"></p><p>From the Speed/accuracy trade-offs for modern convolutional object detectors paper, the following <strong>enhancements</strong> were made to the backbone:</p><ul><li>The conv5_x, avgpool, fc and softmax layers were removed from the original classification model.</li><li>All strides in conv4_x are set to 1x1.</li></ul><blockquote><ul><li>移除ResNet-50最后一个残差结构(conv5_x)以及后面的结构</li><li><strong>对于conv4_x的第一个残差结构，将其stride都修改为1×1大小</strong> —— 这个残差结构里面有6个block，只有第一个block会对shape进行下采样，而我们只需要修改第一个残差结构的卷积核大小和步距为1 —— 那么特征图在经过这个残差结构后，特征图的shape不会发生变化（不影响通道数，因为通道数=卷积核的个数） <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161028699.png"> 之前在SSD理论上说过，经过backbone之后会让特征图经过一系列的卷积从而生成不同感受野的预测特征图。 输入图像经过backbone之后会生成第一个预测特征图</li></ul></blockquote><p>Detector heads are similar to the ones referenced in the paper, however, they are enhanced by additional BatchNorm layers after each convolution.</p><blockquote><p>检测器和原论文基本上一样，不同的是在每一个卷积层都引入了额外的BN层（在原论文的中，生成预测特征图的卷积是没有使用BN的）</p></blockquote><p>Additionally, we removed weight decay on every bias parameter and all the BatchNorm layer parameters as described in the Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes paper.</p><blockquote><p>此外，我们删除了每个偏差参数和所有 BatchNorm 层参数的权重衰减，如具有混合精度的高度可扩展深度学习训练系统：四分钟内训练 ImageNet 论文中所述。</p></blockquote><p>Training of SSD requires computational costly augmentations. To fully utilize GPUs during training we are using the NVIDIA DALI library to accelerate data preparation pipelines.</p><blockquote><p>SSD 的训练需要计算成本高昂的增强。 为了在训练期间充分利用 GPU，我们正在使用 NVIDIA DALI 库来加速数据预处理流程。 我们训练网络的时候基本上使用CPU对数据进行读取和预处理，然后再将数据传入GPUs进行模型的训练。 但这种方法有一个问题：<strong>训练模型的时候GPUs的利用率很低。出现这种问题的主要原因是数据的读取和预处理太慢了。CPU处理数据太慢了，而GPUs处理数据又太快了</strong>——GPUs处理好了这个batch的数据，而CPU还没准备好下一个batch的数据 —— GPUs空闲 -&gt; 导致GPUs利用率低 <strong>针对这个问题，NVIDIA提供了NVIDIA DALI包 —— 让GPUs处理数据</strong></p></blockquote><p>This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. Therefore, researchers can get results 2x faster than training without Tensor Cores, while experiencing the benefits of mixed precision training. This model is tested against each NGC monthly container release to ensure consistent accuracy and performance over time.</p><blockquote><p>该模型使用 Volta、Turing 和 NVIDIA Ampere GPU 架构上的 Tensor Cores 以混合精度进行训练。 因此，研究人员可以获得比没有 Tensor Cores 的训练快 2 倍的结果，同时体验混合精度训练的好处。 该模型针对每个 NGC 每月容器版本进行测试，以确保随着时间的推移保持一致的准确性和性能。 <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161034519.png" style="zoom:67%"> <img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161035875.png" style="zoom:67%"></p></blockquote><h2 id="代码使用注意事项">0.3 代码使用注意事项</h2><h3 id="环境配置">0.3.1 环境配置</h3><ul><li>Python 3.6/3.7/3.8</li><li>Pytorch 1.7.1</li><li>pycocotools(Linux:<code>pip install pycocotools</code>; Windows:<code>pip install pycocotools-windows</code>(不需要额外安装vs))</li><li>Ubuntu或Centos(不建议Windows)</li><li>最好使用GPU训练</li></ul><h3 id="文件结构">0.3.2 文件结构</h3><pre class="line-numbers language-none"><code class="language-none">├── src: 实现SSD模型的相关模块    
│     ├── resnet50_backbone.py   使用resnet50网络作为SSD的backbone  
│     ├── ssd_model.py           SSD网络结构文件 
│     └── utils.py               训练过程中使用到的一些功能实现
├── train_utils: 训练验证相关模块（包括cocotools）  
├── my_dataset.py: 自定义dataset用于读取VOC数据集    
├── train_ssd300.py: 以resnet50做为backbone的SSD网络进行训练    
├── train_multi_GPU.py: 针对使用多GPU的用户使用    
├── predict_test.py: 简易的预测脚本，使用训练好的权重进行预测测试    
├── pascal_voc_classes.json: pascal_voc标签文件    
├── plot_curve.py: 用于绘制训练过程的损失以及验证集的mAP
└── validation.py: 利用训练好的权重验证&#x2F;测试数据的COCO指标，并生成record_mAP.txt文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="预训练权重下载地址下载后放入src文件夹中">0.3.3 预训练权重下载地址（下载后放入src文件夹中）：</h3><ul><li>ResNet50+SSD: https://ngc.nvidia.com/catalog/models<br><code>搜索ssd -&gt; 找到SSD for PyTorch(FP32) -&gt; download FP32 -&gt; 解压文件</code></li><li>如果找不到可通过百度网盘下载，链接:https://pan.baidu.com/s/1byOnoNuqmBLZMDA0-lbCMQ 提取码:iggj</li></ul><h3 id="数据集本例程使用的是pascal-voc2012数据集下载后放入项目当前文件夹中">0.3.4 数据集，本例程使用的是PASCAL VOC2012数据集(下载后放入项目当前文件夹中)</h3><ul><li>Pascal VOC2012 train/val数据集下载地址：http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar</li><li>Pascal VOC2007 test数据集请参考：http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar</li><li>如果不了解数据集或者想使用自己的数据集进行训练，请参考我的bilibili：https://b23.tv/F1kSCK</li></ul><h3 id="训练方法">0.3.5 训练方法</h3><ul><li>确保提前准备好数据集</li><li>确保提前下载好对应预训练模型权重</li><li>单GPU训练或CPU，直接使用train_ssd300.py训练脚本</li><li>若要使用多GPU训练，使用 "python -m torch.distributed.launch --nproc_per_node=8 --use_env train_multi_GPU.py" 指令,nproc_per_node参数为使用GPU数量</li><li>训练过程中保存的<code>results.txt</code>是每个epoch在验证集上的COCO指标，前12个值是COCO指标，后面两个值是训练平均损失以及学习率</li></ul><p><strong>如果对SSD算法原理不是很理解可参考我的bilibili</strong></p><ul><li>https://www.bilibili.com/video/BV1fT4y1L7Gi</li></ul><p><strong>进一步了解该项目，以及对SSD算法代码的分析可参考我的bilibili</strong></p><ul><li>https://www.bilibili.com/video/BV1vK411H771/</li></ul><h3 id="训练结果展示">0.3.6 训练结果展示</h3><p>SSD算法和Faster R-CNN检测精度差不多。对于小的数据集，Faster R-CNN的检测精度应该比SSD高；当数据集很大时，Faster R-CNN和SSD的检测精度是差不多的。 SSD的检测速度比Faster R-CNN要快很多</p><ul><li>Faster R-CNN在单张GPU上大概每秒能检测6~7张图片</li><li>SSD在单张GPU上大概每秒能检测50~60张图片</li></ul><blockquote><p>Note：</p><ul><li>相比使用了FPN（特征金字塔）的Faster R-CNN而言，SSD的检测精度要差很多</li><li>但后面有一个模型是SSD+FPN，名为<strong>RetinaNet</strong> -&gt; 使用ResNet和FPN作为检测模型的backbone，相比使用了FPN的Faster R-CNN而言，检测精度差不多，但速度提升很多</li><li>对于我们真正的生产环境，如果真的要使用目标检测模型其实还需要做很多后续的工作。 + 模式使用GPU进行训练，需将模型转换为TensorRT的格式（检测速度还会提升）</li></ul></blockquote><h1 id="一ssd代码">一、SSD代码</h1><h2 id="ssd框架示意图">1.1 SSD框架示意图</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161033874.png"></p><h2 id="ssd网络的搭建--ssd_model.py">1.2 SSD网络的搭建- ssd_model.py</h2><h3 id="修改backboneresnet-50">1.2.1 修改backbone（ResNet-50）</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Backbone</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrain_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Backbone<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        net <span class="token operator">=</span> resnet50<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 引入resnet50模型</span>
        self<span class="token punctuation">.</span>out_channels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token comment"># 对应每一个预测特征图的channels</span>

        <span class="token keyword">if</span> pretrain_path <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># 加载预训练权重</span>
            net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>pretrain_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 构建backbone（截止到conv4_x） *******</span>
        <span class="token triple-quoted-string string">"""
            net.children():
                net: 实例化的ResNet-50网络
                children()：网络下一层所有的子模块（简单理解为，只要是`nn.xxx`构建的层结构都可以认为是它的子模块）
            
            *list(net.children())[:7]
                先将net.children()得到的子模块使用list接收
                对list进行切片，只取前7个子模块（0, 1, 2, ..., 6）
                    ① conv1; ② bn1; ③ relu; ④ maxpool; ⑤ layer1; ⑥ layer2; ⑦ layer3
                再将list进行解包送给nn.Sequential完成网络的重构（后面的就都不要了）
        """</span>   
        self<span class="token punctuation">.</span>feature_extractor <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment"># 获得Conv4_x中的第一个block（feature_extractor -1 表示最后一层layer4，0表示layer4中第一个模块block1）</span>
        conv4_block1 <span class="token operator">=</span> self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token comment"># 修改conv4_block1的步距，从2->1</span>
        conv4_block1<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>stride <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 1×1卷积的步距，对于ResNet-50没必要，但对于ResNet-18/34是有必要的</span>
        conv4_block1<span class="token punctuation">.</span>conv2<span class="token punctuation">.</span>stride <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 3×3卷积的步距</span>
        conv4_block1<span class="token punctuation">.</span>downsample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>stride <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 捷径路径上的步距</span>


    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
    
<span class="token comment"># resnet50----------------------------------------------------------------------</span>
<span class="token keyword">class</span> <span class="token class-name">ResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> blocks_num<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ResNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>include_top <span class="token operator">=</span> include_top
        self<span class="token punctuation">.</span>in_channel <span class="token operator">=</span> <span class="token number">64</span>
		<span class="token comment"># conv1 - relu对应SSD中的Conv1</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                               padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token comment"># maxpool - layer1 对应Conv2</span>
        self<span class="token punctuation">.</span>maxpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># layer2对应Conv2  layer3对应Conv3</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> blocks_num<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>include_top<span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="搭建ssd网络">1.2.2 搭建SSD网络</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SSD300</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> backbone<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SSD300<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> backbone <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">"backbone is None"</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>backbone<span class="token punctuation">,</span> <span class="token string">"out_channels"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">"the backbone not has attribute: out_channel"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>feature_extractor <span class="token operator">=</span> backbone

        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        <span class="token comment"># out_channels = [1024, 512, 512, 256, 256, 256] for resnet50</span>
        self<span class="token punctuation">.</span>_build_additional_features<span class="token punctuation">(</span>self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">.</span>out_channels<span class="token punctuation">)</span>
        <span class="token comment"># 每一个Default box的scale（即box的生成数量） —— 在每个预测特征图上生成多少个Default Box</span>
        self<span class="token punctuation">.</span>num_defaults <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>
        location_extractors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 存储回归预测器（目标位置）</span>
        confidence_extractors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 存储置信度预测器（目标分数预测器）</span>

        <span class="token comment"># 构建后面一系列的特征提取层（为了生成不同的预测特征图）</span>
        <span class="token comment"># out_channels = [1024, 512, 512, 256, 256, 256] for resnet50</span>
        <span class="token keyword">for</span> nd<span class="token punctuation">,</span> oc <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_defaults<span class="token punctuation">,</span> self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">.</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># nd is number_default_boxes, oc is output_channel</span>
            <span class="token comment"># oc, nd * 4 : 输入为上一层的outputchannel，输出为预测的4个参数（坐标+偏移量）</span>
            location_extractors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>oc<span class="token punctuation">,</span> nd <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment"># oc, nd * self.num_classes : 输入输入为上一层的outputchannel，输出为几个类别的分数</span>
            confidence_extractors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>oc<span class="token punctuation">,</span> nd <span class="token operator">*</span> self<span class="token punctuation">.</span>num_classes<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>loc <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>location_extractors<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conf <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>confidence_extractors<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_init_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

        default_box <span class="token operator">=</span> dboxes300_coco<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>compute_loss <span class="token operator">=</span> Loss<span class="token punctuation">(</span>default_box<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>default_box<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>postprocess <span class="token operator">=</span> PostProcess<span class="token punctuation">(</span>default_box<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_build_additional_features</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        为backbone(resnet50)添加额外的一系列卷积层，得到相应的一系列特征提取器
        :param input_size:
        :return:
        """</span>
        additional_blocks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># input_size = [1024, 512, 512, 256, 256, 256] for resnet50</span>
        middle_channels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span>
        <span class="token triple-quoted-string string">"""
        input_channel = input_size[:-1]= [1024, 512, 512, 256, 256, 256]
        output_channel = input_size[1:]=[512, 512, 256, 256, 256]
        """</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_ch<span class="token punctuation">,</span> output_ch<span class="token punctuation">,</span> middle_ch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>input_size<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> middle_channels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 前三个索引,padding=1, stride=2; 最后两个索引：padding=0, stride=1</span>
            padding<span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i <span class="token operator">&lt;</span> <span class="token number">3</span> <span class="token keyword">else</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                 <span class="token comment"># 因为使用了BN层，所以将bias设置为False</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_ch<span class="token punctuation">,</span> middle_ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>middle_ch<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token comment"># 迭代结果不同就是这个卷积的stride和padding</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>middle_ch<span class="token punctuation">,</span> output_ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>output_ch<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
            additional_blocks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>additional_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>additional_blocks<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_init_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">*</span>self<span class="token punctuation">.</span>additional_blocks<span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>loc<span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>conf<span class="token punctuation">]</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
            <span class="token keyword">for</span> param <span class="token keyword">in</span> layer<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> param<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>
                    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>param<span class="token punctuation">)</span>

    <span class="token comment"># Shape the classifier to the view of bboxes</span>
    <span class="token keyword">def</span> <span class="token function">bbox_view</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">,</span> loc_extractor<span class="token punctuation">,</span> conf_extractor<span class="token punctuation">)</span><span class="token punctuation">:</span>
         <span class="token triple-quoted-string string">"""
        通过bbox_view()这个方法得到所有预测特征图上预测的回归参数和置信度得分
            参数：
                detection_features：预测特征图的list
                self.loc: 回归预测器
                self.conf: 置信度预测器
            返回值：
                locs： 每个box的回归参数
                confs：每个box的类别（置信度）分数
        """</span>
        locs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        confs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> f<span class="token punctuation">,</span> l<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> loc_extractor<span class="token punctuation">,</span> conf_extractor<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># [batch, n*4, feat_size, feat_size] -> [batch, 4, -1] = [BS, 4, n*feat_size*feat_size]</span>
            <span class="token comment"># [BS, 4, n*feat_size*feat_size] = [BS, 4个回归参数, 当前预测特征图所有的Default box数量]</span>
            <span class="token comment"># l(f) -> 得到location回归参数</span>
            locs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>l<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>f<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment"># [batch, n*classes, feat_size, feat_size] -> [batch, classes, -1] -> [BS, classes, n*feat_size*feat_size]</span>
            <span class="token comment"># c(f) -> 得到confidence参数</span>
            confs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>f<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_classes<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		<span class="token triple-quoted-string string">"""
		torch.cat(locs, 2)：将locs在idx=2位置(n*feat_size*feat_size)进行拼接
        使用view()方法时并不会改变原始数据存储的方式，所以需要调用contiguous()来将数据调整为存储连续的tensor
        """</span>
        locs<span class="token punctuation">,</span> confs <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>locs<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>confs<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> locs<span class="token punctuation">,</span> confs

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># image：打包好的一批图片数据</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>feature_extractor<span class="token punctuation">(</span>image<span class="token punctuation">)</span> <span class="token comment"># [1024, 38, 38]</span>

        <span class="token comment"># Feature Map 38x38x1024, 19x19x512, 10x10x512, 5x5x256, 3x3x256, 1x1x256</span>
        detection_features <span class="token operator">=</span> torch<span class="token punctuation">.</span>jit<span class="token punctuation">.</span>annotate<span class="token punctuation">(</span>List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># [x]存储每一个预测特征图的list</span>
        <span class="token comment"># 收集每一个预测特征层的输出 </span>
        detection_features<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># Feature Map1添加到list中</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>additional_blocks<span class="token punctuation">:</span> <span class="token comment"># 遍历得到Feature Map2~6</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            detection_features<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment"># Feature Map 38x38x4, 19x19x6, 10x10x6, 5x5x6, 3x3x4, 1x1x4</span>
        locs<span class="token punctuation">,</span> confs <span class="token operator">=</span> self<span class="token punctuation">.</span>bbox_view<span class="token punctuation">(</span>detection_features<span class="token punctuation">,</span> self<span class="token punctuation">.</span>loc<span class="token punctuation">,</span> self<span class="token punctuation">.</span>conf<span class="token punctuation">)</span>

        <span class="token comment"># For SSD 300, shall return nbatch x 8732 x &#123;nlabels, nlocs&#125; results</span>
        <span class="token comment"># 38x38x4 + 19x19x6 + 10x10x6 + 5x5x6 + 3x3x4 + 1x1x4 = 8732</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>
            <span class="token keyword">if</span> targets <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"In training mode, targets should be passed"</span><span class="token punctuation">)</span>
            <span class="token comment"># bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)</span>
            bboxes_out <span class="token operator">=</span> targets<span class="token punctuation">[</span><span class="token string">'boxes'</span><span class="token punctuation">]</span>
            bboxes_out <span class="token operator">=</span> bboxes_out<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># print(bboxes_out.is_contiguous())</span>
            labels_out <span class="token operator">=</span> targets<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>
            <span class="token comment"># print(labels_out.is_contiguous())</span>

            <span class="token comment"># ploc, plabel, gloc, glabel</span>
            loss <span class="token operator">=</span> self<span class="token punctuation">.</span>compute_loss<span class="token punctuation">(</span>locs<span class="token punctuation">,</span> confs<span class="token punctuation">,</span> bboxes_out<span class="token punctuation">,</span> labels_out<span class="token punctuation">)</span>
            <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">"total_losses"</span><span class="token punctuation">:</span> loss<span class="token punctuation">&#125;</span>

        <span class="token comment"># 将预测回归参数叠加到default box上得到最终预测box，并执行非极大值抑制虑除重叠框</span>
        <span class="token comment"># results = self.encoder.decode_batch(locs, confs)</span>
        results <span class="token operator">=</span> self<span class="token punctuation">.</span>postprocess<span class="token punctuation">(</span>locs<span class="token punctuation">,</span> confs<span class="token punctuation">)</span>
        <span class="token keyword">return</span> results<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="default-box的生成">1.3 Default Box的生成</h2><p>Default Box的scale以及aspect设定：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161015277.png"></p><p>根据scale和aspect求得每个特征图的Default Box和数量</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161015937.png"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DefaultBoxes</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    这个类专门用来生成Default Box
        参数：
            fig_size：输入网络的图片大小 -> 300
            feat_size：每个预测特征图的尺寸(6个预测特征图 -> [38, 19, 10, 5, 3, 1])
            step: 每个在预测特征图上的cell在原图上的跨度 -> [8, 16, 32, 64, 100, 300]
            scales: 就是理论部分讲的scale -> [21, 45, 99, 153, 207, 261, 315]
            aspect_ratio: 每个预测特征图所使用的比例 -> [[2], [2, 3], [2, 3], [2, 3], [2], [2]]
                有6个预测特征图，所以这个大的list有6个元素
                为了方便就没有把1:1这个比例写进去
            scale_xy, scale_wh: 在论文中没有提到，但在源码是有这两个参数的。 可以理解为是一个trick，在损失函数部分会进一步讲解
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> fig_size<span class="token punctuation">,</span> feat_size<span class="token punctuation">,</span> steps<span class="token punctuation">,</span> scales<span class="token punctuation">,</span> aspect_ratios<span class="token punctuation">,</span> scale_xy<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> scale_wh<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fig_size <span class="token operator">=</span> fig_size   <span class="token comment"># 输入网络的图像大小 300</span>
        <span class="token comment"># [38, 19, 10, 5, 3, 1]</span>
        self<span class="token punctuation">.</span>feat_size <span class="token operator">=</span> feat_size  <span class="token comment"># 每个预测层的feature map尺寸</span>

        self<span class="token punctuation">.</span>scale_xy_ <span class="token operator">=</span> scale_xy
        self<span class="token punctuation">.</span>scale_wh_ <span class="token operator">=</span> scale_wh

        <span class="token comment"># According to https://github.com/weiliu89/caffe</span>
        <span class="token comment"># Calculation method slightly different from paper</span>
        <span class="token comment"># [8, 16, 32, 64, 100, 300]</span>
        self<span class="token punctuation">.</span>steps <span class="token operator">=</span> steps    <span class="token comment"># 每个特征层上的一个cell在原图上的跨度</span>

        <span class="token comment"># [21, 45, 99, 153, 207, 261, 315]</span>
        self<span class="token punctuation">.</span>scales <span class="token operator">=</span> scales  <span class="token comment"># 每个特征层上预测的default box的scale</span>

        fk <span class="token operator">=</span> fig_size <span class="token operator">/</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>     <span class="token comment"># 计算每层特征层的fk</span>
        <span class="token comment"># [[2], [2, 3], [2, 3], [2, 3], [2], [2]]</span>
        self<span class="token punctuation">.</span>aspect_ratios <span class="token operator">=</span> aspect_ratios  <span class="token comment"># 每个预测特征层上预测的default box的ratios</span>

        self<span class="token punctuation">.</span>default_boxes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 存储后面生成的Default box的坐标信息</span>
        <span class="token comment"># size of feature and number of feature</span>
        <span class="token comment"># 遍历每层特征层，计算default box</span>
        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> sfeat <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>feat_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># sk1本层的尺度，sk2下一层的尺度，对应上图中scale的内容</span>
            sk1 <span class="token operator">=</span> scales<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">/</span> fig_size  <span class="token comment"># scale转为相对值[0-1]</span>
            sk2 <span class="token operator">=</span> scales<span class="token punctuation">[</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/</span> fig_size  <span class="token comment"># scale转为相对值[0-1]</span>
            sk3 <span class="token operator">=</span> sqrt<span class="token punctuation">(</span>sk1 <span class="token operator">*</span> sk2<span class="token punctuation">)</span> <span class="token comment"># sk3  Default Box默认框尺寸</span>
            <span class="token comment"># 先添加两个1:1比例的default box宽和高</span>
            <span class="token triple-quoted-string string">"""
            添加了2个尺度的Default box
                尺度为sk1，比例为sk1:sk1 -> 1:1的Default box
                尺度为sk3，比例为sk3:sk3 -> 1:1的Default box
            """</span>
            all_sizes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>sk1<span class="token punctuation">,</span> sk1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>sk3<span class="token punctuation">,</span> sk3<span class="token punctuation">)</span><span class="token punctuation">]</span>

            <span class="token comment"># 再将剩下不同比例的default box宽和高添加到all_sizes中</span>
            <span class="token keyword">for</span> alpha <span class="token keyword">in</span> aspect_ratios<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token comment"># 高宽  sk1 * 根号2 / sk1 /根号2 = 2，开根为了保证不同形状的box面积相同</span>
                w<span class="token punctuation">,</span> h <span class="token operator">=</span> sk1 <span class="token operator">*</span> sqrt<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span><span class="token punctuation">,</span> sk1 <span class="token operator">/</span> sqrt<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span>  
                <span class="token comment"># 使用append保证W/h比例为aplha，也就是aspect_radios中的数值</span>
                all_sizes<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 2: 1 </span>
                all_sizes<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 1: 2</span>

            <span class="token comment"># 计算当前特征层对应原图上的所有default box</span>
            <span class="token keyword">for</span> w<span class="token punctuation">,</span> h <span class="token keyword">in</span> all_sizes<span class="token punctuation">:</span>
                <span class="token triple-quoted-string string">"""
                    >>> import itertools
                    >>> for i, j in itertools.product(range(3), repeat=2):\
                    ... print((i, j))
                    ... 
                    (0, 0)  # 第0行的第0个cell
                    (0, 1)  # 第0行的第1个cell
                    (0, 2)  # 第0行的第2个cell
                    (1, 0)  # 第1行的第0个cell
                    (1, 1)  # 第1行的第1个cell
                    (1, 2)
                    (2, 0)
                    (2, 1)
                    (2, 2)
                """</span>
                <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> itertools<span class="token punctuation">.</span>product<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>sfeat<span class="token punctuation">)</span><span class="token punctuation">,</span> repeat<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># i -> 行（y）， j -> 列（x）</span>
                    <span class="token comment"># 计算每个default box的中心坐标（范围是在0-1之间）</span>
                    <span class="token triple-quoted-string string">"""
            Q：为什么i和j要加0.5
            A：这是因为i和j说白了就是预测特征图上每一个像素点的坐标，像素点长为1宽也为1（这就是一个cell），这个没有什么问题
               我们想要知道这个cell的中心坐标，而在图像中，坐标原点是在左上角，横坐标向右为正，纵坐标向下为正
               所以i+0.5就是这个cell的行坐标，j+0.5就是这个cell的纵坐标
                    """</span>
                    cx<span class="token punctuation">,</span> cy <span class="token operator">=</span> <span class="token punctuation">(</span>j <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">/</span> fk<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">/</span> fk<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
                    self<span class="token punctuation">.</span>default_boxes<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>cx<span class="token punctuation">,</span> cy<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 中心点坐标、宽高都是相对坐标</span>
                    <span class="token comment"># 效果如下图所示</span>
        
        <span class="token comment"># 将default_boxes转为tensor格式</span>
        self<span class="token punctuation">.</span>dboxes <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>default_boxes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  <span class="token comment"># 这里不转类型会报错</span>
        self<span class="token punctuation">.</span>dboxes<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 将坐标（x, y, w, h）都限制在0-1之间</span>

        <span class="token comment"># For IoU calculation</span>
        <span class="token comment"># ltrb is left top coordinate and right bottom coordinate</span>
        <span class="token comment"># 将(x, y, w, h)转换成(xmin, ymin, xmax, ymax)，方便后续计算IoU(匹配正负样本时)</span>
        self<span class="token punctuation">.</span>dboxes_ltrb <span class="token operator">=</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([8732, 4]) -> 生成8732个Default box，每个Default box有4个坐标(x,y,w,h)</span>
        self<span class="token punctuation">.</span>dboxes_ltrb<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># xmin &lt;- x - w/2 = 左上角的x坐标</span>
        self<span class="token punctuation">.</span>dboxes_ltrb<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token comment"># ymin &lt;- y - h/2 = 左上角的y坐标</span>
        self<span class="token punctuation">.</span>dboxes_ltrb<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># xmax &lt;- w + w/2 = 右下角的x坐标</span>
        self<span class="token punctuation">.</span>dboxes_ltrb<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token comment"># ymax &lt;- h + h/2 = 右下角的y坐标</span>
	 	<span class="token triple-quoted-string string">"""
	 		到这里存储了两个变量：
            self.dboxes: x,y,w,h
            self.dboxes_ltrb: x1,y1,x2,y2
        """</span>
        
        
    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">scale_xy</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>scale_xy_

    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">scale_wh</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>scale_wh_

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> order<span class="token operator">=</span><span class="token string">'ltrb'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 根据需求返回对应格式的default box</span>
        <span class="token keyword">if</span> order <span class="token operator">==</span> <span class="token string">'ltrb'</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>dboxes_ltrb

        <span class="token keyword">if</span> order <span class="token operator">==</span> <span class="token string">'xywh'</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>dboxes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161350826.png" style="zoom:50%"></p><p>使用时使用<code>dboxes300_coco</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dboxes300_coco</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    figsize <span class="token operator">=</span> <span class="token number">300</span>  <span class="token comment"># 输入网络的图像大小</span>
    feat_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>   <span class="token comment"># 每个预测层的feature map尺寸</span>
    steps <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span>   <span class="token comment"># 每个特征层上的一个cell在原图上的跨度</span>
    <span class="token comment"># use the scales here: https://github.com/amdegroot/ssd.pytorch/blob/master/data/config.py</span>
    scales <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">153</span><span class="token punctuation">,</span> <span class="token number">207</span><span class="token punctuation">,</span> <span class="token number">261</span><span class="token punctuation">,</span> <span class="token number">315</span><span class="token punctuation">]</span>  <span class="token comment"># 每个特征层上预测的default box的scale</span>
    aspect_ratios <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token comment"># 每个预测特征层上预测的default box的ratios</span>
    dboxes <span class="token operator">=</span> DefaultBoxes<span class="token punctuation">(</span>figsize<span class="token punctuation">,</span> feat_size<span class="token punctuation">,</span> steps<span class="token punctuation">,</span> scales<span class="token punctuation">,</span> aspect_ratios<span class="token punctuation">)</span>
    <span class="token keyword">return</span> dboxes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="正负样本匹配">1.4 正负样本匹配</h2><p>调用位置，对数据集进行数据增广时<code>transforms.AssignGTtoDefaultBox()</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data_transform <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"train"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>SSDCropping<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>Normalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     transforms<span class="token punctuation">.</span>AssignGTtoDefaultBox<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"val"</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   transforms<span class="token punctuation">.</span>Normalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>transforms.AssignGTtoDefaultBox</code>：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AssignGTtoDefaultBox</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""将DefaultBox与GT进行匹配"""</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>default_box <span class="token operator">=</span> dboxes300_coco<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 创建DBox(最原生的8732）</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>self<span class="token punctuation">.</span>default_box<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>
        boxes <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token string">'boxes'</span><span class="token punctuation">]</span>  <span class="token comment"># GTBox的坐标信息</span>
        labels <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span>  <span class="token comment"># GTBox对应的labels</span>
        <span class="token comment"># bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)</span>
        <span class="token comment"># 通过self.encoder.encode()方法将DBox与GTBox进行匹配</span>
        bboxes_out<span class="token punctuation">,</span> labels_out <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>boxes<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        target<span class="token punctuation">[</span><span class="token string">'boxes'</span><span class="token punctuation">]</span> <span class="token operator">=</span> bboxes_out
        target<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels_out

        <span class="token keyword">return</span> image<span class="token punctuation">,</span> target
    
<span class="token keyword">def</span> <span class="token function">dboxes300_coco</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    figsize <span class="token operator">=</span> <span class="token number">300</span>  <span class="token comment"># 输入网络的图像大小</span>
    feat_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>   <span class="token comment"># 每个预测层的feature map尺寸</span>
    steps <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span>   <span class="token comment"># 每个特征层上的一个cell在原图上的跨度</span>
    <span class="token comment"># use the scales here: https://github.com/amdegroot/ssd.pytorch/blob/master/data/config.py</span>
    scales <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">153</span><span class="token punctuation">,</span> <span class="token number">207</span><span class="token punctuation">,</span> <span class="token number">261</span><span class="token punctuation">,</span> <span class="token number">315</span><span class="token punctuation">]</span>  <span class="token comment"># 每个特征层上预测的default box的scale</span>
    aspect_ratios <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token comment"># 每个预测特征层上预测的default box的ratios</span>
    dboxes <span class="token operator">=</span> DefaultBoxes<span class="token punctuation">(</span>figsize<span class="token punctuation">,</span> feat_size<span class="token punctuation">,</span> steps<span class="token punctuation">,</span> scales<span class="token punctuation">,</span> aspect_ratios<span class="token punctuation">)</span>
    <span class="token keyword">return</span> dboxes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>self.encoder.encode()</code>：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># This function is from https://github.com/kuangliu/pytorch-ssd.</span>
<span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
        Inspired by https://github.com/kuangliu/pytorch-src
        Transform between (bboxes, lables) &lt;-> SSD output

        dboxes: default boxes in size 8732 x 4,
            encoder: input ltrb format, output xywh format
            decoder: input xywh format, output ltrb format

        encode:
            input  : bboxes_in (Tensor nboxes x 4), labels_in (Tensor nboxes)
            output : bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)
            criteria : IoU threshold of bboexes

        decode:
            input  : bboxes_in (Tensor 8732 x 4), scores_in (Tensor 8732 x nitems)
            output : bboxes_out (Tensor nboxes x 4), labels_out (Tensor nboxes)
            criteria : IoU threshold of bboexes
            max_output : maximum number of output bboxes
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dboxes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>dboxes <span class="token operator">=</span> dboxes<span class="token punctuation">(</span>order<span class="token operator">=</span><span class="token string">'ltrb'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dboxes_xywh <span class="token operator">=</span> dboxes<span class="token punctuation">(</span>order<span class="token operator">=</span><span class="token string">'xywh'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>nboxes <span class="token operator">=</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># default boxes的数量</span>
        self<span class="token punctuation">.</span>scale_xy <span class="token operator">=</span> dboxes<span class="token punctuation">.</span>scale_xy
        self<span class="token punctuation">.</span>scale_wh <span class="token operator">=</span> dboxes<span class="token punctuation">.</span>scale_wh

    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bboxes_in<span class="token punctuation">,</span> labels_in<span class="token punctuation">,</span> criteria<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        encode:
            input  : bboxes_in (Tensor nboxes x 4), labels_in (Tensor nboxes)
            output : bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)
            criteria : IoU threshold of bboexes
            
            bboxes_in: GTBox的坐标信息
            labels_in： GTBox的标签信息
        """</span>
        <span class="token comment"># 计算每个GT与default box的iou</span>
        ious <span class="token operator">=</span> calc_iou_tensor<span class="token punctuation">(</span>bboxes_in<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">)</span>  <span class="token comment">#[nboxes, 8732]  </span>
        <span class="token comment"># 寻找每个default box匹配到的最大IoU。best_dbox_ious最大IOU值，best_dbox_idx最大IOU索引</span>
        best_dbox_ious<span class="token punctuation">,</span> best_dbox_idx <span class="token operator">=</span> ious<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># [8732,]  </span>
        <span class="token comment"># 寻找每个GT匹配到的最大IoU</span>
        best_bbox_ious<span class="token punctuation">,</span> best_bbox_idx <span class="token operator">=</span> ious<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [nboxes,]</span>

        <span class="token comment"># 将每个GT匹配到的最佳default box设置为正样本（对应论文中Matching strategy的第一条）</span>
        <span class="token triple-quoted-string string">"""
        Matching strategy：
            1. 用每一个GTBox与DBox求IoU（会将GTBox分配给与它IoU最大的DBox）
            2. 将IoU大于0.5的DBox设置为正样本
        """</span>
        <span class="token comment"># set best ious 2.0</span>
        <span class="token comment"># 将每个GTBox匹配到的最大IoU的DBox设置为正样本</span>
        <span class="token triple-quoted-string string">"""
            tensor.index_fill_(0, best_bbox_idx, 2.0):
                第一个参数： dim
                第二个参数： 需要填充的索引
                第三个参数： 需要填充的数值
            填充的数只要大于0.5都是可以的
        """</span>
        best_dbox_ious<span class="token punctuation">.</span>index_fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> best_bbox_idx<span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">)</span>  <span class="token comment"># dim, index, value</span>
        <span class="token comment"># 将相应default box匹配最大IOU的GT索引进行替换</span>
        idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> best_bbox_idx<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        best_dbox_idx<span class="token punctuation">[</span>best_bbox_idx<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> idx
		<span class="token triple-quoted-string string">"""
            做完上面这两个操作：
                best_dbox_idx和best_bbox_idx的对应关系就一致了
        """</span>
        
        <span class="token comment"># filter IoU > 0.5</span>
        <span class="token comment"># 寻找与GT iou大于0.5的default box,对应论文中Matching strategy的第二条(这里包括了第一条匹配到的信息)</span>
        masks <span class="token operator">=</span> best_dbox_ious <span class="token operator">></span> criteria
        <span class="token triple-quoted-string string">"""
            针对每一个Default Box而言，都已经被划分为正负样本了。
            接下来我们需要对划分为正样本的DBox所对应的GT的 标签和GTBox信息 提取出来，方便后续计算
            
            self.nboxes: DBox的数量
            labels_in：针对每一个GTBox的类别标签
            
            best_dbox_idx[masks]：将mask所有为True的数据取出来 -> 将划分为正样本的所有DBox对应的GTBox的索引取出来
            labels_in[best_dbox_idx[masks]]：再将对应GTBox的索引传去label_in中 -> 所有DBox对应GTBox的标签取出来
            
            在labels_in中，所有正样本的数值>0，所有负样本的数值=0（背景）
            
            这里找正样本DBox对应GTBox的标签，目的是找到DBox的标签（二者是一样的）
        """</span>
        <span class="token comment"># [8732,]</span>
        labels_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>nboxes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        labels_out<span class="token punctuation">[</span>masks<span class="token punctuation">]</span> <span class="token operator">=</span> labels_in<span class="token punctuation">[</span>best_dbox_idx<span class="token punctuation">[</span>masks<span class="token punctuation">]</span><span class="token punctuation">]</span>
        
        <span class="token triple-quoted-string string">"""
            上面两步将所有划分为正样本的DBox的标签取出来了，接下来我们还需要DBox对应GTBox的信息提出来（坐标信息）
            best_dbox_idx[masks]：拿到所有被划分到正样本的GTBox的索引
            bboxes_in[best_dbox_idx[masks]: 拿到针对每一个划分为正样本的DBox所对应GTBox的坐标信息
            (bboxes_in是GTBox的坐标信息)
            
            对于每一个DBox而言，如果它被划分为正样本，那么它的标签和坐标信息都是对应GTBox的标签和坐标的
                             如果它被划分为负样本的话，它的标签为0，它的坐标信息还是它原来的DBox坐标信息
        """</span>
        
        <span class="token comment"># 将default box匹配到正样本的位置设置成对应GT的box信息</span>
        bboxes_out <span class="token operator">=</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
        bboxes_out<span class="token punctuation">[</span>masks<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span>best_dbox_idx<span class="token punctuation">[</span>masks<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

        <span class="token comment"># Transform format to xywh format</span>
        x <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># x 左上+右下 /2 = 中心点x</span>
        y <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># y 左下+右上 /2 = 中心点y</span>
        w <span class="token operator">=</span> bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># w</span>
        h <span class="token operator">=</span> bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">-</span> bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># h</span>
        bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> x
        bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> y
        bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> w
        bboxes_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> h
        <span class="token keyword">return</span> bboxes_out<span class="token punctuation">,</span> labels_out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="loss的计算">1.5 Loss的计算</h2><p>在ssd_model中的<code>self.compute_loss = Loss(default_box)</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Loss</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
        Implements the loss as the sum of the followings:
        1. Confidence Loss: All labels, with hard negative mining
        2. Localization Loss: Only on positive labels
        Suppose input dboxes has the shape 8732x4
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dboxes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Args:
            dboxes:  utils中的 dboxes = DefaultBoxes(figsize, feat_size, steps, scales, aspect_ratios)
                即实例化的Default Box

            dboxes.scale_xy = 0.1
            dboxes.scale_wh = 0.2
        """</span>
        
        <span class="token builtin">super</span><span class="token punctuation">(</span>Loss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># Two factor are from following links</span>
        <span class="token comment"># http://jany.st/post/2017-11-05-single-shot-detector-ssd-from-scratch-in-tensorflow.html</span>
        self<span class="token punctuation">.</span>scale_xy <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> dboxes<span class="token punctuation">.</span>scale_xy  <span class="token comment"># 10</span>
        self<span class="token punctuation">.</span>scale_wh <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> dboxes<span class="token punctuation">.</span>scale_wh  <span class="token comment"># 5</span>
		
         <span class="token comment"># 定义计算定位的损失器 -> SmoothL1</span>
        self<span class="token punctuation">.</span>location_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span>
        <span class="token triple-quoted-string string">"""
            nn.Parameter：转化为PyTorch的参数
                参数：
                    ① data (Tensor) – parameter tensor.
                    ② requires_grad (bool, optional)    -> Default: True
                        if the parameter requires gradient. 
                        See Locally disabling gradient computation for more details. 
        """</span>
        <span class="token comment"># [num_anchors, 4] -> [4, num_anchors] -> [1, 4, num_anchors]</span>
        self<span class="token punctuation">.</span>dboxes <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>dboxes<span class="token punctuation">(</span>order<span class="token operator">=</span><span class="token string">"xywh"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        <span class="token comment"># 定义计算分类的损失器 -> Softmax + 交叉熵</span>
        self<span class="token punctuation">.</span>confidence_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_location_vec</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> loc<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># type: (Tensor) -> Tensor</span>
        <span class="token triple-quoted-string string">"""
        Generate Location Vectors
        计算ground truth相对anchors的回归参数
        :param loc: anchor匹配到的对应GTBOX Nx4x8732
        :return:
        """</span>
        gxy <span class="token operator">=</span> self<span class="token punctuation">.</span>scale_xy <span class="token operator">*</span> <span class="token punctuation">(</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># Nx2x8732</span>
        gwh <span class="token operator">=</span> self<span class="token punctuation">.</span>scale_wh <span class="token operator">*</span> <span class="token punctuation">(</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Nx2x8732</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>gxy<span class="token punctuation">,</span> gwh<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_location_vec</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> loc<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># type: (Tensor) -> Tensor</span>
        <span class="token triple-quoted-string string">"""
        - Generate Location Vectors —— 计算ground truth相对anchors的回归参数

        :param loc: anchor匹配到的对应GTBOX Nx4x8732

        计算公式：
            .. math::
                \begin&#123;aligned&#125;
                    &amp; x_&#123;回归&#125; = \frac&#123;x_&#123;gtbox&#125; - x_&#123;dbox&#125;&#125;&#123;w_&#123;dbox&#125;&#125; \\
                    &amp; y_&#123;回归&#125; = \frac&#123;y_&#123;gtbox&#125; - y_&#123;dbox&#125;&#125;&#123;h_&#123;dbox&#125;&#125; \\
                    &amp; w_&#123;回归&#125; = \ln(\frac&#123;w_&#123;gtbox&#125;&#125;&#123;w_&#123;dbox&#125;&#125;) \\
                    &amp; h_&#123;回归&#125; = \ln(\frac&#123;h_&#123;gtbox&#125;&#125;&#123;h_&#123;dbox&#125;&#125;) \\
                \end&#123;aligned&#125;

        .. note::
            - 这里我觉得是计算 `DBox的默认位置` 和 `所匹配到GTBox位置之间` 的差距，拿这个差距和DBox的预测回归参数进行比较，得到损失
            - 也就是说，这里计算的是DBox和GTBox的实际差距（偏离量），网络预测的回归参数是DBox应该位移的量，那这两个数去进行损失函数的计算是比较合理的
            - self.scale_xy（5）和self.scale_wh（10）是两个缩放因子
            - 这么做的原因可以理解为是一个trick -> 加速模型收敛

        :return: 返回DBox与GT的差距，shape为[BS, 4, 8732]
        """</span>
        gxy <span class="token operator">=</span> self<span class="token punctuation">.</span>scale_xy <span class="token operator">*</span> <span class="token punctuation">(</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># Nx2x8732</span>
        gwh <span class="token operator">=</span> self<span class="token punctuation">.</span>scale_wh <span class="token operator">*</span> <span class="token punctuation">(</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>dboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Nx2x8732</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>gxy<span class="token punctuation">,</span> gwh<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ploc<span class="token punctuation">,</span> plabel<span class="token punctuation">,</span> gloc<span class="token punctuation">,</span> glabel<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># type: (Tensor, Tensor, Tensor, Tensor) -> Tensor</span>
        <span class="token triple-quoted-string string">"""
            ploc, plabel: Nx4x8732, Nxlabel_numx8732
                predicted location and labels
                ① ploc：预测的回归参数
                ② plabel：预测的标签值

            gloc, glabel: Nx4x8732, Nx8732
                ground truth location and labels
                ① gloc：预处理过程中每个Default Box（这里应该叫anchor）所匹配到的GT box对应的坐标
                ② glabel：预处理过程中每个Default Box（这里应该叫anchor）所匹配到的GT box对应的标签
        """</span>
        <span class="token triple-quoted-string string">"""
            在预处理过程中会对每一个Dbox匹配和它对应的GTBox以及标签
                如果该DBox有匹配到GTBox -> 它的glabel肯定是一个>0的数
                如果该DBox没有匹配到GTBox -> 它的glabel被置为0（0对应的是背景）
                
            mask = torch.gt(glabel, 0)
                通过这个运算之后，就能得到所有匹配到GTBox的DBox
                mask是一个蒙版
        """</span>
        
        <span class="token comment"># 获取正样本的mask  Tensor: [N, 8732]</span>
        mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>gt<span class="token punctuation">(</span>glabel<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># (gt: >)</span>
        <span class="token comment"># mask1 = torch.nonzero(glabel)</span>
        <span class="token comment"># 计算一个batch中的每张图片的正样本个数 Tensor: [N]</span>
        pos_num <span class="token operator">=</span> mask<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># shape: [BS]：表明是求batch中每张图片正样本的数量</span>
        <span class="token triple-quoted-string string">"""
            [ 2, 10, 52, 27]  这里我们的BS=4，所以只有4张图片
                第一张图片匹配到的正样本个数为2
                第二张图片匹配到的正样本个数为10
                ...
        """</span>

        <span class="token triple-quoted-string string">"""
            计算每一个DBox所匹配到GTBox的location回归参数
                gloc：预处理过程中每个Default Box所匹配到的GT box对应的坐标
                    shape为[BS, 4, 8732] = [BS, 4个坐标, 所有的DBox]
        """</span>
        <span class="token comment"># 计算gt的location回归参数 Tensor: [N, 4, 8732]</span>
        vec_gd <span class="token operator">=</span> self<span class="token punctuation">.</span>_location_vec<span class="token punctuation">(</span>gloc<span class="token punctuation">)</span>

        
        
        
        <span class="token comment"># sum on four coordinates, and mask</span>
        <span class="token comment"># 计算定位损失(只有正样本)</span>
        <span class="token triple-quoted-string string">"""
            ploc： 预测的回归参数（DBox应该如何移动以更好的匹配GTBox）    [BS, 4, 8732]
            vec_gd：DBox一开始和匹配的的GTBox之间的偏移量              [BS, 4, 8732]
            
            vec_gd计算的是DBox和GTBox的实际差距（偏离量）
            网络预测的回归参数是DBox应该位移的量
            拿这两个数去进行损失函数的计算是比较合理的
            
            Note：
                定位损失应该只计算正样本的定义损失，负样本不应该参与，而loc_loss = self.location_loss(ploc, vec_gd).sum(dim=1)
                计算了所有样本的损失，我们应该对其进行筛选 -> 使用刚才得到mask进行筛选
                    
                    import torch

                    mask = [True, False, True, True, False, False, False, False, True]
                    mask = torch.tensor(mask)
                    
                    mask.float()  # tensor([1., 0., 1., 1., 0., 0., 0., 0., 1.])
        """</span>
        loc_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>location_loss<span class="token punctuation">(</span>ploc<span class="token punctuation">,</span> vec_gd<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Tensor: [N, 8732] 包含正样本和负样本（但是负样本损失没意义）</span>
        loc_loss <span class="token operator">=</span> <span class="token punctuation">(</span>mask<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> loc_loss<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Tenosr: [N]  -> 对所有的location损失求和 -> 每张图片的location loss</span>

        
        
        <span class="token triple-quoted-string string">"""
            计算分类损失
                ① plabel： DBox的分类值      torch.Size([4, 21, 8732]) = [BS, classes+1, DBox数量]
                ② glabel： DBox所匹配到的GT的真实分类值     torch.Size([4, 8732]) = [BS, DBox数量]
                    如果该DBox没有匹配到GTBox，则glabel=0（负样本对应的就是背景）
                返回值：
                    con: 每一个DBox的分类损失       torch.Size([4, 8732]) = [BS, DBox数量]
                    
            Note：
                我们不会用到这8732个分类loss的，因为我们在loss时需要考虑到正负样本平衡的问题
                （SSD论文中，正负样本比例为3:1）
                而这8732个DBox只有很少一部分是正样本，绝大多数都是负样本
                如果直接这样计算的话 -> 正负样本不平衡 -> 给网络训练带来很大的困难
                
                所以我们需要分别获取它们的正负样本的loss
                正样本我们一开始就得到了（用mask），现在需要计算负样本
        """</span>
        
        <span class="token comment"># hard negative mining Tenosr: [N, 8732]</span>
        con <span class="token operator">=</span> self<span class="token punctuation">.</span>confidence_loss<span class="token punctuation">(</span>plabel<span class="token punctuation">,</span> glabel<span class="token punctuation">)</span>

        
        
        <span class="token comment"># positive mask will never selected</span>
        <span class="token comment"># 获取负样本</span>
        con_neg <span class="token operator">=</span> con<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
        con_neg<span class="token punctuation">[</span>mask<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.0</span> <span class="token comment"># 将正样本的分类损失全部置为0 -> 得到负样本的分类损失</span>
        <span class="token comment"># 按照confidence_loss降序排列 con_idx(Tensor: [N, 8732])</span>
        _<span class="token punctuation">,</span> con_idx <span class="token operator">=</span> con_neg<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> descending<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># ① 对负样本的分类损失进行降序排列，不要返回值，只要索引 -> 损失越来越小</span>
        _<span class="token punctuation">,</span> con_rank <span class="token operator">=</span> con_idx<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 这个步骤比较巧妙 ② 对负样本损失的索引进行升序排列</span>


        <span class="token comment"># number of negative three times positive</span>
        <span class="token comment"># 用于损失计算的负样本数是正样本的3倍（在原论文Hard negative mining部分），</span>
        <span class="token comment"># 但不能超过总样本数8732  # mask.size(1)=8732</span>
        neg_num <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token number">3</span> <span class="token operator">*</span> pos_num<span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span>mask<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 对负样本个数进行限制</span>
        neg_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>lt<span class="token punctuation">(</span>con_rank<span class="token punctuation">,</span> neg_num<span class="token punctuation">)</span>  <span class="token comment"># (lt: &lt;) Tensor [N, 8732] # ③ 进行取值</span>
		<span class="token triple-quoted-string string">"""
            经过这①②③三步之后，neg_mask中为True的个数为neg_num，且正好对应分类损失最大的位置
        """</span>

        <span class="token triple-quoted-string string">"""
            在得到正负样本的mask之后就可以计算最后的分类损失
                所有的正样本都会用到
                所有总的样本mask = 正样本的mask + 选取的负样本mask -> mask.float() + neg_mask.float()
        """</span>

        <span class="token comment"># confidence最终loss使用选取的正样本loss+选取的负样本loss</span>
        con_loss <span class="token operator">=</span> <span class="token punctuation">(</span>con <span class="token operator">*</span> <span class="token punctuation">(</span>mask<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> neg_mask<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Tensor [N]</span>

        <span class="token triple-quoted-string string">"""
            总的损失 = (定位损失 + 分类损失) / N
            
            Note:
                N为正样本的个数（而不是总的样本数）
        """</span>
        
        <span class="token comment"># avoid no object detected</span>
        <span class="token comment"># 避免出现图像中没有GTBOX的情况</span>
        total_loss <span class="token operator">=</span> loc_loss <span class="token operator">+</span> con_loss
        <span class="token comment"># eg. [15, 3, 5, 0] -> [1.0, 1.0, 1.0, 0.0]</span>
        <span class="token triple-quoted-string string">"""
            pos_num的确是正样本的个数    data: tensor([18, 61,  7,  6], device='cuda:0')
            但是不一定这个batch中每一张图片都有正样本数，因为最后的总损失需要/正样本个数，
            这里总损失是针对一张图片的，而不是一个batch，对于一张图片来说，它的pos_num有可能为0（正样本数为0）
            比如pos_num=tensor([0, 0,  7,  6], device='cuda:0')
            那么在计算时就会出现除零错误，因此需对其下限进行1e-6的限制
        """</span>
        num_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>gt<span class="token punctuation">(</span>pos_num<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 统计一个batch中的每张图像中是否存在正样本， 如果没有则该张图片为负样本，不计算损失</span>
        pos_num <span class="token operator">=</span> pos_num<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">)</span>  <span class="token comment"># 防止出现分母为零的情况</span>
        ret <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss <span class="token operator">*</span> num_mask <span class="token operator">/</span> pos_num<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 只计算存在正样本的图像损失</span>
        <span class="token comment"># ret： tensor(19.5028, device='cuda:0')</span>
        <span class="token keyword">return</span> ret
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="后处理--非训练模式">1.6 后处理- 非训练模式</h2><p><code>ssd_model.class SSD300.forward</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>	
   results <span class="token operator">=</span> self<span class="token punctuation">.</span>postprocess<span class="token punctuation">(</span>locs<span class="token punctuation">,</span> confs<span class="token punctuation">)</span>
       <span class="token keyword">return</span> results<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">PostProcess</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dboxes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        如果不在训练，那么就对结果进行后处理
        Args:
            dboxes: 根据预测特征图生成的Default Box（原生的，8732个）
            dboxes_xywh：先对DBox进行调用（格式为xywh），之后再添加一个维度，并且声明它不需要梯度（因为是正向传播不训练），最后将其转换为PyTorch的参数
            dboxes.scale_xy和dboxes.scale_wh是两个超参数
            self.criteria：IoU阈值的标准
            self.max_output: 输出目标的最大数量
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>PostProcess<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># [num_anchors, 4] -> [1, num_anchors, 4]</span>
        self<span class="token punctuation">.</span>dboxes_xywh <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>dboxes<span class="token punctuation">(</span>order<span class="token operator">=</span><span class="token string">'xywh'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>scale_xy <span class="token operator">=</span> dboxes<span class="token punctuation">.</span>scale_xy  <span class="token comment"># 0.1</span>
        self<span class="token punctuation">.</span>scale_wh <span class="token operator">=</span> dboxes<span class="token punctuation">.</span>scale_wh  <span class="token comment"># 0.2</span>

        self<span class="token punctuation">.</span>criteria <span class="token operator">=</span> <span class="token number">0.5</span>
        self<span class="token punctuation">.</span>max_output <span class="token operator">=</span> <span class="token number">100</span>

    <span class="token keyword">def</span> <span class="token function">scale_back_batch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bboxes_in<span class="token punctuation">,</span> scores_in<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># type: (Tensor, Tensor) -> Tuple[Tensor, Tensor]</span>
        <span class="token triple-quoted-string string">"""
            1）通过预测的boxes回归参数得到最终预测坐标
            2）将box格式从xywh转换回ltrb
            3）将预测目标score通过softmax处理
            Do scale and transform from xywh to ltrb
            suppose input N x 4 x num_bbox | N x label_num x num_bbox

            bboxes_in: [N, 4, 8732]是网络预测的xywh回归参数
            scores_in: [N, label_num, 8732]是预测的每个default box的各目标概率
        """</span>

        <span class="token comment"># Returns a view of the original tensor with its dimensions permuted.</span>
        <span class="token comment"># [batch, 4, 8732] -> [batch, 8732, 4]</span>
        bboxes_in <span class="token operator">=</span> bboxes_in<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># [batch, label_num, 8732] -> [batch, 8732, label_num]</span>
        scores_in <span class="token operator">=</span> scores_in<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># print(bboxes_in.is_contiguous())</span>

        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>scale_xy <span class="token operator">*</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>   <span class="token comment"># 预测的x, y回归参数</span>
        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>scale_wh <span class="token operator">*</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>   <span class="token comment"># 预测的w, h回归参数</span>

        <span class="token triple-quoted-string string">"""
            回归参数的计算如下：
                回归参数x = (GTBox的x - 预测DBox的x) / 预测DBox的w
                回归参数y = (GTBox的y - 预测DBox的y) / 预测DBox的h
                回归参数w = ln(GTBox的w / 预测DBox的w)
                回归参数h = ln(GTBox的h / 预测DBox的h)
                
            现在我们知道回归参数了，去算GTbox：
                GTBox(最终的预测边界框)的x = (回归参数x)*预测DBox的w + 预测DBox的x
                GTBox(最终的预测边界框)的y = (回归参数y)*预测DBox的w + 预测DBox的h
                GTBox(最终的预测边界框)的w = ln(回归参数w) * 预测DBox的w
                GTBox(最终的预测边界框)的h = ln(回归参数h) * 预测DBox的h
        """</span>
        
        <span class="token comment"># 将预测的回归参数叠加到default box上得到最终的预测边界框</span>
        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>dboxes_xywh<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>dboxes_xywh<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>dboxes_xywh<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

        <span class="token comment"># transform format to ltrb</span>
        l <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
        t <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
        r <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
        b <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>

        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> l  <span class="token comment"># xmin</span>
        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> t  <span class="token comment"># ymin</span>
        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r  <span class="token comment"># xmax</span>
        bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> b  <span class="token comment"># ymax</span>

        <span class="token comment"># scores_in: [batch, 8732, label_num]</span>
        <span class="token keyword">return</span> bboxes_in<span class="token punctuation">,</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>scores_in<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">decode_single_new</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bboxes_in<span class="token punctuation">,</span> scores_in<span class="token punctuation">,</span> criteria<span class="token punctuation">,</span> num_output<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># type: (Tensor, Tensor, float, int) -> Tuple[Tensor, Tensor, Tensor]</span>
        <span class="token triple-quoted-string string">"""
        decode:
            input  : bboxes_in (Tensor 8732 x 4), scores_in (Tensor 8732 x nitems)
            output : bboxes_out (Tensor nboxes x 4), labels_out (Tensor nboxes)
            criteria : IoU threshold of bboexes
            max_output : maximum number of output bboxes
        """</span>
        device <span class="token operator">=</span> bboxes_in<span class="token punctuation">.</span>device <span class="token comment"># 获取变量的设备信息</span>
        num_classes <span class="token operator">=</span> scores_in<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># 类别个数（20 + 1 = 21）</span>

        <span class="token comment"># 对越界的bbox进行裁剪</span>
        <span class="token triple-quoted-string string">"""
            Note: 这里bboxes_in里面的都是相对值，所以将其限制在[0, 1]就可以了
        """</span>
        bboxes_in <span class="token operator">=</span> bboxes_in<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
		<span class="token triple-quoted-string string">"""
            SSD算法每一个DBox只预测一组回归参数，并不像Faster R-CNN那样，针对每一个类别都去预测一组回归参数。
            为了使用和Faster R-CNN相同的算法，这里将DBox的信息复制了num_classes次（包括背景）
        """</span>
        <span class="token comment"># [8732, 4] -> [8732, 21, 4]</span>
        bboxes_in <span class="token operator">=</span> bboxes_in<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>scores_in<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>

        <span class="token comment"># create labels for each prediction</span>
		<span class="token triple-quoted-string string">"""
            为每一个DBox创建一个label
                import torch
                torch.arange(21)
                
                Res:
                tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
                            18, 19, 20])
        """</span>
        labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span> <span class="token comment"># [21, ]</span>
        <span class="token comment"># [num_classes] -> [8732, num_classes]</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>scores_in<span class="token punctuation">)</span>

        <span class="token comment"># remove prediction with the background label</span>
        <span class="token comment"># 移除归为背景类别的概率信息</span>
        bboxes_in <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># [8732, 21, 4] -> [8732, 20, 4]</span>
        scores_in <span class="token operator">=</span> scores_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># [8732, 21] -> [8732, 20]</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># [8732, 21] -> [8732, 20]</span>

        <span class="token comment"># batch everything, by making every class prediction be a separate instance</span>
        bboxes_in <span class="token operator">=</span> bboxes_in<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment"># [8732, 20, 4] -> [8732x20, 4]</span>
        scores_in <span class="token operator">=</span> scores_in<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [8732, 20] -> [8732x20]</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [8732, 20] -> [8732x20]</span>

        <span class="token comment"># remove low scoring boxes</span>
        <span class="token comment"># 移除低概率目标，self.scores_thresh=0.05</span>
        <span class="token comment"># inds = torch.nonzero(scores_in > 0.05).squeeze(1)</span>
        inds <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>gt<span class="token punctuation">(</span>scores_in<span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># 获取概率大于0.05的元素索引</span>
        <span class="token comment"># 获取BBox预测概率、label在对应位置上的数值</span>
        bboxes_in<span class="token punctuation">,</span> scores_in<span class="token punctuation">,</span> labels <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span>inds<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> scores_in<span class="token punctuation">[</span>inds<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>inds<span class="token punctuation">]</span>

        <span class="token comment"># remove empty boxes, 移除面积很小的DBox</span>
        <span class="token triple-quoted-string string">"""
            右下角x - 左上角的x -> ws
            右下角y - 左上角的y -> hs
        """</span>
        ws<span class="token punctuation">,</span> hs <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">-</span> bboxes_in<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        keep <span class="token operator">=</span> <span class="token punctuation">(</span>ws <span class="token operator">>=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>hs <span class="token operator">>=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span> <span class="token comment"># 宽度 >= 1个像素；高度 >= 1个像素</span>
        <span class="token comment"># keep = keep.nonzero().squeeze(1)</span>
        keep <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>keep<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># 滤除小面积目标</span>
        bboxes_in<span class="token punctuation">,</span> scores_in<span class="token punctuation">,</span> labels <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token punctuation">,</span> scores_in<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>keep<span class="token punctuation">]</span>

        <span class="token comment"># non-maximum suppression -> 重叠目标的过滤</span>
        keep <span class="token operator">=</span> batched_nms<span class="token punctuation">(</span>bboxes_in<span class="token punctuation">,</span> scores_in<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> iou_threshold<span class="token operator">=</span>criteria<span class="token punctuation">)</span>

        <span class="token comment"># keep only topk scoring predictions</span>
        keep <span class="token operator">=</span> keep<span class="token punctuation">[</span><span class="token punctuation">:</span>num_output<span class="token punctuation">]</span> <span class="token comment"># 控制输出box的最大数量</span>
        bboxes_out <span class="token operator">=</span> bboxes_in<span class="token punctuation">[</span>keep<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 根据索引取box坐标</span>
        scores_out <span class="token operator">=</span> scores_in<span class="token punctuation">[</span>keep<span class="token punctuation">]</span> <span class="token comment"># 根据索引取box分数</span>
        labels_out <span class="token operator">=</span> labels<span class="token punctuation">[</span>keep<span class="token punctuation">]</span> <span class="token comment"># 根据索引取box类别</span>

        <span class="token keyword">return</span> bboxes_out<span class="token punctuation">,</span> labels_out<span class="token punctuation">,</span> scores_out

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bboxes_in<span class="token punctuation">,</span> scores_in<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Args:
            bboxes_in: 预测得到的DBox的坐标偏移量（坐标回归参数）
            scores_in: 预测每个DBox对应的类别

        Returns:

        """</span>
        <span class="token comment"># 通过预测的boxes回归参数得到最终预测坐标, 将预测目标score通过softmax处理</span>
         <span class="token triple-quoted-string string">"""
            boxes: 最终的预测框坐标（x1,y1,x2,y2）
            probs: 每个预测框的概率
        """</span>
        bboxes<span class="token punctuation">,</span> probs <span class="token operator">=</span> self<span class="token punctuation">.</span>scale_back_batch<span class="token punctuation">(</span>bboxes_in<span class="token punctuation">,</span> scores_in<span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>jit<span class="token punctuation">.</span>annotate<span class="token punctuation">(</span>List<span class="token punctuation">[</span>Tuple<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> Tensor<span class="token punctuation">,</span> Tensor<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 遍历一个batch中的每张image数据</span>
        <span class="token triple-quoted-string string">"""
            tensor.split(split_size, dim)
                split_size： 分割的大小
                dim: 分割的维度
        """</span>
        <span class="token comment"># bboxes: [batch, 8732, 4]</span>
        <span class="token keyword">for</span> bbox<span class="token punctuation">,</span> prob <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>bboxes<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> probs<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># split_size, split_dim</span>
            <span class="token comment"># bbox: [1, 8732, 4]</span>
            bbox <span class="token operator">=</span> bbox<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 压缩BS维度</span>
            prob <span class="token operator">=</span> prob<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 压缩BS维度</span>
            <span class="token triple-quoted-string string">"""
                bbox: 每张图片的预测边界框坐标
                prob: 每张图片的预测边界框的概率信息
                self.criteria: NMS的IoU阈值
                self.max_output: 输出的最大目标个数
                
                得到每张图片的预测边界框相对坐标、分数（该标签对应的概率）和它的标签
            """</span>
            outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>decode_single_new<span class="token punctuation">(</span>bbox<span class="token punctuation">,</span> prob<span class="token punctuation">,</span> self<span class="token punctuation">.</span>criteria<span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_output<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>参考：https://blog.csdn.net/weixin_44878336/article/details/124716916</p></blockquote></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/posts/15102.html">http://unicorn-acc.github.io/posts/15102.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/56582.html"><img class="prev-cover" src="https://w.wallhaven.cc/full/9d/wallhaven-9d5o8w.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python数据结构模板总结</div></div></a></div><div class="next-post pull-right"><a href="/posts/45578.html"><img class="next-cover" src="https://w.wallhaven.cc/full/39/wallhaven-39zg5v.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Java数据结构模板总结</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/5074.html" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/posts/47625.html" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/posts/56670.html" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/posts/2490.html" title="图像分类_花分类数据集"><img class="cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-06</div><div class="title">图像分类_花分类数据集</div></div></a></div><div><a href="/posts/64179.html" title="图像分类_00_LeNet_Pytorch官方示例"><img class="cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_00_LeNet_Pytorch官方示例</div></div></a></div><div><a href="/posts/32696.html" title="目标检测的常见指标与COCO评价标准"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-12</div><div class="title">目标检测的常见指标与COCO评价标准</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-text">0. 引言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E6%9D%A5%E6%BA%90"><span class="toc-text">0.1 代码来源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E6%94%B9%E5%8A%A8"><span class="toc-text">0.2 代码改动</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-text">0.3 代码使用注意事项</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-text">0.3.1 环境配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84"><span class="toc-text">0.3.2 文件结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%8B%E8%BD%BD%E5%90%8E%E6%94%BE%E5%85%A5src%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD"><span class="toc-text">0.3.3 预训练权重下载地址（下载后放入src文件夹中）：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9C%AC%E4%BE%8B%E7%A8%8B%E4%BD%BF%E7%94%A8%E7%9A%84%E6%98%AFpascal-voc2012%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD%E5%90%8E%E6%94%BE%E5%85%A5%E9%A1%B9%E7%9B%AE%E5%BD%93%E5%89%8D%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD"><span class="toc-text">0.3.4 数据集，本例程使用的是PASCAL VOC2012数据集(下载后放入项目当前文件夹中)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95"><span class="toc-text">0.3.5 训练方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA"><span class="toc-text">0.3.6 训练结果展示</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80ssd%E4%BB%A3%E7%A0%81"><span class="toc-text">一、SSD代码</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ssd%E6%A1%86%E6%9E%B6%E7%A4%BA%E6%84%8F%E5%9B%BE"><span class="toc-text">1.1 SSD框架示意图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ssd%E7%BD%91%E7%BB%9C%E7%9A%84%E6%90%AD%E5%BB%BA--ssd_model.py"><span class="toc-text">1.2 SSD网络的搭建- ssd_model.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9backboneresnet-50"><span class="toc-text">1.2.1 修改backbone（ResNet-50）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%90%AD%E5%BB%BAssd%E7%BD%91%E7%BB%9C"><span class="toc-text">1.2.2 搭建SSD网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#default-box%E7%9A%84%E7%94%9F%E6%88%90"><span class="toc-text">1.3 Default Box的生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E5%8C%B9%E9%85%8D"><span class="toc-text">1.4 正负样本匹配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#loss%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-text">1.5 Loss的计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E5%A4%84%E7%90%86--%E9%9D%9E%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%BC%8F"><span class="toc-text">1.6 后处理- 非训练模式</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const n of document.querySelectorAll('script[type^="math/tex"]')){var e=!!n.type.match(/; *mode=display/),e=new t.options.MathItem(n.textContent,t.inputJax[0],e),a=document.createTextNode("");n.parentNode.replaceChild(a,n),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],insertScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t.hasAttribute("display")?btf.wrap(t,"div",{class:"mathjax-overflow"}):btf.wrap(t,"span",{class:"mathjax-overflow"})})},"",!1]}}};const a=document.createElement("script");a.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script src="/js/mouth.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (54)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (19)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(33.333333333333336% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>