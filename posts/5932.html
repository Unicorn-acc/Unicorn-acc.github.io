<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>目标检测-03-FPN特征金字塔网络(Feature Pyramid Network) | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:type" content="article"><meta property="og:title" content="目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)"><meta property="og:url" content="http://unicorn-acc.github.io/posts/5932.html"><meta property="og:site_name" content="Miraclo’s Blog"><meta property="og:description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg"><meta property="article:published_time" content="2022-11-17T16:26:04.000Z"><meta property="article:modified_time" content="2022-11-19T06:50:06.675Z"><meta property="article:author" content="Miraclo"><meta property="article:tag" content="DeepLearning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/posts/5932"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"prismjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:2e3},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:500,languages:{author:"作者: Miraclo",link:"链接: ",source:"来源: Miraclo’s Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-11-19 06:50:06"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouth.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">124</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2022-11-17T16:26:04.000Z" title="发表于 2022-11-17 16:26:04">2022-11-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/2%E3%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AF%87/">2、目标检测篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="目标检测-03-FPN特征金字塔网络(Feature Pyramid Network)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>参考内容来自霹雳吧啦Wz</p><p>up主的b站链接：https://space.bilibili.com/18161609/channel/index</p><p>up主的github：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</p><p>up主的CSDN博客：https://blog.csdn.net/qq_37541097/article/details/103482003</p><p>文章参考：https://blog.csdn.net/weixin_44878336/category_11399973.html</p></blockquote><p><strong>Feature Pyramid Networks for Object Detection</strong>（2016年CVPR）</p><p>作者: Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie</p><p>机构:</p><ol type="1"><li>Facebook AI Research (FAIR)</li><li>Cornell University and Cornell Tech</li></ol><p>论文地址：https://arxiv.org/abs/1612.03144</p><p><strong>FPN的创新点：</strong></p><p>​ FPN主要设计了一种<strong>特征金字塔的网络结构</strong>，可以应用到其他检测网络中，<strong>实现更高的检测精度</strong>。其出发点是认为图像的特征金字塔，这种多尺度的分解方式，对保证尺度不变性有重要作用；而传统的图像金字塔方法检测速度太慢，类似SSD这种取卷积网络不同层次的特征图来近似图像金字塔的做法，不能很好利用浅层网络高解析率的特征，对小物体的检测效果不佳。所以，论文作者设计了一种特征金字塔的网络结构，<strong>具有多尺度的特征，同时高低解析率的特征进行了一定的融合。</strong></p><h1 id="摘要">0. 摘要</h1><p>Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using FPN in a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.</p><p>特征金字塔是识别系统中检测不同尺度目标的一个基本组成部分。但最近的深度学习目标检测器避免了金字塔表示，部分原因是它们的计算和内存密集。在本文中，我们利用深度卷积网络固有的多尺度、金字塔式的层次结构来构建特征金字塔，而不需要额外的成本。我们开发了一个具有<strong>横向连接</strong>的<strong>自上而下</strong>的架构，用于在所有尺度上构建高水平的语义特征图。这种架构被称为特征金字塔网络（FPN），作为一种通用的特征提取器，在一些应用中显示出明显的改进。在基本的Faster R-CNN系统中使用FPN，我们的方法在COCO检测baseline上取得了最先进的<strong>单模型结果</strong>，没有任何花哨的东西，超过了所有现有的单模型作品，包括COCO 2016挑战赛获奖者的作品。此外，我们的方法可以在GPU上以5 FPS的速度运行，因此是一个实用而准确的多尺度目标检测解决方案。代码将公开提供。</p><h1 id="前瞻">1. 前瞻</h1><h2 id="fpn在faster-r-cnn上的效果">1.1 FPN在Faster R-CNN上的效果</h2><p>Faster R-CNN如果使用了FPN结构，在COCO的AP@0.5~0.95上可以提升2.3%；在PASCAL的AP@0.5是可以提升3.8%。这说明FPN结构对于提升目标检测网络性能很有效果。</p><h2 id="不同的图像金字塔方案对比">1.2 不同的图像金字塔方案对比</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171629773.png" style="zoom:50%"></p><blockquote><p>Figure 1. (a) Using an image pyramid to build a feature pyramid. Features are computed on each of the image scales independently, which is slow. (b) Recent detection systems have opted to use only single scale features for faster detection. © An alternative is to reuse the pyramidal feature hierarchy computed by a ConvNet as if it were a featurized image pyramid. (d) Our proposed Feature Pyramid Network (FPN) is fast like (b) and ©, but more accurate. In this figure, feature maps are indicate by blue outlines and thicker outlines denote semantically stronger features.</p><p>图1. (a) 使用图像金字塔来建立一个特征金字塔。特征是在每个图像尺度上<strong>独立计算</strong>的，这很慢。 (b) 最近的目标检测网络选择了只使用单一尺度的特征，以加快检测速度。© 另一种方法是重新使用由ConvNet计算的金字塔特征层次，就像它是一个特征化的图像金字塔。(d) 我们提出的特征金字塔网络（FPN）与(b)和©一样快速，但更准确。在该图中，特征图由蓝色轮廓表示，<strong>较粗的轮廓表示语义上更强的特征</strong>。</p></blockquote><h3 id="a-特征化的图像金字塔">1.2.1 (a) 特征化的图像金字塔</h3><p>因为要检测不同尺度的图片,所以可以将图片缩放到不同的尺度, 如 (a) 所示, 将特征图缩放到了 4 个不同的尺度. 然后需要对每种不同尺度的特征图以此通过目标检测网络得到检测结果.</p><p>因为预测多少个尺度的图片, 就要检测多少次不同尺度的图片.这种方法的效率很明显是非常低的.</p><h3 id="b-单一的尺度的图片">1.2.2 (b) 单一的尺度的图片</h3><p>也就是Faster R-CNN中使用的策略, 网络检测就使用一种尺度的图片. 图b的优点很明显, 因为只有一种尺度的图片, 因此速度会有优势. 但是因为没有不同尺度的图片, 所以对小目标的预测效果并不是很好.</p><blockquote><p>图片通过backbone后会进行下采样.</p></blockquote><h3 id="c-金字塔型特征层级">1.2.3 (c) 金字塔型特征层级</h3><p>图c中的方案和SSD的方案类似. 首先使用一张图片(一种尺度)输入给backbone, backbone在正向传播中会得到不同尺度的特征图, 然后对这些不同尺度的特征图分别进行预测. 相比于(a), 这样的处理方案无疑是更好的.</p><h3 id="d-fpn-feature-pyramid-network-特征金字塔网络结构">1.2.4 (d) FPN (Feature Pyramid Network, 特征金字塔网络结构)</h3><p>图(d) 和 图©有些类似, 但并不想图©在不同尺度的特征图上进行简单地预测, 而是将不同尺度的特征图进行融合后, 再进行预测.</p><p>根据 1.1 中的结果可以看到, FPN的确是可以提升网络的检测效果的.</p><h1 id="fpn-feature-pyramid-network-特征金字塔网络结构">2. FPN (Feature Pyramid Network, 特征金字塔网络结构)</h1><p>前面我们提到, 我们需要对不同尺度的特征图进行融合, 那么问题来了 – 该如何进行融合呢?</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171630938.png" style="zoom:50%"></p><blockquote><p>Figure 3. A building block illustrating the lateral connection and the top-down pathway, merged by addition.</p><p>图3. 一个说明横向联系和自上而下途径的构件，通过加法合并。</p></blockquote><h2 id="fpn工作细节">2.1 FPN工作细节</h2><p>上图中,每一个需要融合的特征图的尺寸其是人为设计的, 一般而言, 在backbone中的特征图的<strong>下采样率为2</strong>.</p><p>在FPN结构, 对于每一个backbone中的特征图都会<strong>先使用一个 1×1的卷积层处理. 使用1×1卷积层的目的是调整不同特征图的channel.</strong></p><blockquote><p>因为在融合的时候采用的是加法 ⊕, 所以在融合之前需要保证不同特征图的shape是相同的. 而1×1的卷积层是保证它们的channel是一样的.</p></blockquote><p>接下来我们需要将特征图的尺寸统一.</p><p>先对于最上面的特征图(最高层的)需要进行2倍的上采样, 使其尺寸×2 (上采样过程不会改变channel); 再对中间特征图进行2×的上采样.</p><h2 id="两倍上采样实现过程">2.2 两倍上采样实现过程</h2><p>这里的上采样实现非常简单, 并没有使用转置卷积 (Transposed Convolution/ Deconvolution), 而是使用 <strong>邻近插值算法</strong> 实现的, 如下所示:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    inner_lateral <span class="token operator">=</span> sefl<span class="token punctuation">.</span>get_result_from_inner_blocks<span class="token punctuation">(</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> idx<span class="token punctuation">)</span>
    feat_shape <span class="token operator">=</span> inner_lateral<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
    inner_top_down <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>last_inner<span class="token punctuation">,</span> size<span class="token operator">=</span>feat_shape<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"nearest"</span><span class="token punctuation">)</span>  <span class="token comment"># 邻近插值算法</span>
    last_inner <span class="token operator">=</span> inner_lateral <span class="token operator">+</span> inner_top_down
    result<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>get_result_from_layer_blocks<span class="token punctuation">(</span>last_inner<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="fpn细节结构">2.3 FPN细节结构</h2><p><img src="https://img-blog.csdnimg.cn/29ba03c0e34548b880c68dbed52b1898.png#pic_center" style="zoom:50%"></p><p><strong>在通过1×1卷积和上采样之后, FPN每个分支的特征图都就可以融合了</strong>. 之前图中没有画出来的是后面的3×3卷积. 每一个3×3卷积会对得到的融合后的特征图进行特征图提取, 从而以此得到最终输出 <code>P2</code>, <code>P3</code>, <code>P4</code>, <code>P5</code>.</p><p>根据原论文的描述, 最终会在<code>P5</code>的基础上进行下采样, 从而得到 <code>P6</code>.</p><p>这里下采样的具体实现也非常简单, 就是MaxPooling.</p><blockquote><p>原论文中, 1×1卷积核的个数为256, 即最终得到的特征图的channel都等于256.</p><p>得到<code>P6</code>的Pooling使用的MaxPooling, 而它的池化核大小为1×1, 所以这里换成AVGPooling效果也是一样的 😂.</p></blockquote><h3 id="注意事项1">2.3.1 注意事项1</h3><p><code>P6</code> 只用于Faster R-CNN的RPN部分(RPN生成Proposals的时候会使用 <code>P2 ~ P6</code>这5个特征图). 但对于Faster R-CNN的Predictor, 只会使用 <code>P2 ~ P5</code>这四个特征图上进行预测.</p><blockquote><p>对于Faster R-CNN而言, 会在预测特征图上进行RPN, 从而生成得到一系列的Proposals, 之后会将得到的proposals映射回特征图上, 然后再将映射的这部分特征输入到Predictor, 得到最终预测的结果.</p><p>但是在使用FPN结构的Faster R-CNN网络中, 首先FPN结构生成5种不同尺度的预测特征图, 之后在所有的预测特征图上进行RPN, 从而得到预测所需的proposals. 在将proposals映射会预测特征图时, <strong>不会使用5种不同尺度的预测特征图, 而是仅仅使用 <code>P2 ~ P5</code> 这四种尺度的预测特征图上</strong>. 最后再经过Predictor得到最终预测的结果.</p></blockquote><p>这里肯定会有疑惑 --<strong>&gt; RPN网络在不同尺度特征图上生成的proposals该如何确定它们各自该映射到哪一个特征图上呢?</strong> 这个问题我们先按下不表.</p><h3 id="注意事项2">2.3.2 注意事项2</h3><p>由于在RPN网络中生成了多个不同尺度的proposals, 所以网络可以在不同的预测特征图上分别针对不同尺度的目标进行预测.</p><blockquote><p>之前在讲Faster R-CNN时, 由于只有一个预测特征图, 所以仅仅是在一个预测特征图上生成不同面积和比例的Anchors. 但是引入FPN结构后, 就可以使用不同尺度的特征图去预测不同大小的目标.</p></blockquote><h2 id="不同预测特征图预测的目标大小及其参数设置">2.4 不同预测特征图预测的目标大小及其参数设置</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171645419.png" style="zoom:50%"></p><blockquote><p>Formally, we define the anchors to have areas of {322, 642, 1282, 2562, 5122} pixels on {P2, P3, P4, P5, P6} respectively. As in [29] we also use anchors of multiple aspect ratios {1:2, 1:1, 2:1} at each level. So in total there are 15 anchors over the pyramid.</p><p>形式上，我们定义Anchors在{P2, P3, P4, P5, P6}上的面积分别为{322, 642, 1282, 2562, 5122}像素。与[29]一样，我们也在每一级使用多个长宽比的锚点{1:2, 1:1, 2:1}。所以在金字塔上总共有15个锚点。</p></blockquote><table><thead><tr class="header"><th>预测特征图</th><th>预测目标大小</th><th>预测目标尺寸</th><th>比例</th></tr></thead><tbody><tr class="odd"><td><code>P2</code></td><td>最小目标</td><td>32×32</td><td>1:2, 1:1, 2:1</td></tr><tr class="even"><td><code>P3</code></td><td>略小目标</td><td>64×64</td><td>1:2, 1:1, 2:1</td></tr><tr class="odd"><td><code>P4</code></td><td>中目标</td><td>128×128</td><td>1:2, 1:1, 2:1</td></tr><tr class="even"><td><code>P5</code></td><td>大目标</td><td>256×256</td><td>1:2, 1:1, 2:1</td></tr><tr class="odd"><td><code>P6</code></td><td>最大目标</td><td>512×512</td><td>1:2, 1:1, 2:1</td></tr></tbody></table><h1 id="其他">3. 其他</h1><h2 id="rpn和faster-r-cnn组件的数量">3.1 RPN和Faster R-CNN组件的数量</h2><p>在讲解Faster R-CNN的时候我们知道, 网络中有两个非常重要的部分:</p><ol type="1"><li>RPN</li><li>Faster R-CNN Predictor</li></ol><p>如下图所示.</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211171647463.png"></p><p>但是在使用了FPN结构后, 会生成多个预测特征图, 那么我们是否需要针对每一个预测特征图使用不同的RPN和Predictor呢?</p><p>在原论文中, 作者也对其进行了实验. 作者发现: 在不同的预测特征图上, 共用同一个RPN和Predicator和分别在不同预测特征图使用不同的RPN和Predictor的效果其实是差不多的.</p><p>既然在检测效果上没有什么差异, 那么共享RPN和Predictor是更好的选择 -&gt; 减少网络训练参数.</p><h2 id="proposals映射策略">3.2 proposals映射策略</h2><p>因为使用了FPN结构, 所以会生成不同尺度的proposals和预测特征图, 但RPN部分和Predicator部分使用的预测特征图是不同的, 因此如何让proposals映射到预测特征图上就成了一个问题.</p><p>作者在原论文中给出了方案:</p><p>We view our feature pyramid as if it were produced from an image pyramid. Thus we can adapt the assignment strategy of region-based detectors [15, 11] in the case when they are run on image pyramids. Formally, we assign an RoI of width w and height h (on the input image to the network) to the level <span class="math inline">\(P_k\)</span> of our feature pyramid by:</p><p>我们把我们的特征金字塔看作是由图像金字塔产生的。因此，当基于区域的检测器[15, 11]在图像金字塔上运行时，我们可以调整它们的分配策略。形式上，我们将宽度为 $ w$、高度为 $ h$ 的RoI（在网络的输入图像上）分配给我们的特征金字塔的第<span class="math inline">\(P_k\)</span> 层，方法是：</p><ul><li>$ k = k_0 + _2 ( / 224)$</li></ul><p>上述公式中:</p><ul><li><span class="math inline">\(\lfloor \cdot \rfloor\)</span>表示向下取整</li><li><span class="math inline">\(k \in \{2, 3, 4, 5\}\)</span> 就是proposals应该映射到的预测特征图索引(对应<code>P2 ~ P5</code>).</li><li><span class="math inline">\(k_0\)</span> 设置为4</li><li><span class="math inline">\(wh\)</span> 为RPN网络生成一系列proposals在原图上的宽度和高度</li></ul><p>假设 某一个层的proposals映射到原图上的<span class="math inline">\(wh = 112\)</span>, 那么:</p><p><span class="math inline">\(k=⌊k0+log_2⁡(wh/224)⌋=⌊4+log_2⁡(1/2)⌋=⌊4+(−1)⌋=3\)</span></p><p>$ k$与预测特征图的编号是一一对应的, 也就是说, 该尺度的proposals应该映射到 <code>P3</code>上.</p><hr><h1 id="代码实现">4、代码实现</h1><p>其PyTorch代码实现如下:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LevelMapper</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Determine which FPN level each RoI in a set of RoIs should map to based
    on the heuristic in the FPN paper.

    Args:
        k_min (int)
        k_max (int)
        canonical_scale (int)
        canonical_level (int)
        eps (float)
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        k_min<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
        k_max<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
        canonical_scale<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">224</span><span class="token punctuation">,</span>
        canonical_level<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>
        eps<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1e-6</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>k_min <span class="token operator">=</span> k_min
        self<span class="token punctuation">.</span>k_max <span class="token operator">=</span> k_max
        self<span class="token punctuation">.</span>s0 <span class="token operator">=</span> canonical_scale
        self<span class="token punctuation">.</span>lvl0 <span class="token operator">=</span> canonical_level
        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> eps

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> boxlists<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Tensor<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Args:
            boxlists (list[BoxList])
            box_area: 将宽和高相乘后再开根号
        """</span>
        <span class="token comment"># Compute level ids</span>
        s <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>box_area<span class="token punctuation">(</span>boxlist<span class="token punctuation">)</span> <span class="token keyword">for</span> boxlist <span class="token keyword">in</span> boxlists<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># Eqn.(1) in FPN paper</span>
        target_lvls <span class="token operator">=</span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>lvl0 <span class="token operator">+</span> torch<span class="token punctuation">.</span>log2<span class="token punctuation">(</span>s <span class="token operator">/</span> self<span class="token punctuation">.</span>s0<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>eps<span class="token punctuation">,</span> dtype<span class="token operator">=</span>s<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>
        target_lvls <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>target_lvls<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span>self<span class="token punctuation">.</span>k_min<span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span>self<span class="token punctuation">.</span>k_max<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>target_lvls<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>k_min<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/posts/5932.html">http://unicorn-acc.github.io/posts/5932.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/60257.html"><img class="prev-cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">目标检测-03-RetinaNet</div></div></a></div><div class="next-post pull-right"><a href="/posts/24362.html"><img class="next-cover" src="https://w.wallhaven.cc/full/p9/wallhaven-p9273e.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">JVM系列-05-虚拟机栈（重点）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/5074.html" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/posts/47625.html" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/posts/56670.html" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/posts/2490.html" title="图像分类_花分类数据集"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-06</div><div class="title">图像分类_花分类数据集</div></div></a></div><div><a href="/posts/64179.html" title="图像分类_00_LeNet_Pytorch官方示例"><img class="cover" src="https://w.wallhaven.cc/full/1p/wallhaven-1pjml1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_00_LeNet_Pytorch官方示例</div></div></a></div><div><a href="/posts/32696.html" title="目标检测的常见指标与COCO评价标准"><img class="cover" src="https://w.wallhaven.cc/full/1p/wallhaven-1pjml1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-12</div><div class="title">目标检测的常见指标与COCO评价标准</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">0. 摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E7%9E%BB"><span class="toc-text">1. 前瞻</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#fpn%E5%9C%A8faster-r-cnn%E4%B8%8A%E7%9A%84%E6%95%88%E6%9E%9C"><span class="toc-text">1.1 FPN在Faster R-CNN上的效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E7%9A%84%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94"><span class="toc-text">1.2 不同的图像金字塔方案对比</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#a-%E7%89%B9%E5%BE%81%E5%8C%96%E7%9A%84%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94"><span class="toc-text">1.2.1 (a) 特征化的图像金字塔</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#b-%E5%8D%95%E4%B8%80%E7%9A%84%E5%B0%BA%E5%BA%A6%E7%9A%84%E5%9B%BE%E7%89%87"><span class="toc-text">1.2.2 (b) 单一的尺度的图片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#c-%E9%87%91%E5%AD%97%E5%A1%94%E5%9E%8B%E7%89%B9%E5%BE%81%E5%B1%82%E7%BA%A7"><span class="toc-text">1.2.3 (c) 金字塔型特征层级</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#d-fpn-feature-pyramid-network-%E7%89%B9%E5%BE%81%E9%87%91%E5%AD%97%E5%A1%94%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">1.2.4 (d) FPN (Feature Pyramid Network, 特征金字塔网络结构)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#fpn-feature-pyramid-network-%E7%89%B9%E5%BE%81%E9%87%91%E5%AD%97%E5%A1%94%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">2. FPN (Feature Pyramid Network, 特征金字塔网络结构)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#fpn%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82"><span class="toc-text">2.1 FPN工作细节</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E5%80%8D%E4%B8%8A%E9%87%87%E6%A0%B7%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B"><span class="toc-text">2.2 两倍上采样实现过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#fpn%E7%BB%86%E8%8A%82%E7%BB%93%E6%9E%84"><span class="toc-text">2.3 FPN细节结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B91"><span class="toc-text">2.3.1 注意事项1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B92"><span class="toc-text">2.3.2 注意事项2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E9%A2%84%E6%B5%8B%E7%89%B9%E5%BE%81%E5%9B%BE%E9%A2%84%E6%B5%8B%E7%9A%84%E7%9B%AE%E6%A0%87%E5%A4%A7%E5%B0%8F%E5%8F%8A%E5%85%B6%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-text">2.4 不同预测特征图预测的目标大小及其参数设置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%BB%96"><span class="toc-text">3. 其他</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#rpn%E5%92%8Cfaster-r-cnn%E7%BB%84%E4%BB%B6%E7%9A%84%E6%95%B0%E9%87%8F"><span class="toc-text">3.1 RPN和Faster R-CNN组件的数量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#proposals%E6%98%A0%E5%B0%84%E7%AD%96%E7%95%A5"><span class="toc-text">3.2 proposals映射策略</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-text">4、代码实现</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const n of document.querySelectorAll('script[type^="math/tex"]')){var e=!!n.type.match(/; *mode=display/),e=new t.options.MathItem(n.textContent,t.inputJax[0],e),a=document.createTextNode("");n.parentNode.replaceChild(a,n),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],insertScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t.hasAttribute("display")?btf.wrap(t,"div",{class:"mathjax-overflow"}):btf.wrap(t,"span",{class:"mathjax-overflow"})})},"",!1]}}};const a=document.createElement("script");a.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script src="/js/mouth.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (54)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (19)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(33.333333333333336% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>