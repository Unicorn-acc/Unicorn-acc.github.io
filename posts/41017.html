<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>目标检测_02_SSD理论详解 | Miraclo’s Blog</title><meta name="author" content="Miraclo"><meta name="copyright" content="Miraclo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:type" content="article"><meta property="og:title" content="目标检测_02_SSD理论详解"><meta property="og:url" content="http://unicorn-acc.github.io/posts/41017.html"><meta property="og:site_name" content="Miraclo’s Blog"><meta property="og:description" content="参考内容来自霹雳吧啦Wz up主的b站链接：https:&#x2F;&#x2F;space.bilibili.com&#x2F;18161609&#x2F;channel&#x2F;index up主的github：https:&#x2F;&#x2F;github.com&#x2F;WZMIAOMIAO&#x2F;deep-learning-for-image-processing up主的CSDN博客：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_37541097&#x2F;articl"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg"><meta property="article:published_time" content="2022-11-15T15:41:46.000Z"><meta property="article:modified_time" content="2022-11-18T07:19:39.444Z"><meta property="article:author" content="Miraclo"><meta property="article:tag" content="DeepLearning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://unicorn-acc.github.io/posts/41017"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"prismjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:2e3},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:500,languages:{author:"作者: Miraclo",link:"链接: ",source:"来源: Miraclo’s Blog",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:void 0,source:{justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js",css:"https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"目标检测_02_SSD理论详解",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2022-11-18 07:19:39"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouth.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Miraclo’s Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/algor-record/"><i class="fa-fw fas fa-gamepad"></i><span> 算法刷题记录</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><i class="fa-fw fa-solid fa-shuffle"></i><span></span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">目标检测_02_SSD理论详解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2022-11-15T15:41:46.000Z" title="发表于 2022-11-15 15:41:46">2022-11-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/2%E3%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AF%87/">2、目标检测篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="目标检测_02_SSD理论详解"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>参考内容来自霹雳吧啦Wz</p><p>up主的b站链接：https://space.bilibili.com/18161609/channel/index</p><p>up主的github：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</p><p>up主的CSDN博客：https://blog.csdn.net/qq_37541097/article/details/103482003</p></blockquote><h1 id="一-引言">一、 引言</h1><h2 id="ssd-single-shot-multibox-detector简介">1.1 SSD: Single Shot MultiBox Detector简介</h2><p>论文地址：https://arxiv.org/abs/1512.02325</p><p>官方代码地址：https://github.com/weiliu89/caffe/tree/ssd</p><p>​ SSD网络（Single Shot MultiBox Detector，单发多框检测器）是作者Wei Liu在ECCV 2016上发表的论文。对于输入尺寸300×300的网络，使用NVIDIA TITAN X在PASCAL VOC2007测试集上达到74.3%mAP以及59 FPS，对于512×512的网络，mAP达到了76.9 %，超越了当时最强的Faster R-CNN（mAP: 73.2%）。而且<strong>它真正达到了实时检测</strong>。</p><p>​ SSD算法是One-stage目标检测算法中的一种，不需要region proposal阶段，可以直接产生物体的类别概率和位置坐标值，经过单次检测即可直接得到最终的检测结果，具有检测速度快的特点。</p><p><strong>SSD的创新点：</strong></p><ul><li><p>引入了SSD，这是一种针对多个类别的单发检测器，比YOLO更快，并且更精确，精度上可以和包括faster rcnn在内的two-stage目标检测算法媲美</p></li><li><p>SSD的核心是在特征图上<strong>应用小卷积核来预测固定的一组默认边界框（anchor）的类别分数和框偏移量</strong>。</p></li><li><p>为了实现高检测精度，我们<strong>根据不同尺度的特征图生成不同尺度的预测</strong>，并通过<strong>宽高比</strong>来区分预测。</p></li><li><p>即使在低分辨率输入图像上，这些设计也可实现简单的端到端训练和高精度，从而进一步提高速度与精度之间的平衡。</p></li></ul><h2 id="目标检测的发展">1.2 目标检测的发展</h2><p>在SSD之前，目标检测算法分为两类：</p><ol type="1"><li>双阶段网络 —— Faster R-CNN ①先通过RPN网络生成一系列proposals，②然后根据生成的proposals进行概率的预测和定位回归</li><li>单阶段网络 —— SSD 只需一步便可以将目标检测出来</li></ol><h2 id="tensorflow复现的ssd代码">1.3 TensorFlow复现的SSD代码</h2><p>https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md</p><p>我们可以看到，tf有很多预训练模型都是基于Faster R-CNN和SSD进行改进的，所以SSD是One-stage算法中非常经典的算法之一。</p><h2 id="faster-r-cnn存在的问题">1.4 Faster R-CNN存在的问题</h2><h3 id="检测流程">1.4.1 检测流程</h3><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211151657341.png" style="zoom:50%"></p><ol type="1"><li>将图片输入到backbone得到feature map</li><li>通过RPN网络生成一系列proposals</li><li>将proposals映射到feature map中 —— 得到每一个proposals对应的特征矩阵</li><li>将每一个特征矩阵都经过ROI Pooling层 —— 统一缩放到指定的大小（原文为7×7）</li><li>通过目标分类器和边界框回归器分别预测和回归每一个proposals的类别和边界框回归参数</li><li>根据类别和边界框回归参数得到预测结果</li><li>通过NMS后再滤除低概率的目标 —— 得到最终的检测结果</li></ol><h2 id="存在的问题">1.4.2 存在的问题</h2><ol type="1"><li>对小目标检测效果很差</li><li>模型大，检测速度较慢</li></ol><h3 id="为什么faster-r-cnn对小目标检测效果差">1.4.2.1 为什么Faster R-CNN对小目标检测效果差？</h3><p>输入图片只在一个特征层（输入图片经过backbone后得到的feature map就叫做特征层）上进行预测，而这个feature map（特征层）是经过很多卷积层之后所得到，图片很小了，已经非常抽象了 —— 它的感受野很大，就会丢失很多细节信息。而检测小目标通常需要那么丢失的细节信息。所以在一个高层的特征图上预测小目标，检测效果肯定不好。</p><p>既然在高层的特征图上预测小目标效果不好，那我们能不能在相对低层的特征图上进行预测呢？</p><p>可以！我们先按下不表。</p><h3 id="为什么faster-r-cnn模型大且检测速度慢">1.4.2.2 为什么Faster R-CNN模型大且检测速度慢？</h3><p>Faster R-CNN检测速度慢的原因有很多，主要原因是因为它是双阶段的：</p><ol type="1"><li>RPN进行了一次预测</li><li>Fast R-CNN又进行了一次预测</li></ol><p>所以它的检测速度慢 —— 这也是Two-stage网络的通病。</p><h1 id="二ssd网络框架">二、SSD网络框架</h1><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152041665.png"></p><ul><li>输入图像的shape是固定的，必须是300×300（如果不是需进行缩放）</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152044380.png"></p><ul><li>将图片输入到VGG-16的backbone中，将Conv5_3的2x2池话核换为3x3，这样高宽不会发生变化</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152052943.png" style="zoom:50%"></p><ul><li><code>Conv4_3</code>是SSD的第一个预测特征层（feature map），添加一系列的卷积层得到其他预测特征层：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152052221.png" style="zoom:50%"></p><ul><li>通过不同的卷积就可以得到六个预测特征层（feature map）</li><li>在这6个预测特征层上分别预测不同大小的目标：<ul><li>①： 感受野最小 —— 最小的目标</li><li>…</li><li>⑥：感受野最大 —— 最大的目标</li></ul></li></ul><h2 id="不同特征图-feature-map-匹配不同大小的目标">2.1 不同特征图 (feature map) 匹配不同大小的目标</h2><p>为了方便理解，看下图：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152057619.png"></p><p>8×8的特征矩阵（feature map）相对4×4的特征矩阵，抽象程度更低一些 —— <strong>细节信息</strong>保留更多一些 -&gt; 在低层特征矩阵上预测小目标：</p><ul><li>猫的面积相对狗要小一些，所以我们应该在8×8的feature map上预测猫的目标边界框</li><li>狗的面积更大，4×4的feature map更加适合去预测这样大目标（如果用8×8的默认边界框去匹配狗，不好匹配到的）</li></ul><p>这样操作使得网络更容易检测不同大小的目标，进而提升小目标和大目标的检测效果。</p><h2 id="default-box">2.2 Default Box</h2><h3 id="什么是default-box">2.2.1 什么是Default Box</h3><p>Default Box类似与Faster R-CNN中的Anchor Box。Faster R-CNN的RPN网络就是利用事先生成的Anchor Box进行边界框的分类和回归预测。SSD的Default Box与Anchor Box原理类似，只不过<strong>SSD将Default Box放在了不同的预测特征层（feature map）上面。</strong></p><h3 id="default-box的scale以及aspect设定">2.2.2 Default Box的scale以及aspect设定</h3><ul><li>scale是<strong>目标尺度</strong></li><li>aspect每个目标scale所对应的一系列<strong>比例</strong></li></ul><p><img src="https://img-blog.csdnimg.cn/8b62fc5ac48140eaa7175401ca605253.png" style="zoom:50%"></p><p>如果按照原论文中给的方法计算scale，与代码实现用的算法是不太一样的，所以这里就不讲论文中的公式了。</p><p>Default Box的scale以及aspect设定：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161015277.png" style="zoom:50%"></p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152103457.png" style="zoom:67%"></p><p><strong>Q</strong>：为什么scale会有两个值？ <strong>A</strong>：根据公式<span class="math inline">\(S&#39;_k = \sqrt{S_kS_{k+1}+1}\)</span>，scale前一个数对应着 <span class="math inline">\(S_k\)</span>，后一个数代表<span class="math inline">\(S_{k+1}\)</span>。其中<span class="math inline">\(S_k\)</span>表示当前层的scale，而<span class="math inline">\(S_{k+1}\)</span>对应这是下一层的scale。</p><p><strong>Q</strong>：aspect的比例是怎么来的？ <strong>A</strong>：论文中提到了，下图中红色的均采用4种Default Box，而绿色的使用6种Default Box。所以aspect的比例，第一个和倒数两个是一样的，中间3个是一样的。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152107724.png" style="zoom:50%"></p><h3 id="根据scale和aspect求得每个特征图的default-box和数量">1.2.3 根据scale和aspect求得每个特征图的Default Box和数量</h3><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161015937.png" style="zoom:50%"></p><ul><li><p>对于预测特征层①，涉及两种scale ——21（3个）和<span class="math inline">\(\sqrt{21 \times 45}\)</span>（1个），所以共有4种Default Box，生成Default Box的数量就是feature map的像素×Default Box的种类。</p></li><li><p>…</p></li><li><p>总共生成Default Box的数量为：</p><p><span class="math inline">\(Default Box数量=特征层①+特征层②+特征层③+特征层④+特征层⑤+特征层⑥\\=(38×38×4)+(19×19×6)+(10×10×6)+(5×5×6)+(3×3×4)+(1×1×4)\\=8732\)</span></p><blockquote><p>预测特征层（feature map）的每一个位置上都会生成 <strong>4种或者6种</strong> Default Box</p></blockquote><p>举例：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161015807.png"></p></li></ul><p>在SSD中有6个预测特征图，这里列举了2个——预测特征图1和预测特征图4。对于每张预测特征图，下方分别是它采用的scale和aspect。<strong>预测特征图</strong>上的点即为要生成Default Box的中心点，注意！这里不是在feature map上生成Default Box，而是将点所在的框（其实就是一个像素）映射到原图中，并在原图上生成对应的Default Box。 其中： <strong>feature map 1</strong> —— 使用 4 种Default Box</p><ul><li>首先将feature map 1上的黑点映射到原图上，然后根据原图上这个点的坐标绘制相应的Default Box</li><li>中间的黄色框为scale=21, aspect为$ 1:1$的Default Box。</li><li>两个蓝色的框分别表示scale21，比例为<span class="math inline">\(1:2\)</span>和$ 2:1$的两个Default Box</li><li>最大的黄色为scale为$ <span class="math inline">\(，aspect为\)</span> 1:1$的Default Box</li></ul><p><strong>feature map 2</strong> —— 使用 6 种Default Box</p><ul><li>首先将feature map 2上的黑点映射到原图上，然后根据原图上这个点的坐标绘制相应的Default Box</li><li>…</li></ul><blockquote><p>Note：</p><ul><li>不是在feature map上生成Default Box，而是将点所在的框（其实就是一个像素）映射到原图中，并在原图上生成对应的Default Box</li><li>aspect表示比例，是 $ aspect=高度:宽度$</li></ul></blockquote><h1 id="三-预测器predictor的实现">三、 预测器（predictor）的实现</h1><p>如何在六个预测特征图上进行预测。</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152120125.png" style="zoom:67%"></p><p>对于高和宽为 <span class="math inline">\(m \times n\)</span>，Channel为 p 的预测特征图而言，直接使用卷积核大小为 <span class="math inline">\(3 \times 3 \times p\)</span> 的小卷积来实现（其中 p 为卷积核的channel，与输入图片channel保持一致）。通过3×3的卷积核来生成概率分数以及Default Box的坐标迁移量（边界框回归参数）</p><blockquote><p>这里的实现方法和Fast R-CNN类似</p></blockquote><h2 id="卷积核的个数">3.1 卷积核的个数</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152121332.png" style="zoom:50%"></p><p>刚才说过，在每一个预测特征层上使用卷积核大小为 <span class="math inline">\(3 \times 3 \times p\)</span> 的小卷积来实现预测。那么会使用多少个卷积核呢？论文中，对于<strong>预测特征图的每一个位置</strong>会生成 <span class="math inline">\(k\)</span> 个Default Box，对每个Default Box分别计算 <span class="math inline">\(c\)</span> 个类别分数和 $ 4$ 个坐标偏移量。因此预测特征层上一个像素点需要 $ (c+4)k$ 个卷积核才能进行卷积处理。</p><blockquote><p>注意上面说的是预测特征图的每一个位置，即一个pixel 还记得吗，预测特征图上每一个像素点都会生成 4种或6种 Default Box</p></blockquote><p>对于 m × n m nm×n 的feature map而言，则需要$ (c+4)k m n$ 个卷积核才能对整张feature map进行卷积处理。</p><h2 id="类别分数预测和边界框回归参数预测">3.2 类别分数预测和边界框回归参数预测</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152123015.png" style="zoom:50%"> 对于预测特征图上每一个像素点，需要 <span class="math inline">\((c+4)\times k\)</span> 个卷积核，即 <span class="math inline">\(c \times k + 4 \times k\)</span> ，其中：</p><ul><li>$ ck$ 为每个像素点的总的类别分数 —— <strong>每个Default Box的类别分数</strong></li><li><span class="math inline">\(4 \times k\)</span> 为每一个像素点总的回归参数 —— <strong>每个Default Box的回归参数</strong></li></ul><h3 id="目标类别分数预测">3.2.1 目标类别分数预测</h3><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152126690.png"> 对每个Default Box都会预测$ c$ 个类别分数（注意这里的 $ c$ 是包括背景类别的，对于VOC来说，这里的 <span class="math inline">\(c=1+20=21\)</span>)</p><p>以每 $ c$ 个类别分数进行划分 —— 对应每个Default Box的类别分数， 共有$ k$ 个Default Box，所以共有$ c k $ 个具体类别分数。</p><h3 id="边界框回归参数预测">3.2.2 边界框回归参数预测</h3><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152126555.png"> 和类别分数预测原理一样，只不过这里把类别数改为了边界框回归的4个参数（中心坐标x,y和宽度高度w,h)。</p><p>注意：</p><ul><li>在Faster R-CNN中，会生成 $ 4 c$ 个边界框回归参数（而不是SSD的 $ 4$ 个）—— 针对每一个Anchor分别生成每一个类别的边界框回归参数。</li><li>在SSD中，对于每一个Default Box只生成 <span class="math inline">\(4\)</span> 个边界框回归参数 —— <strong>不关注Default Box是归于哪一个类别的</strong></li></ul><h1 id="四-正负样本选取">四、 正负样本选取</h1><h2 id="正样本的选取">4.1 正样本的选取</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152127872.png"> 对于正样本的选取，论文中给出了2个匹配准则：</p><ol type="1"><li>对于每一个GT box去匹配与其<strong>IoU值最大的</strong>Default Box —— 匹配到Default Box为正样本</li><li>对于任意的Default Box，它只要<strong>与任意GT Box的IoU大于0.5</strong> —— 认定该Default Box为正样本</li></ol><blockquote><p>SSD的匹配准则与Faster R-CNN的匹配准则也比较类似</p><p>需要注意的，所有的Default Box就是所有的样本，这里我们选取正负样本其实就是在选取Default Box —— 将部分Default Box归为正样本；将部分Default Box归于负样本</p></blockquote><h2 id="负样本的选取">4.2 负样本的选取</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211161016758.png"> 按道理来说，选取出正样本之后剩下的部分都可以归于负样本了。但剩下的负样本中并<strong>不是都用来计算的</strong>。网络会生成8732个Default Box，但在训练过程中，Default Box匹配到<strong>GT Box的正样本个数很少</strong> —— 基本上是<strong>几个到十几个</strong>。所以如果直接把剩下的Default Box全归于负样本，全部参与计算的话 —— 会带来严重的<strong>正负样本不平衡</strong>问题。基于这个问题，我们需要对负样本进行筛选，从用的准则如下：</p><ol type="1"><li>先计算剩下Default Box的最大confidence loss（置信度误差），Confidence loss越大 —— 网络将这个负样本预测为目标的概率越大 -&gt; 这是不能容忍的</li></ol><blockquote><p>负样本的损失越大，说明预测结果越是接近正样本，所以是不能容忍的</p><p>换句话说，作为负样本它的损失越大，那么网络一旦将其作为正样本，那么它的损失会很小 —— 网络预测其为正样本的概率越大！</p></blockquote><ol start="2" type="1"><li>根据confidence loss选取排名在前的负样本</li></ol><blockquote><p>具体选取多少呢？ 论文中说负样本：正样本大概为3：1即可。</p></blockquote><p>这种负样本的选取方式在论文中称为 —— Hard negative mining</p><h1 id="五-损失的计算">五、 损失的计算</h1><p>有了正负样本之后，就可以计算模型的损失。模型的损失分为两个部分：①类别损失和②定位损失，如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152131228.png" style="zoom:50%"></p><p>其中：</p><h2 id="类别损失">5.1 类别损失</h2><p>类别损失实际上是一个softmax损失：</p><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152131926.png" style="zoom:50%"></p><p>其中：</p><ul><li><span class="math inline">\(x, c\)</span> 分别为预测类别和真实类别</li><li><span class="math inline">\(x_{ij}^p=\{0， 1\}\)</span>为第 <span class="math inline">\(i\)</span> 个Default Box匹配到的第$ j$ 个GT Box（类别是 <span class="math inline">\(P\)</span>）—— 不用管它，看为 $ 1$就行</li><li><span class="math inline">\(\hat{c}_i^p\)</span>为预测的第$ i$ 个Default Box对应GT Box的类别概率 $ P<span class="math inline">\(，具体表达为\)</span>_i^p = $—— 第 $ i$ 个Default Box会匹配到一个GT Box（因为这部分的 <span class="math inline">\(i\in Pos\)</span>，所以都是正样本 -&gt; 肯定有与之对应的GT Box）。假设这里GT Box对应的是“猫”这个类别，那么<span class="math inline">\(\hat{c}_i^p\)</span>就是对应网络输出Default Box为猫的概率 —— <strong>网络预测第 $ i$ 个Default Box为类别 $ p$ 的概率</strong>。</li><li>负样本部分只需关注 <span class="math inline">\(\hat{c}^0_i\)</span>就可以了 —— <strong>网络预测第 <span class="math inline">\(i\)</span> 个Default Box为背景的概率</strong>。</li></ul><h2 id="定位损失">5.2 定位损失</h2><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152137633.png" style="zoom:67%"></p><p>回归参数简单理解的公式：</p><p>$x回归=xgtbox−xdboxwdbox $</p><p>$ y回归=ygtbox−ydboxhdbox $</p><p>$ w回归=ln(wgtboxwdbox) $</p><p>$ h回归=ln(hgtboxhdbox)$</p><blockquote><p>Note：</p><ul><li>定位损失是针对正样本而言的，因为负样本连GT Box都没有（有Default Box但没有GT Box），所以无法负样本的定位损失，且负样本定位损失计算出来也没有什么意义</li><li>SSD回归参数的计算和Faster R-CNN是一模一样的！</li></ul></blockquote><h1 id="六-回顾和总结">六、 回顾和总结</h1><p><img src="https://cdn.jsdelivr.net/gh/Unicorn-acc/blogimgs/imgs/202211152041665.png"></p><ol type="1"><li>输入为300×300的图片，先通过VGG-16的前置网络部分生成一个预测特征图</li><li>经过一系列卷积层，生成一系列预测特征图 —— 总共有6个预测特征图</li><li>分别在这6个预测特征层上预测不同尺度和比例的目标 —— 共生成8732个Default Box</li><li>对Default Box进行NMS和小概率目标滤除后</li><li>得到最终的预测结果</li></ol><blockquote><p>参考：https://blog.csdn.net/weixin_44878336/article/details/124674128</p></blockquote></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Unicorn-acc.github.io">Miraclo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://unicorn-acc.github.io/posts/41017.html">http://unicorn-acc.github.io/posts/41017.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Unicorn-acc.github.io" target="_blank">Miraclo’s Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/l8/wallhaven-l8qm3l.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/45578.html"><img class="prev-cover" src="https://w.wallhaven.cc/full/39/wallhaven-39zg5v.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Java数据结构模板总结</div></div></a></div><div class="next-post pull-right"><a href="/posts/890.html"><img class="next-cover" src="https://w.wallhaven.cc/full/y8/wallhaven-y8lqo7.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Java常用类及其方法总结</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/5074.html" title="图像分类_CIFAR10数据集"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_CIFAR10数据集</div></div></a></div><div><a href="/posts/47625.html" title="图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)"><img class="cover" src="https://w.wallhaven.cc/full/kx/wallhaven-kx3p1q.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-04</div><div class="title">图像分类_Fashion-MNIST数据集(ResNet18进行迁移学习)</div></div></a></div><div><a href="/posts/56670.html" title="目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)"><img class="cover" src="https://w.wallhaven.cc/full/vq/wallhaven-vqmyq3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-11</div><div class="title">目标检测&#x2F;分割_PASCAL VOC2012数据集与制作自己的数据集(VOC格式)</div></div></a></div><div><a href="/posts/2490.html" title="图像分类_花分类数据集"><img class="cover" src="https://w.wallhaven.cc/full/zy/wallhaven-zyxvqy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-06</div><div class="title">图像分类_花分类数据集</div></div></a></div><div><a href="/posts/64179.html" title="图像分类_00_LeNet_Pytorch官方示例"><img class="cover" src="https://w.wallhaven.cc/full/d6/wallhaven-d65mzm.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-07</div><div class="title">图像分类_00_LeNet_Pytorch官方示例</div></div></a></div><div><a href="/posts/32696.html" title="目标检测的常见指标与COCO评价标准"><img class="cover" src="https://w.wallhaven.cc/full/x6/wallhaven-x619o3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-12</div><div class="title">目标检测的常见指标与COCO评价标准</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-%E5%BC%95%E8%A8%80"><span class="toc-text">一、 引言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ssd-single-shot-multibox-detector%E7%AE%80%E4%BB%8B"><span class="toc-text">1.1 SSD: Single Shot MultiBox Detector简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%8F%91%E5%B1%95"><span class="toc-text">1.2 目标检测的发展</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tensorflow%E5%A4%8D%E7%8E%B0%E7%9A%84ssd%E4%BB%A3%E7%A0%81"><span class="toc-text">1.3 TensorFlow复现的SSD代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#faster-r-cnn%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">1.4 Faster R-CNN存在的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E6%B5%8B%E6%B5%81%E7%A8%8B"><span class="toc-text">1.4.1 检测流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">1.4.2 存在的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88faster-r-cnn%E5%AF%B9%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%88%E6%9E%9C%E5%B7%AE"><span class="toc-text">1.4.2.1 为什么Faster R-CNN对小目标检测效果差？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88faster-r-cnn%E6%A8%A1%E5%9E%8B%E5%A4%A7%E4%B8%94%E6%A3%80%E6%B5%8B%E9%80%9F%E5%BA%A6%E6%85%A2"><span class="toc-text">1.4.2.2 为什么Faster R-CNN模型大且检测速度慢？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8Cssd%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6"><span class="toc-text">二、SSD网络框架</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E7%89%B9%E5%BE%81%E5%9B%BE-feature-map-%E5%8C%B9%E9%85%8D%E4%B8%8D%E5%90%8C%E5%A4%A7%E5%B0%8F%E7%9A%84%E7%9B%AE%E6%A0%87"><span class="toc-text">2.1 不同特征图 (feature map) 匹配不同大小的目标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#default-box"><span class="toc-text">2.2 Default Box</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFdefault-box"><span class="toc-text">2.2.1 什么是Default Box</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#default-box%E7%9A%84scale%E4%BB%A5%E5%8F%8Aaspect%E8%AE%BE%E5%AE%9A"><span class="toc-text">2.2.2 Default Box的scale以及aspect设定</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AEscale%E5%92%8Caspect%E6%B1%82%E5%BE%97%E6%AF%8F%E4%B8%AA%E7%89%B9%E5%BE%81%E5%9B%BE%E7%9A%84default-box%E5%92%8C%E6%95%B0%E9%87%8F"><span class="toc-text">1.2.3 根据scale和aspect求得每个特征图的Default Box和数量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-%E9%A2%84%E6%B5%8B%E5%99%A8predictor%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-text">三、 预测器（predictor）的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E4%B8%AA%E6%95%B0"><span class="toc-text">3.1 卷积核的个数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB%E5%88%AB%E5%88%86%E6%95%B0%E9%A2%84%E6%B5%8B%E5%92%8C%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%8F%82%E6%95%B0%E9%A2%84%E6%B5%8B"><span class="toc-text">3.2 类别分数预测和边界框回归参数预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E7%B1%BB%E5%88%AB%E5%88%86%E6%95%B0%E9%A2%84%E6%B5%8B"><span class="toc-text">3.2.1 目标类别分数预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%8F%82%E6%95%B0%E9%A2%84%E6%B5%8B"><span class="toc-text">3.2.2 边界框回归参数预测</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B-%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E9%80%89%E5%8F%96"><span class="toc-text">四、 正负样本选取</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E6%A0%B7%E6%9C%AC%E7%9A%84%E9%80%89%E5%8F%96"><span class="toc-text">4.1 正样本的选取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E9%80%89%E5%8F%96"><span class="toc-text">4.2 负样本的选取</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94-%E6%8D%9F%E5%A4%B1%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-text">五、 损失的计算</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB%E5%88%AB%E6%8D%9F%E5%A4%B1"><span class="toc-text">5.1 类别损失</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%8D%9F%E5%A4%B1"><span class="toc-text">5.2 定位损失</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD-%E5%9B%9E%E9%A1%BE%E5%92%8C%E6%80%BB%E7%BB%93"><span class="toc-text">六、 回顾和总结</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Miraclo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">人只有在走上坡路的时候才会累和迷茫。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const n of document.querySelectorAll('script[type^="math/tex"]')){var e=!!n.type.match(/; *mode=display/),e=new t.options.MathItem(n.textContent,t.inputJax[0],e),a=document.createTextNode("");n.parentNode.replaceChild(a,n),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],insertScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t.hasAttribute("display")?btf.wrap(t,"div",{class:"mathjax-overflow"}):btf.wrap(t,"span",{class:"mathjax-overflow"})})},"",!1]}}};const a=document.createElement("script");a.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script></div><link rel="stylesheet" href="/css/Lete.css"><script src="/js/custom.js"></script><script src="/js/mouth.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/Java技术栈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Java技术栈相关 (54)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 深度学习笔记相关 (19)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/深度学习笔记/网络模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 网络模型 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://Unicorn-acc.github.io/categories/数据库/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">‍👓 数据库相关 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://Unicorn-acc.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(33.333333333333336% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>